[
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "to_native_string",
        "input": "Given a string object, regardless of type, returns a representation of\nthat string in the native string type, encoding and decoding where\nnecessary. This assumes ASCII unless told otherwise.",
        "output": "def to_native_string(string, encoding=\"ascii\"):\n    \"\"\"Given a string object, regardless of type, returns a representation of\n    that string in the native string type, encoding and decoding where\n    necessary. This assumes ASCII unless told otherwise.\n    \"\"\"\n    if isinstance(string, builtin_str):\n        out = string\n    else:\n        out = string.decode(encoding)\n\n    return out"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "unicode_is_ascii",
        "input": "Determine if unicode string only contains ASCII characters.\n\n:param str u_string: unicode string to check. Must be unicode\n    and not Python 2 `str`.\n:rtype: bool",
        "output": "def unicode_is_ascii(u_string):\n    \"\"\"Determine if unicode string only contains ASCII characters.\n\n    :param str u_string: unicode string to check. Must be unicode\n        and not Python 2 `str`.\n    :rtype: bool\n    \"\"\"\n    assert isinstance(u_string, str)\n    try:\n        u_string.encode(\"ascii\")\n        return True\n    except UnicodeEncodeError:\n        return False"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "send",
        "input": "Sends PreparedRequest object. Returns Response object.\n\n:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n:param stream: (optional) Whether to stream the request content.\n:param timeout: (optional) How long to wait for the server to send\n    data before giving up, as a float, or a :ref:`(connect timeout,\n    read timeout) <timeouts>` tuple.\n:type timeout: float or tuple\n:param verify: (optional) Either a boolean, in which case it controls whether we verify\n    the server's TLS certificate, or a string, in which case it must be a path\n    to a CA bundle to use\n:param cert: (optional) Any user-provided SSL certificate to be trusted.\n:param proxies: (optional) The proxies dictionary to apply to the request.",
        "output": "def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "close",
        "input": "Cleans up adapter specific items.",
        "output": "def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "init_poolmanager",
        "input": "Initializes a urllib3 PoolManager.\n\nThis method should not be called from user code, and is only\nexposed for use when subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param connections: The number of urllib3 connection pools to cache.\n:param maxsize: The maximum number of connections to save in the pool.\n:param block: Block when no free connections are available.\n:param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.",
        "output": "def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \"\"\"Initializes a urllib3 PoolManager.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param connections: The number of urllib3 connection pools to cache.\n        :param maxsize: The maximum number of connections to save in the pool.\n        :param block: Block when no free connections are available.\n        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n        \"\"\"\n        # save these values for pickling\n        self._pool_connections = connections\n        self._pool_maxsize = maxsize\n        self._pool_block = block\n\n        self.poolmanager = PoolManager(\n            num_pools=connections,\n            maxsize=maxsize,\n            block=block,\n            **pool_kwargs,\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "proxy_manager_for",
        "input": "Return urllib3 ProxyManager for the given proxy.\n\nThis method should not be called from user code, and is only\nexposed for use when subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param proxy: The proxy to return a urllib3 ProxyManager for.\n:param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n:returns: ProxyManager\n:rtype: urllib3.ProxyManager",
        "output": "def proxy_manager_for(self, proxy, **proxy_kwargs):\n        \"\"\"Return urllib3 ProxyManager for the given proxy.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The proxy to return a urllib3 ProxyManager for.\n        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n        :returns: ProxyManager\n        :rtype: urllib3.ProxyManager\n        \"\"\"\n        if proxy in self.proxy_manager:\n            manager = self.proxy_manager[proxy]\n        elif proxy.lower().startswith(\"socks\"):\n            username, password = get_auth_from_url(proxy)\n            manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n                proxy,\n                username=username,\n                password=password,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs,\n            )\n        else:\n            proxy_headers = self.proxy_headers(proxy)\n            manager = self.proxy_manager[proxy] = proxy_from_url(\n                proxy,\n                proxy_headers=proxy_headers,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs,\n            )\n\n        return manager"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "cert_verify",
        "input": "Verify a SSL certificate. This method should not be called from user\ncode, and is only exposed for use when subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param conn: The urllib3 connection object associated with the cert.\n:param url: The requested URL.\n:param verify: Either a boolean, in which case it controls whether we verify\n    the server's TLS certificate, or a string, in which case it must be a path\n    to a CA bundle to use\n:param cert: The SSL certificate to verify.",
        "output": "def cert_verify(self, conn, url, verify, cert):\n        \"\"\"Verify a SSL certificate. This method should not be called from user\n        code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param conn: The urllib3 connection object associated with the cert.\n        :param url: The requested URL.\n        :param verify: Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: The SSL certificate to verify.\n        \"\"\"\n        if url.lower().startswith(\"https\") and verify:\n            conn.cert_reqs = \"CERT_REQUIRED\"\n\n            # Only load the CA certificates if 'verify' is a string indicating the CA bundle to use.\n            # Otherwise, if verify is a boolean, we don't load anything since\n            # the connection will be using a context with the default certificates already loaded,\n            # and this avoids a call to the slow load_verify_locations()\n            if verify is not True:\n                # `verify` must be a str with a path then\n                cert_loc = verify\n\n                if not os.path.exists(cert_loc):\n                    raise OSError(\n                        f\"Could not find a suitable TLS CA certificate bundle, \"\n                        f\"invalid path: {cert_loc}\"\n                    )\n\n                if not os.path.isdir(cert_loc):\n                    conn.ca_certs = cert_loc\n                else:\n                    conn.ca_cert_dir = cert_loc\n        else:\n            conn.cert_reqs = \"CERT_NONE\"\n            conn.ca_certs = None\n            conn.ca_cert_dir = None\n\n        if cert:\n            if not isinstance(cert, basestring):\n                conn.cert_file = cert[0]\n                conn.key_file = cert[1]\n            else:\n                conn.cert_file = cert\n                conn.key_file = None\n            if conn.cert_file and not os.path.exists(conn.cert_file):\n                raise OSError(\n                    f\"Could not find the TLS certificate file, \"\n                    f\"invalid path: {conn.cert_file}\"\n                )\n            if conn.key_file and not os.path.exists(conn.key_file):\n                raise OSError(\n                    f\"Could not find the TLS key file, invalid path: {conn.key_file}\"\n                )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "build_response",
        "input": "Builds a :class:`Response <requests.Response>` object from a urllib3\nresponse. This should not be called from user code, and is only exposed\nfor use when subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n\n:param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n:param resp: The urllib3 response object.\n:rtype: requests.Response",
        "output": "def build_response(self, req, resp):\n        \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n        response. This should not be called from user code, and is only exposed\n        for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n\n        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n        :param resp: The urllib3 response object.\n        :rtype: requests.Response\n        \"\"\"\n        response = Response()\n\n        # Fallback to None if there's no status_code, for whatever reason.\n        response.status_code = getattr(resp, \"status\", None)\n\n        # Make headers case-insensitive.\n        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\n\n        # Set encoding.\n        response.encoding = get_encoding_from_headers(response.headers)\n        response.raw = resp\n        response.reason = response.raw.reason\n\n        if isinstance(req.url, bytes):\n            response.url = req.url.decode(\"utf-8\")\n        else:\n            response.url = req.url\n\n        # Add new cookies from the server.\n        extract_cookies_to_jar(response.cookies, req, resp)\n\n        # Give the Response some context.\n        response.request = req\n        response.connection = self\n\n        return response"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "build_connection_pool_key_attributes",
        "input": "Build the PoolKey attributes used by urllib3 to return a connection.\n\nThis looks at the PreparedRequest, the user-specified verify value,\nand the value of the cert parameter to determine what PoolKey values\nto use to select a connection from a given urllib3 Connection Pool.\n\nThe SSL related pool key arguments are not consistently set. As of\nthis writing, use the following to determine what keys may be in that\ndictionary:\n\n* If ``verify`` is ``True``, ``\"ssl_context\"`` will be set and will be the\n  default Requests SSL Context\n* If ``verify`` is ``False``, ``\"ssl_context\"`` will not be set but\n  ``\"cert_reqs\"`` will be set\n* If ``verify`` is a string, (i.e., it is a user-specified trust bundle)\n  ``\"ca_certs\"`` will be set if the string is not a directory recognized\n  by :py:func:`os.path.isdir`, otherwise ``\"ca_certs_dir\"`` will be\n  set.\n* If ``\"cert\"`` is specified, ``\"cert_file\"`` will always be set. If\n  ``\"cert\"`` is a tuple with a second item, ``\"key_file\"`` will also\n  be present\n\nTo override these settings, one may subclass this class, call this\nmethod and use the above logic to change parameters as desired. For\nexample, if one wishes to use a custom :py:class:`ssl.SSLContext` one\nmust both set ``\"ssl_context\"`` and based on what else they require,\nalter the other keys to ensure the desired behaviour.\n\n:param request:\n    The PreparedReqest being sent over the connection.\n:type request:\n    :class:`~requests.models.PreparedRequest`\n:param verify:\n    Either a boolean, in which case it controls whether\n    we verify the server's TLS certificate, or a string, in which case it\n    must be a path to a CA bundle to use.\n:param cert:\n    (optional) Any user-provided SSL certificate for client\n    authentication (a.k.a., mTLS). This may be a string (i.e., just\n    the path to a file which holds both certificate and key) or a\n    tuple of length 2 with the certificate file path and key file\n    path.\n:returns:\n    A tuple of two dictionaries. The first is the \"host parameters\"\n    portion of the Pool Key including scheme, hostname, and port. The\n    second is a dictionary of SSLContext related parameters.",
        "output": "def build_connection_pool_key_attributes(self, request, verify, cert=None):\n        \"\"\"Build the PoolKey attributes used by urllib3 to return a connection.\n\n        This looks at the PreparedRequest, the user-specified verify value,\n        and the value of the cert parameter to determine what PoolKey values\n        to use to select a connection from a given urllib3 Connection Pool.\n\n        The SSL related pool key arguments are not consistently set. As of\n        this writing, use the following to determine what keys may be in that\n        dictionary:\n\n        * If ``verify`` is ``True``, ``\"ssl_context\"`` will be set and will be the\n          default Requests SSL Context\n        * If ``verify`` is ``False``, ``\"ssl_context\"`` will not be set but\n          ``\"cert_reqs\"`` will be set\n        * If ``verify`` is a string, (i.e., it is a user-specified trust bundle)\n          ``\"ca_certs\"`` will be set if the string is not a directory recognized\n          by :py:func:`os.path.isdir`, otherwise ``\"ca_certs_dir\"`` will be\n          set.\n        * If ``\"cert\"`` is specified, ``\"cert_file\"`` will always be set. If\n          ``\"cert\"`` is a tuple with a second item, ``\"key_file\"`` will also\n          be present\n\n        To override these settings, one may subclass this class, call this\n        method and use the above logic to change parameters as desired. For\n        example, if one wishes to use a custom :py:class:`ssl.SSLContext` one\n        must both set ``\"ssl_context\"`` and based on what else they require,\n        alter the other keys to ensure the desired behaviour.\n\n        :param request:\n            The PreparedReqest being sent over the connection.\n        :type request:\n            :class:`~requests.models.PreparedRequest`\n        :param verify:\n            Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use.\n        :param cert:\n            (optional) Any user-provided SSL certificate for client\n            authentication (a.k.a., mTLS). This may be a string (i.e., just\n            the path to a file which holds both certificate and key) or a\n            tuple of length 2 with the certificate file path and key file\n            path.\n        :returns:\n            A tuple of two dictionaries. The first is the \"host parameters\"\n            portion of the Pool Key including scheme, hostname, and port. The\n            second is a dictionary of SSLContext related parameters.\n        \"\"\"\n        return _urllib3_request_context(request, verify, cert, self.poolmanager)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_connection_with_tls_context",
        "input": "Returns a urllib3 connection for the given request and TLS settings.\nThis should not be called from user code, and is only exposed for use\nwhen subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param request:\n    The :class:`PreparedRequest <PreparedRequest>` object to be sent\n    over the connection.\n:param verify:\n    Either a boolean, in which case it controls whether we verify the\n    server's TLS certificate, or a string, in which case it must be a\n    path to a CA bundle to use.\n:param proxies:\n    (optional) The proxies dictionary to apply to the request.\n:param cert:\n    (optional) Any user-provided SSL certificate to be used for client\n    authentication (a.k.a., mTLS).\n:rtype:\n    urllib3.ConnectionPool",
        "output": "def get_connection_with_tls_context(self, request, verify, proxies=None, cert=None):\n        \"\"\"Returns a urllib3 connection for the given request and TLS settings.\n        This should not be called from user code, and is only exposed for use\n        when subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request:\n            The :class:`PreparedRequest <PreparedRequest>` object to be sent\n            over the connection.\n        :param verify:\n            Either a boolean, in which case it controls whether we verify the\n            server's TLS certificate, or a string, in which case it must be a\n            path to a CA bundle to use.\n        :param proxies:\n            (optional) The proxies dictionary to apply to the request.\n        :param cert:\n            (optional) Any user-provided SSL certificate to be used for client\n            authentication (a.k.a., mTLS).\n        :rtype:\n            urllib3.ConnectionPool\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        try:\n            host_params, pool_kwargs = self.build_connection_pool_key_attributes(\n                request,\n                verify,\n                cert,\n            )\n        except ValueError as e:\n            raise InvalidURL(e, request=request)\n        if proxy:\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\n            proxy_url = parse_url(proxy)\n            if not proxy_url.host:\n                raise InvalidProxyURL(\n                    \"Please check proxy URL. It is malformed \"\n                    \"and could be missing the host.\"\n                )\n            proxy_manager = self.proxy_manager_for(proxy)\n            conn = proxy_manager.connection_from_host(\n                **host_params, pool_kwargs=pool_kwargs\n            )\n        else:\n            # Only scheme should be lower case\n            conn = self.poolmanager.connection_from_host(\n                **host_params, pool_kwargs=pool_kwargs\n            )\n\n        return conn"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_connection",
        "input": "DEPRECATED: Users should move to `get_connection_with_tls_context`\nfor all subclasses of HTTPAdapter using Requests>=2.32.2.\n\nReturns a urllib3 connection for the given URL. This should not be\ncalled from user code, and is only exposed for use when subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param url: The URL to connect to.\n:param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n:rtype: urllib3.ConnectionPool",
        "output": "def get_connection(self, url, proxies=None):\n        \"\"\"DEPRECATED: Users should move to `get_connection_with_tls_context`\n        for all subclasses of HTTPAdapter using Requests>=2.32.2.\n\n        Returns a urllib3 connection for the given URL. This should not be\n        called from user code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param url: The URL to connect to.\n        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n        :rtype: urllib3.ConnectionPool\n        \"\"\"\n        warnings.warn(\n            (\n                \"`get_connection` has been deprecated in favor of \"\n                \"`get_connection_with_tls_context`. Custom HTTPAdapter subclasses \"\n                \"will need to migrate for Requests>=2.32.2. Please see \"\n                \"https://github.com/psf/requests/pull/6710 for more details.\"\n            ),\n            DeprecationWarning,\n        )\n        proxy = select_proxy(url, proxies)\n\n        if proxy:\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\n            proxy_url = parse_url(proxy)\n            if not proxy_url.host:\n                raise InvalidProxyURL(\n                    \"Please check proxy URL. It is malformed \"\n                    \"and could be missing the host.\"\n                )\n            proxy_manager = self.proxy_manager_for(proxy)\n            conn = proxy_manager.connection_from_url(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "close",
        "input": "Disposes of any internal state.\n\nCurrently, this closes the PoolManager and any active ProxyManager,\nwhich closes any pooled connections.",
        "output": "def close(self):\n        \"\"\"Disposes of any internal state.\n\n        Currently, this closes the PoolManager and any active ProxyManager,\n        which closes any pooled connections.\n        \"\"\"\n        self.poolmanager.clear()\n        for proxy in self.proxy_manager.values():\n            proxy.clear()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "request_url",
        "input": "Obtain the url to use when making the final request.\n\nIf the message is being sent through a HTTP proxy, the full URL has to\nbe used. Otherwise, we should only use the path portion of the URL.\n\nThis should not be called from user code, and is only exposed for use\nwhen subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n:rtype: str",
        "output": "def request_url(self, request, proxies):\n        \"\"\"Obtain the url to use when making the final request.\n\n        If the message is being sent through a HTTP proxy, the full URL has to\n        be used. Otherwise, we should only use the path portion of the URL.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n        :rtype: str\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        scheme = urlparse(request.url).scheme\n\n        is_proxied_http_request = proxy and scheme != \"https\"\n        using_socks_proxy = False\n        if proxy:\n            proxy_scheme = urlparse(proxy).scheme.lower()\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n\n        url = request.path_url\n        if url.startswith(\"//\"):  # Don't confuse urllib3\n            url = f\"/{url.lstrip('/')}\"\n\n        if is_proxied_http_request and not using_socks_proxy:\n            url = urldefragauth(request.url)\n\n        return url"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "add_headers",
        "input": "Add any headers needed by the connection. As of v2.0 this does\nnothing by default, but is left for overriding by users that subclass\nthe :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\nThis should not be called from user code, and is only exposed for use\nwhen subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n:param kwargs: The keyword arguments from the call to send().",
        "output": "def add_headers(self, request, **kwargs):\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n        nothing by default, but is left for overriding by users that subclass\n        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "proxy_headers",
        "input": "Returns a dictionary of the headers to add to any request sent\nthrough a proxy. This works with urllib3 magic to ensure that they are\ncorrectly sent to the proxy, rather than in a tunnelled request if\nCONNECT is being used.\n\nThis should not be called from user code, and is only exposed for use\nwhen subclassing the\n:class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n:param proxy: The url of the proxy being used for this request.\n:rtype: dict",
        "output": "def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "send",
        "input": "Sends PreparedRequest object. Returns Response object.\n\n:param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n:param stream: (optional) Whether to stream the request content.\n:param timeout: (optional) How long to wait for the server to send\n    data before giving up, as a float, or a :ref:`(connect timeout,\n    read timeout) <timeouts>` tuple.\n:type timeout: float or tuple or urllib3 Timeout object\n:param verify: (optional) Either a boolean, in which case it controls whether\n    we verify the server's TLS certificate, or a string, in which case it\n    must be a path to a CA bundle to use\n:param cert: (optional) Any user-provided SSL certificate to be trusted.\n:param proxies: (optional) The proxies dictionary to apply to the request.\n:rtype: requests.Response",
        "output": "def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n\n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n\n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n\n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n\n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n\n        try:\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n\n        except (ProtocolError, OSError) as err:\n            raise ConnectionError(err, request=request)\n\n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n\n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n\n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n\n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n\n            raise ConnectionError(e, request=request)\n\n        except ClosedPoolError as e:\n            raise ConnectionError(e, request=request)\n\n        except _ProxyError as e:\n            raise ProxyError(e)\n\n        except (_SSLError, _HTTPError) as e:\n            if isinstance(e, _SSLError):\n                # This branch is for urllib3 versions earlier than v1.22\n                raise SSLError(e, request=request)\n            elif isinstance(e, ReadTimeoutError):\n                raise ReadTimeout(e, request=request)\n            elif isinstance(e, _InvalidHeader):\n                raise InvalidHeader(e, request=request)\n            else:\n                raise\n\n        return self.build_response(request, resp)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "request",
        "input": "Constructs and sends a :class:`Request <Request>`.\n\n:param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n:param url: URL for the new :class:`Request` object.\n:param params: (optional) Dictionary, list of tuples or bytes to send\n    in the query string for the :class:`Request`.\n:param data: (optional) Dictionary, list of tuples, bytes, or file-like\n    object to send in the body of the :class:`Request`.\n:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n:param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n:param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n:param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n    ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n    or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n    defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n    to add for the file.\n:param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n:param timeout: (optional) How many seconds to wait for the server to send data\n    before giving up, as a float, or a :ref:`(connect timeout, read\n    timeout) <timeouts>` tuple.\n:type timeout: float or tuple\n:param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.\n:type allow_redirects: bool\n:param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n:param verify: (optional) Either a boolean, in which case it controls whether we verify\n        the server's TLS certificate, or a string, in which case it must be a path\n        to a CA bundle to use. Defaults to ``True``.\n:param stream: (optional) if ``False``, the response content will be immediately downloaded.\n:param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n:return: :class:`Response <Response>` object\n:rtype: requests.Response\n\nUsage::\n\n  >>> import requests\n  >>> req = requests.request('GET', 'https://httpbin.org/get')\n  >>> req\n  <Response [200]>",
        "output": "def request(method, url, **kwargs):\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\n\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\n    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.\n        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``\n        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\n        to add for the file.\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n    :param timeout: (optional) How many seconds to wait for the server to send data\n        before giving up, as a float, or a :ref:`(connect timeout, read\n        timeout) <timeouts>` tuple.\n    :type timeout: float or tuple\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.\n    :type allow_redirects: bool\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``.\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.request('GET', 'https://httpbin.org/get')\n      >>> req\n      <Response [200]>\n    \"\"\"\n\n    # By using the 'with' statement we are sure the session is closed, thus we\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\n    # cases, and look like a memory leak in others.\n    with sessions.Session() as session:\n        return session.request(method=method, url=url, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get",
        "input": "Sends a GET request.\n\n:param url: URL for the new :class:`Request` object.\n:param params: (optional) Dictionary, list of tuples or bytes to send\n    in the query string for the :class:`Request`.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:return: :class:`Response <Response>` object\n:rtype: requests.Response",
        "output": "def get(url, params=None, **kwargs):\n    r\"\"\"Sends a GET request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param params: (optional) Dictionary, list of tuples or bytes to send\n        in the query string for the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"get\", url, params=params, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "options",
        "input": "Sends an OPTIONS request.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:return: :class:`Response <Response>` object\n:rtype: requests.Response",
        "output": "def options(url, **kwargs):\n    r\"\"\"Sends an OPTIONS request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"options\", url, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "head",
        "input": "Sends a HEAD request.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n    `allow_redirects` is not provided, it will be set to `False` (as\n    opposed to the default :meth:`request` behavior).\n:return: :class:`Response <Response>` object\n:rtype: requests.Response",
        "output": "def head(url, **kwargs):\n    r\"\"\"Sends a HEAD request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes. If\n        `allow_redirects` is not provided, it will be set to `False` (as\n        opposed to the default :meth:`request` behavior).\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    kwargs.setdefault(\"allow_redirects\", False)\n    return request(\"head\", url, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "post",
        "input": "Sends a POST request.\n\n:param url: URL for the new :class:`Request` object.\n:param data: (optional) Dictionary, list of tuples, bytes, or file-like\n    object to send in the body of the :class:`Request`.\n:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:return: :class:`Response <Response>` object\n:rtype: requests.Response",
        "output": "def post(url, data=None, json=None, **kwargs):\n    r\"\"\"Sends a POST request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"post\", url, data=data, json=json, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "put",
        "input": "Sends a PUT request.\n\n:param url: URL for the new :class:`Request` object.\n:param data: (optional) Dictionary, list of tuples, bytes, or file-like\n    object to send in the body of the :class:`Request`.\n:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:return: :class:`Response <Response>` object\n:rtype: requests.Response",
        "output": "def put(url, data=None, **kwargs):\n    r\"\"\"Sends a PUT request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"put\", url, data=data, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "patch",
        "input": "Sends a PATCH request.\n\n:param url: URL for the new :class:`Request` object.\n:param data: (optional) Dictionary, list of tuples, bytes, or file-like\n    object to send in the body of the :class:`Request`.\n:param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:return: :class:`Response <Response>` object\n:rtype: requests.Response",
        "output": "def patch(url, data=None, **kwargs):\n    r\"\"\"Sends a PATCH request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n        object to send in the body of the :class:`Request`.\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"patch\", url, data=data, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "delete",
        "input": "Sends a DELETE request.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:return: :class:`Response <Response>` object\n:rtype: requests.Response",
        "output": "def delete(url, **kwargs):\n    r\"\"\"Sends a DELETE request.\n\n    :param url: URL for the new :class:`Request` object.\n    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n    :return: :class:`Response <Response>` object\n    :rtype: requests.Response\n    \"\"\"\n\n    return request(\"delete\", url, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_basic_auth_str",
        "input": "Returns a Basic Auth string.",
        "output": "def _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n\n    # \"I want us to put a big-ol' comment on top of it that\n    # says that this behaviour is dumb but we need to preserve\n    # it because people are relying on it.\"\n    #    - Lukasa\n    #\n    # These are here solely to maintain backwards compatibility\n    # for things like ints. This will be removed in 3.0.0.\n    if not isinstance(username, basestring):\n        warnings.warn(\n            \"Non-string usernames will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(username),\n            category=DeprecationWarning,\n        )\n        username = str(username)\n\n    if not isinstance(password, basestring):\n        warnings.warn(\n            \"Non-string passwords will no longer be supported in Requests \"\n            \"3.0.0. Please convert the object you've passed in ({!r}) to \"\n            \"a string or bytes object in the near future to avoid \"\n            \"problems.\".format(type(password)),\n            category=DeprecationWarning,\n        )\n        password = str(password)\n    # -- End Removal --\n\n    if isinstance(username, str):\n        username = username.encode(\"latin1\")\n\n    if isinstance(password, str):\n        password = password.encode(\"latin1\")\n\n    authstr = \"Basic \" + to_native_string(\n        b64encode(b\":\".join((username, password))).strip()\n    )\n\n    return authstr"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "build_digest_header",
        "input": ":rtype: str",
        "output": "def build_digest_header(self, method, url):\n        \"\"\"\n        :rtype: str\n        \"\"\"\n\n        realm = self._thread_local.chal[\"realm\"]\n        nonce = self._thread_local.chal[\"nonce\"]\n        qop = self._thread_local.chal.get(\"qop\")\n        algorithm = self._thread_local.chal.get(\"algorithm\")\n        opaque = self._thread_local.chal.get(\"opaque\")\n        hash_utf8 = None\n\n        if algorithm is None:\n            _algorithm = \"MD5\"\n        else:\n            _algorithm = algorithm.upper()\n        # lambdas assume digest modules are imported at the top level\n        if _algorithm == \"MD5\" or _algorithm == \"MD5-SESS\":\n\n            def md5_utf8(x):\n                if isinstance(x, str):\n                    x = x.encode(\"utf-8\")\n                return hashlib.md5(x).hexdigest()\n\n            hash_utf8 = md5_utf8\n        elif _algorithm == \"SHA\":\n\n            def sha_utf8(x):\n                if isinstance(x, str):\n                    x = x.encode(\"utf-8\")\n                return hashlib.sha1(x).hexdigest()\n\n            hash_utf8 = sha_utf8\n        elif _algorithm == \"SHA-256\":\n\n            def sha256_utf8(x):\n                if isinstance(x, str):\n                    x = x.encode(\"utf-8\")\n                return hashlib.sha256(x).hexdigest()\n\n            hash_utf8 = sha256_utf8\n        elif _algorithm == \"SHA-512\":\n\n            def sha512_utf8(x):\n                if isinstance(x, str):\n                    x = x.encode(\"utf-8\")\n                return hashlib.sha512(x).hexdigest()\n\n            hash_utf8 = sha512_utf8\n\n        KD = lambda s, d: hash_utf8(f\"{s}:{d}\")  # noqa:E731\n\n        if hash_utf8 is None:\n            return None\n\n        # XXX not implemented yet\n        entdig = None\n        p_parsed = urlparse(url)\n        #: path is request-uri defined in RFC 2616 which should not be empty\n        path = p_parsed.path or \"/\"\n        if p_parsed.query:\n            path += f\"?{p_parsed.query}\"\n\n        A1 = f\"{self.username}:{realm}:{self.password}\"\n        A2 = f\"{method}:{path}\"\n\n        HA1 = hash_utf8(A1)\n        HA2 = hash_utf8(A2)\n\n        if nonce == self._thread_local.last_nonce:\n            self._thread_local.nonce_count += 1\n        else:\n            self._thread_local.nonce_count = 1\n        ncvalue = f\"{self._thread_local.nonce_count:08x}\"\n        s = str(self._thread_local.nonce_count).encode(\"utf-8\")\n        s += nonce.encode(\"utf-8\")\n        s += time.ctime().encode(\"utf-8\")\n        s += os.urandom(8)\n\n        cnonce = hashlib.sha1(s).hexdigest()[:16]\n        if _algorithm == \"MD5-SESS\":\n            HA1 = hash_utf8(f\"{HA1}:{nonce}:{cnonce}\")\n\n        if not qop:\n            respdig = KD(HA1, f\"{nonce}:{HA2}\")\n        elif qop == \"auth\" or \"auth\" in qop.split(\",\"):\n            noncebit = f\"{nonce}:{ncvalue}:{cnonce}:auth:{HA2}\"\n            respdig = KD(HA1, noncebit)\n        else:\n            # XXX handle auth-int.\n            return None\n\n        self._thread_local.last_nonce = nonce\n\n        # XXX should the partial digests be encoded too?\n        base = (\n            f'username=\"{self.username}\", realm=\"{realm}\", nonce=\"{nonce}\", '\n            f'uri=\"{path}\", response=\"{respdig}\"'\n        )\n        if opaque:\n            base += f', opaque=\"{opaque}\"'\n        if algorithm:\n            base += f', algorithm=\"{algorithm}\"'\n        if entdig:\n            base += f', digest=\"{entdig}\"'\n        if qop:\n            base += f', qop=\"auth\", nc={ncvalue}, cnonce=\"{cnonce}\"'\n\n        return f\"Digest {base}\""
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "handle_redirect",
        "input": "Reset num_401_calls counter on redirects.",
        "output": "def handle_redirect(self, r, **kwargs):\n        \"\"\"Reset num_401_calls counter on redirects.\"\"\"\n        if r.is_redirect:\n            self._thread_local.num_401_calls = 1"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "handle_401",
        "input": "Takes the given response and tries digest-auth, if needed.\n\n:rtype: requests.Response",
        "output": "def handle_401(self, r, **kwargs):\n        \"\"\"\n        Takes the given response and tries digest-auth, if needed.\n\n        :rtype: requests.Response\n        \"\"\"\n\n        # If response is not 4xx, do not auth\n        # See https://github.com/psf/requests/issues/3772\n        if not 400 <= r.status_code < 500:\n            self._thread_local.num_401_calls = 1\n            return r\n\n        if self._thread_local.pos is not None:\n            # Rewind the file position indicator of the body to where\n            # it was to resend the request.\n            r.request.body.seek(self._thread_local.pos)\n        s_auth = r.headers.get(\"www-authenticate\", \"\")\n\n        if \"digest\" in s_auth.lower() and self._thread_local.num_401_calls < 2:\n            self._thread_local.num_401_calls += 1\n            pat = re.compile(r\"digest \", flags=re.IGNORECASE)\n            self._thread_local.chal = parse_dict_header(pat.sub(\"\", s_auth, count=1))\n\n            # Consume content and release the original connection\n            # to allow our new request to reuse the same one.\n            r.content\n            r.close()\n            prep = r.request.copy()\n            extract_cookies_to_jar(prep._cookies, r.request, r.raw)\n            prep.prepare_cookies(prep._cookies)\n\n            prep.headers[\"Authorization\"] = self.build_digest_header(\n                prep.method, prep.url\n            )\n            _r = r.connection.send(prep, **kwargs)\n            _r.history.append(r)\n            _r.request = prep\n\n            return _r\n\n        self._thread_local.num_401_calls = 1\n        return r"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_resolve_char_detection",
        "input": "Find supported character detection libraries.",
        "output": "def _resolve_char_detection():\n    \"\"\"Find supported character detection libraries.\"\"\"\n    chardet = None\n    for lib in (\"chardet\", \"charset_normalizer\"):\n        if chardet is None:\n            try:\n                chardet = importlib.import_module(lib)\n            except ImportError:\n                pass\n    return chardet"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "extract_cookies_to_jar",
        "input": "Extract the cookies from the response into a CookieJar.\n\n:param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)\n:param request: our own requests.Request object\n:param response: urllib3.HTTPResponse object",
        "output": "def extract_cookies_to_jar(jar, request, response):\n    \"\"\"Extract the cookies from the response into a CookieJar.\n\n    :param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)\n    :param request: our own requests.Request object\n    :param response: urllib3.HTTPResponse object\n    \"\"\"\n    if not (hasattr(response, \"_original_response\") and response._original_response):\n        return\n    # the _original_response field is the wrapped httplib.HTTPResponse object,\n    req = MockRequest(request)\n    # pull out the HTTPMessage with the headers and put it in the mock:\n    res = MockResponse(response._original_response.msg)\n    jar.extract_cookies(res, req)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_cookie_header",
        "input": "Produce an appropriate Cookie header string to be sent with `request`, or None.\n\n:rtype: str",
        "output": "def get_cookie_header(jar, request):\n    \"\"\"\n    Produce an appropriate Cookie header string to be sent with `request`, or None.\n\n    :rtype: str\n    \"\"\"\n    r = MockRequest(request)\n    jar.add_cookie_header(r)\n    return r.get_new_headers().get(\"Cookie\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "remove_cookie_by_name",
        "input": "Unsets a cookie by name, by default over all domains and paths.\n\nWraps CookieJar.clear(), is O(n).",
        "output": "def remove_cookie_by_name(cookiejar, name, domain=None, path=None):\n    \"\"\"Unsets a cookie by name, by default over all domains and paths.\n\n    Wraps CookieJar.clear(), is O(n).\n    \"\"\"\n    clearables = []\n    for cookie in cookiejar:\n        if cookie.name != name:\n            continue\n        if domain is not None and domain != cookie.domain:\n            continue\n        if path is not None and path != cookie.path:\n            continue\n        clearables.append((cookie.domain, cookie.path, cookie.name))\n\n    for domain, path, name in clearables:\n        cookiejar.clear(domain, path, name)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "create_cookie",
        "input": "Make a cookie from underspecified parameters.\n\nBy default, the pair of `name` and `value` will be set for the domain ''\nand sent on every request (this is sometimes called a \"supercookie\").",
        "output": "def create_cookie(name, value, **kwargs):\n    \"\"\"Make a cookie from underspecified parameters.\n\n    By default, the pair of `name` and `value` will be set for the domain ''\n    and sent on every request (this is sometimes called a \"supercookie\").\n    \"\"\"\n    result = {\n        \"version\": 0,\n        \"name\": name,\n        \"value\": value,\n        \"port\": None,\n        \"domain\": \"\",\n        \"path\": \"/\",\n        \"secure\": False,\n        \"expires\": None,\n        \"discard\": True,\n        \"comment\": None,\n        \"comment_url\": None,\n        \"rest\": {\"HttpOnly\": None},\n        \"rfc2109\": False,\n    }\n\n    badargs = set(kwargs) - set(result)\n    if badargs:\n        raise TypeError(\n            f\"create_cookie() got unexpected keyword arguments: {list(badargs)}\"\n        )\n\n    result.update(kwargs)\n    result[\"port_specified\"] = bool(result[\"port\"])\n    result[\"domain_specified\"] = bool(result[\"domain\"])\n    result[\"domain_initial_dot\"] = result[\"domain\"].startswith(\".\")\n    result[\"path_specified\"] = bool(result[\"path\"])\n\n    return cookielib.Cookie(**result)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "morsel_to_cookie",
        "input": "Convert a Morsel object into a Cookie containing the one k/v pair.",
        "output": "def morsel_to_cookie(morsel):\n    \"\"\"Convert a Morsel object into a Cookie containing the one k/v pair.\"\"\"\n\n    expires = None\n    if morsel[\"max-age\"]:\n        try:\n            expires = int(time.time() + int(morsel[\"max-age\"]))\n        except ValueError:\n            raise TypeError(f\"max-age: {morsel['max-age']} must be integer\")\n    elif morsel[\"expires\"]:\n        time_template = \"%a, %d-%b-%Y %H:%M:%S GMT\"\n        expires = calendar.timegm(time.strptime(morsel[\"expires\"], time_template))\n    return create_cookie(\n        comment=morsel[\"comment\"],\n        comment_url=bool(morsel[\"comment\"]),\n        discard=False,\n        domain=morsel[\"domain\"],\n        expires=expires,\n        name=morsel.key,\n        path=morsel[\"path\"],\n        port=None,\n        rest={\"HttpOnly\": morsel[\"httponly\"]},\n        rfc2109=False,\n        secure=bool(morsel[\"secure\"]),\n        value=morsel.value,\n        version=morsel[\"version\"] or 0,\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "cookiejar_from_dict",
        "input": "Returns a CookieJar from a key/value dictionary.\n\n:param cookie_dict: Dict of key/values to insert into CookieJar.\n:param cookiejar: (optional) A cookiejar to add the cookies to.\n:param overwrite: (optional) If False, will not replace cookies\n    already in the jar with new ones.\n:rtype: CookieJar",
        "output": "def cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :param cookiejar: (optional) A cookiejar to add the cookies to.\n    :param overwrite: (optional) If False, will not replace cookies\n        already in the jar with new ones.\n    :rtype: CookieJar\n    \"\"\"\n    if cookiejar is None:\n        cookiejar = RequestsCookieJar()\n\n    if cookie_dict is not None:\n        names_from_jar = [cookie.name for cookie in cookiejar]\n        for name in cookie_dict:\n            if overwrite or (name not in names_from_jar):\n                cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))\n\n    return cookiejar"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "merge_cookies",
        "input": "Add cookies to cookiejar and returns a merged CookieJar.\n\n:param cookiejar: CookieJar object to add the cookies to.\n:param cookies: Dictionary or CookieJar object to be added.\n:rtype: CookieJar",
        "output": "def merge_cookies(cookiejar, cookies):\n    \"\"\"Add cookies to cookiejar and returns a merged CookieJar.\n\n    :param cookiejar: CookieJar object to add the cookies to.\n    :param cookies: Dictionary or CookieJar object to be added.\n    :rtype: CookieJar\n    \"\"\"\n    if not isinstance(cookiejar, cookielib.CookieJar):\n        raise ValueError(\"You can only merge into CookieJar\")\n\n    if isinstance(cookies, dict):\n        cookiejar = cookiejar_from_dict(cookies, cookiejar=cookiejar, overwrite=False)\n    elif isinstance(cookies, cookielib.CookieJar):\n        try:\n            cookiejar.update(cookies)\n        except AttributeError:\n            for cookie_in_jar in cookies:\n                cookiejar.set_cookie(cookie_in_jar)\n\n    return cookiejar"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "add_header",
        "input": "cookiejar has no legitimate use for this method; add it back if you find one.",
        "output": "def add_header(self, key, val):\n        \"\"\"cookiejar has no legitimate use for this method; add it back if you find one.\"\"\"\n        raise NotImplementedError(\n            \"Cookie headers should be added with add_unredirected_header()\"\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__init__",
        "input": "Make a MockResponse for `cookiejar` to read.\n\n:param headers: a httplib.HTTPMessage or analogous carrying the headers",
        "output": "def __init__(self, headers):\n        \"\"\"Make a MockResponse for `cookiejar` to read.\n\n        :param headers: a httplib.HTTPMessage or analogous carrying the headers\n        \"\"\"\n        self._headers = headers"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get",
        "input": "Dict-like get() that also supports optional domain and path args in\norder to resolve naming collisions from using one cookie jar over\nmultiple domains.\n\n.. warning:: operation is O(n), not O(1).",
        "output": "def get(self, name, default=None, domain=None, path=None):\n        \"\"\"Dict-like get() that also supports optional domain and path args in\n        order to resolve naming collisions from using one cookie jar over\n        multiple domains.\n\n        .. warning:: operation is O(n), not O(1).\n        \"\"\"\n        try:\n            return self._find_no_duplicates(name, domain, path)\n        except KeyError:\n            return default"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "set",
        "input": "Dict-like set() that also supports optional domain and path args in\norder to resolve naming collisions from using one cookie jar over\nmultiple domains.",
        "output": "def set(self, name, value, **kwargs):\n        \"\"\"Dict-like set() that also supports optional domain and path args in\n        order to resolve naming collisions from using one cookie jar over\n        multiple domains.\n        \"\"\"\n        # support client code that unsets cookies by assignment of a None value:\n        if value is None:\n            remove_cookie_by_name(\n                self, name, domain=kwargs.get(\"domain\"), path=kwargs.get(\"path\")\n            )\n            return\n\n        if isinstance(value, Morsel):\n            c = morsel_to_cookie(value)\n        else:\n            c = create_cookie(name, value, **kwargs)\n        self.set_cookie(c)\n        return c"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "iterkeys",
        "input": "Dict-like iterkeys() that returns an iterator of names of cookies\nfrom the jar.\n\n.. seealso:: itervalues() and iteritems().",
        "output": "def iterkeys(self):\n        \"\"\"Dict-like iterkeys() that returns an iterator of names of cookies\n        from the jar.\n\n        .. seealso:: itervalues() and iteritems().\n        \"\"\"\n        for cookie in iter(self):\n            yield cookie.name"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "keys",
        "input": "Dict-like keys() that returns a list of names of cookies from the\njar.\n\n.. seealso:: values() and items().",
        "output": "def keys(self):\n        \"\"\"Dict-like keys() that returns a list of names of cookies from the\n        jar.\n\n        .. seealso:: values() and items().\n        \"\"\"\n        return list(self.iterkeys())"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "itervalues",
        "input": "Dict-like itervalues() that returns an iterator of values of cookies\nfrom the jar.\n\n.. seealso:: iterkeys() and iteritems().",
        "output": "def itervalues(self):\n        \"\"\"Dict-like itervalues() that returns an iterator of values of cookies\n        from the jar.\n\n        .. seealso:: iterkeys() and iteritems().\n        \"\"\"\n        for cookie in iter(self):\n            yield cookie.value"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "values",
        "input": "Dict-like values() that returns a list of values of cookies from the\njar.\n\n.. seealso:: keys() and items().",
        "output": "def values(self):\n        \"\"\"Dict-like values() that returns a list of values of cookies from the\n        jar.\n\n        .. seealso:: keys() and items().\n        \"\"\"\n        return list(self.itervalues())"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "iteritems",
        "input": "Dict-like iteritems() that returns an iterator of name-value tuples\nfrom the jar.\n\n.. seealso:: iterkeys() and itervalues().",
        "output": "def iteritems(self):\n        \"\"\"Dict-like iteritems() that returns an iterator of name-value tuples\n        from the jar.\n\n        .. seealso:: iterkeys() and itervalues().\n        \"\"\"\n        for cookie in iter(self):\n            yield cookie.name, cookie.value"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "items",
        "input": "Dict-like items() that returns a list of name-value tuples from the\njar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a\nvanilla python dict of key value pairs.\n\n.. seealso:: keys() and values().",
        "output": "def items(self):\n        \"\"\"Dict-like items() that returns a list of name-value tuples from the\n        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a\n        vanilla python dict of key value pairs.\n\n        .. seealso:: keys() and values().\n        \"\"\"\n        return list(self.iteritems())"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "list_domains",
        "input": "Utility method to list all the domains in the jar.",
        "output": "def list_domains(self):\n        \"\"\"Utility method to list all the domains in the jar.\"\"\"\n        domains = []\n        for cookie in iter(self):\n            if cookie.domain not in domains:\n                domains.append(cookie.domain)\n        return domains"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "list_paths",
        "input": "Utility method to list all the paths in the jar.",
        "output": "def list_paths(self):\n        \"\"\"Utility method to list all the paths in the jar.\"\"\"\n        paths = []\n        for cookie in iter(self):\n            if cookie.path not in paths:\n                paths.append(cookie.path)\n        return paths"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "multiple_domains",
        "input": "Returns True if there are multiple domains in the jar.\nReturns False otherwise.\n\n:rtype: bool",
        "output": "def multiple_domains(self):\n        \"\"\"Returns True if there are multiple domains in the jar.\n        Returns False otherwise.\n\n        :rtype: bool\n        \"\"\"\n        domains = []\n        for cookie in iter(self):\n            if cookie.domain is not None and cookie.domain in domains:\n                return True\n            domains.append(cookie.domain)\n        return False  # there is only one domain in jar"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_dict",
        "input": "Takes as an argument an optional domain and path and returns a plain\nold Python dict of name-value pairs of cookies that meet the\nrequirements.\n\n:rtype: dict",
        "output": "def get_dict(self, domain=None, path=None):\n        \"\"\"Takes as an argument an optional domain and path and returns a plain\n        old Python dict of name-value pairs of cookies that meet the\n        requirements.\n\n        :rtype: dict\n        \"\"\"\n        dictionary = {}\n        for cookie in iter(self):\n            if (domain is None or cookie.domain == domain) and (\n                path is None or cookie.path == path\n            ):\n                dictionary[cookie.name] = cookie.value\n        return dictionary"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__getitem__",
        "input": "Dict-like __getitem__() for compatibility with client code. Throws\nexception if there are more than one cookie with name. In that case,\nuse the more explicit get() method instead.\n\n.. warning:: operation is O(n), not O(1).",
        "output": "def __getitem__(self, name):\n        \"\"\"Dict-like __getitem__() for compatibility with client code. Throws\n        exception if there are more than one cookie with name. In that case,\n        use the more explicit get() method instead.\n\n        .. warning:: operation is O(n), not O(1).\n        \"\"\"\n        return self._find_no_duplicates(name)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__setitem__",
        "input": "Dict-like __setitem__ for compatibility with client code. Throws\nexception if there is already a cookie of that name in the jar. In that\ncase, use the more explicit set() method instead.",
        "output": "def __setitem__(self, name, value):\n        \"\"\"Dict-like __setitem__ for compatibility with client code. Throws\n        exception if there is already a cookie of that name in the jar. In that\n        case, use the more explicit set() method instead.\n        \"\"\"\n        self.set(name, value)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__delitem__",
        "input": "Deletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``'s\n``remove_cookie_by_name()``.",
        "output": "def __delitem__(self, name):\n        \"\"\"Deletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``'s\n        ``remove_cookie_by_name()``.\n        \"\"\"\n        remove_cookie_by_name(self, name)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "update",
        "input": "Updates this jar with cookies from another CookieJar or dict-like",
        "output": "def update(self, other):\n        \"\"\"Updates this jar with cookies from another CookieJar or dict-like\"\"\"\n        if isinstance(other, cookielib.CookieJar):\n            for cookie in other:\n                self.set_cookie(copy.copy(cookie))\n        else:\n            super().update(other)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_find",
        "input": "Requests uses this method internally to get cookie values.\n\nIf there are conflicting cookies, _find arbitrarily chooses one.\nSee _find_no_duplicates if you want an exception thrown if there are\nconflicting cookies.\n\n:param name: a string containing name of cookie\n:param domain: (optional) string containing domain of cookie\n:param path: (optional) string containing path of cookie\n:return: cookie.value",
        "output": "def _find(self, name, domain=None, path=None):\n        \"\"\"Requests uses this method internally to get cookie values.\n\n        If there are conflicting cookies, _find arbitrarily chooses one.\n        See _find_no_duplicates if you want an exception thrown if there are\n        conflicting cookies.\n\n        :param name: a string containing name of cookie\n        :param domain: (optional) string containing domain of cookie\n        :param path: (optional) string containing path of cookie\n        :return: cookie.value\n        \"\"\"\n        for cookie in iter(self):\n            if cookie.name == name:\n                if domain is None or cookie.domain == domain:\n                    if path is None or cookie.path == path:\n                        return cookie.value\n\n        raise KeyError(f\"name={name!r}, domain={domain!r}, path={path!r}\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_find_no_duplicates",
        "input": "Both ``__get_item__`` and ``get`` call this function: it's never\nused elsewhere in Requests.\n\n:param name: a string containing name of cookie\n:param domain: (optional) string containing domain of cookie\n:param path: (optional) string containing path of cookie\n:raises KeyError: if cookie is not found\n:raises CookieConflictError: if there are multiple cookies\n    that match name and optionally domain and path\n:return: cookie.value",
        "output": "def _find_no_duplicates(self, name, domain=None, path=None):\n        \"\"\"Both ``__get_item__`` and ``get`` call this function: it's never\n        used elsewhere in Requests.\n\n        :param name: a string containing name of cookie\n        :param domain: (optional) string containing domain of cookie\n        :param path: (optional) string containing path of cookie\n        :raises KeyError: if cookie is not found\n        :raises CookieConflictError: if there are multiple cookies\n            that match name and optionally domain and path\n        :return: cookie.value\n        \"\"\"\n        toReturn = None\n        for cookie in iter(self):\n            if cookie.name == name:\n                if domain is None or cookie.domain == domain:\n                    if path is None or cookie.path == path:\n                        if toReturn is not None:\n                            # if there are multiple cookies that meet passed in criteria\n                            raise CookieConflictError(\n                                f\"There are multiple cookies with name, {name!r}\"\n                            )\n                        # we will eventually return this as long as no cookie conflict\n                        toReturn = cookie.value\n\n        if toReturn:\n            return toReturn\n        raise KeyError(f\"name={name!r}, domain={domain!r}, path={path!r}\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__getstate__",
        "input": "Unlike a normal CookieJar, this class is pickleable.",
        "output": "def __getstate__(self):\n        \"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\n        state = self.__dict__.copy()\n        # remove the unpickleable RLock object\n        state.pop(\"_cookies_lock\")\n        return state"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__setstate__",
        "input": "Unlike a normal CookieJar, this class is pickleable.",
        "output": "def __setstate__(self, state):\n        \"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\n        self.__dict__.update(state)\n        if \"_cookies_lock\" not in self.__dict__:\n            self._cookies_lock = threading.RLock()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "copy",
        "input": "Return a copy of this RequestsCookieJar.",
        "output": "def copy(self):\n        \"\"\"Return a copy of this RequestsCookieJar.\"\"\"\n        new_cj = RequestsCookieJar()\n        new_cj.set_policy(self.get_policy())\n        new_cj.update(self)\n        return new_cj"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_policy",
        "input": "Return the CookiePolicy instance used.",
        "output": "def get_policy(self):\n        \"\"\"Return the CookiePolicy instance used.\"\"\"\n        return self._policy"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__init__",
        "input": "Initialize RequestException with `request` and `response` objects.",
        "output": "def __init__(self, *args, **kwargs):\n        \"\"\"Initialize RequestException with `request` and `response` objects.\"\"\"\n        response = kwargs.pop(\"response\", None)\n        self.response = response\n        self.request = kwargs.pop(\"request\", None)\n        if response is not None and not self.request and hasattr(response, \"request\"):\n            self.request = self.response.request\n        super().__init__(*args, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__init__",
        "input": "Construct the JSONDecodeError instance first with all\nargs. Then use it's args to construct the IOError so that\nthe json specific args aren't used as IOError specific args\nand the error message from JSONDecodeError is preserved.",
        "output": "def __init__(self, *args, **kwargs):\n        \"\"\"\n        Construct the JSONDecodeError instance first with all\n        args. Then use it's args to construct the IOError so that\n        the json specific args aren't used as IOError specific args\n        and the error message from JSONDecodeError is preserved.\n        \"\"\"\n        CompatJSONDecodeError.__init__(self, *args)\n        InvalidJSONError.__init__(self, *self.args, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__reduce__",
        "input": "The __reduce__ method called when pickling the object must\nbe the one from the JSONDecodeError (be it json/simplejson)\nas it expects all the arguments for instantiation, not just\none like the IOError, and the MRO would by default call the\n__reduce__ method from the IOError due to the inheritance order.",
        "output": "def __reduce__(self):\n        \"\"\"\n        The __reduce__ method called when pickling the object must\n        be the one from the JSONDecodeError (be it json/simplejson)\n        as it expects all the arguments for instantiation, not just\n        one like the IOError, and the MRO would by default call the\n        __reduce__ method from the IOError due to the inheritance order.\n        \"\"\"\n        return CompatJSONDecodeError.__reduce__(self)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_implementation",
        "input": "Return a dict with the Python implementation and version.\n\nProvide both the name and the version of the Python implementation\ncurrently running. For example, on CPython 3.10.3 it will return\n{'name': 'CPython', 'version': '3.10.3'}.\n\nThis function works best on CPython and PyPy: in particular, it probably\ndoesn't work for Jython or IronPython. Future investigation should be done\nto work out the correct shape of the code for those platforms.",
        "output": "def _implementation():\n    \"\"\"Return a dict with the Python implementation and version.\n\n    Provide both the name and the version of the Python implementation\n    currently running. For example, on CPython 3.10.3 it will return\n    {'name': 'CPython', 'version': '3.10.3'}.\n\n    This function works best on CPython and PyPy: in particular, it probably\n    doesn't work for Jython or IronPython. Future investigation should be done\n    to work out the correct shape of the code for those platforms.\n    \"\"\"\n    implementation = platform.python_implementation()\n\n    if implementation == \"CPython\":\n        implementation_version = platform.python_version()\n    elif implementation == \"PyPy\":\n        implementation_version = \"{}.{}.{}\".format(\n            sys.pypy_version_info.major,\n            sys.pypy_version_info.minor,\n            sys.pypy_version_info.micro,\n        )\n        if sys.pypy_version_info.releaselevel != \"final\":\n            implementation_version = \"\".join(\n                [implementation_version, sys.pypy_version_info.releaselevel]\n            )\n    elif implementation == \"Jython\":\n        implementation_version = platform.python_version()  # Complete Guess\n    elif implementation == \"IronPython\":\n        implementation_version = platform.python_version()  # Complete Guess\n    else:\n        implementation_version = \"Unknown\"\n\n    return {\"name\": implementation, \"version\": implementation_version}"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "info",
        "input": "Generate information for a bug report.",
        "output": "def info():\n    \"\"\"Generate information for a bug report.\"\"\"\n    try:\n        platform_info = {\n            \"system\": platform.system(),\n            \"release\": platform.release(),\n        }\n    except OSError:\n        platform_info = {\n            \"system\": \"Unknown\",\n            \"release\": \"Unknown\",\n        }\n\n    implementation_info = _implementation()\n    urllib3_info = {\"version\": urllib3.__version__}\n    charset_normalizer_info = {\"version\": None}\n    chardet_info = {\"version\": None}\n    if charset_normalizer:\n        charset_normalizer_info = {\"version\": charset_normalizer.__version__}\n    if chardet:\n        chardet_info = {\"version\": chardet.__version__}\n\n    pyopenssl_info = {\n        \"version\": None,\n        \"openssl_version\": \"\",\n    }\n    if OpenSSL:\n        pyopenssl_info = {\n            \"version\": OpenSSL.__version__,\n            \"openssl_version\": f\"{OpenSSL.SSL.OPENSSL_VERSION_NUMBER:x}\",\n        }\n    cryptography_info = {\n        \"version\": getattr(cryptography, \"__version__\", \"\"),\n    }\n    idna_info = {\n        \"version\": getattr(idna, \"__version__\", \"\"),\n    }\n\n    system_ssl = ssl.OPENSSL_VERSION_NUMBER\n    system_ssl_info = {\"version\": f\"{system_ssl:x}\" if system_ssl is not None else \"\"}\n\n    return {\n        \"platform\": platform_info,\n        \"implementation\": implementation_info,\n        \"system_ssl\": system_ssl_info,\n        \"using_pyopenssl\": pyopenssl is not None,\n        \"using_charset_normalizer\": chardet is None,\n        \"pyOpenSSL\": pyopenssl_info,\n        \"urllib3\": urllib3_info,\n        \"chardet\": chardet_info,\n        \"charset_normalizer\": charset_normalizer_info,\n        \"cryptography\": cryptography_info,\n        \"idna\": idna_info,\n        \"requests\": {\n            \"version\": requests_version,\n        },\n    }"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "main",
        "input": "Pretty-print the bug information as JSON.",
        "output": "def main():\n    \"\"\"Pretty-print the bug information as JSON.\"\"\"\n    print(json.dumps(info(), sort_keys=True, indent=2))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dispatch_hook",
        "input": "Dispatches a hook dictionary on a given piece of data.",
        "output": "def dispatch_hook(key, hooks, hook_data, **kwargs):\n    \"\"\"Dispatches a hook dictionary on a given piece of data.\"\"\"\n    hooks = hooks or {}\n    hooks = hooks.get(key)\n    if hooks:\n        if hasattr(hooks, \"__call__\"):\n            hooks = [hooks]\n        for hook in hooks:\n            _hook_data = hook(hook_data, **kwargs)\n            if _hook_data is not None:\n                hook_data = _hook_data\n    return hook_data"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "path_url",
        "input": "Build the path URL to use.",
        "output": "def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = \"/\"\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append(\"?\")\n            url.append(query)\n\n        return \"\".join(url)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_encode_params",
        "input": "Encode parameters in a piece of data.\n\nWill successfully encode parameters when passed as a dict or a list of\n2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\nif parameters are supplied as a dict.",
        "output": "def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, \"read\"):\n            return data\n        elif hasattr(data, \"__iter__\"):\n            result = []\n            for k, vs in to_key_val_list(data):\n                if isinstance(vs, basestring) or not hasattr(vs, \"__iter__\"):\n                    vs = [vs]\n                for v in vs:\n                    if v is not None:\n                        result.append(\n                            (\n                                k.encode(\"utf-8\") if isinstance(k, str) else k,\n                                v.encode(\"utf-8\") if isinstance(v, str) else v,\n                            )\n                        )\n            return urlencode(result, doseq=True)\n        else:\n            return data"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_encode_files",
        "input": "Build the body for a multipart/form-data request.\n\nWill successfully encode files when passed as a dict or a list of\ntuples. Order is retained if data is a list of tuples but arbitrary\nif parameters are supplied as a dict.\nThe tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\nor 4-tuples (filename, fileobj, contentype, custom_headers).",
        "output": "def _encode_files(files, data):\n        \"\"\"Build the body for a multipart/form-data request.\n\n        Will successfully encode files when passed as a dict or a list of\n        tuples. Order is retained if data is a list of tuples but arbitrary\n        if parameters are supplied as a dict.\n        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\n        or 4-tuples (filename, fileobj, contentype, custom_headers).\n        \"\"\"\n        if not files:\n            raise ValueError(\"Files must be provided.\")\n        elif isinstance(data, basestring):\n            raise ValueError(\"Data must not be a string.\")\n\n        new_fields = []\n        fields = to_key_val_list(data or {})\n        files = to_key_val_list(files or {})\n\n        for field, val in fields:\n            if isinstance(val, basestring) or not hasattr(val, \"__iter__\"):\n                val = [val]\n            for v in val:\n                if v is not None:\n                    # Don't call str() on bytestrings: in Py3 it all goes wrong.\n                    if not isinstance(v, bytes):\n                        v = str(v)\n\n                    new_fields.append(\n                        (\n                            field.decode(\"utf-8\")\n                            if isinstance(field, bytes)\n                            else field,\n                            v.encode(\"utf-8\") if isinstance(v, str) else v,\n                        )\n                    )\n\n        for k, v in files:\n            # support for explicit filename\n            ft = None\n            fh = None\n            if isinstance(v, (tuple, list)):\n                if len(v) == 2:\n                    fn, fp = v\n                elif len(v) == 3:\n                    fn, fp, ft = v\n                else:\n                    fn, fp, ft, fh = v\n            else:\n                fn = guess_filename(v) or k\n                fp = v\n\n            if isinstance(fp, (str, bytes, bytearray)):\n                fdata = fp\n            elif hasattr(fp, \"read\"):\n                fdata = fp.read()\n            elif fp is None:\n                continue\n            else:\n                fdata = fp\n\n            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n            rf.make_multipart(content_type=ft)\n            new_fields.append(rf)\n\n        body, content_type = encode_multipart_formdata(new_fields)\n\n        return body, content_type"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "register_hook",
        "input": "Properly register a hook.",
        "output": "def register_hook(self, event, hook):\n        \"\"\"Properly register a hook.\"\"\"\n\n        if event not in self.hooks:\n            raise ValueError(f'Unsupported event specified, with event name \"{event}\"')\n\n        if isinstance(hook, Callable):\n            self.hooks[event].append(hook)\n        elif hasattr(hook, \"__iter__\"):\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "deregister_hook",
        "input": "Deregister a previously registered hook.\nReturns True if the hook existed, False if not.",
        "output": "def deregister_hook(self, event, hook):\n        \"\"\"Deregister a previously registered hook.\n        Returns True if the hook existed, False if not.\n        \"\"\"\n\n        try:\n            self.hooks[event].remove(hook)\n            return True\n        except ValueError:\n            return False"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare",
        "input": "Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.",
        "output": "def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare",
        "input": "Prepares the entire request with the given parameters.",
        "output": "def prepare(\n        self,\n        method=None,\n        url=None,\n        headers=None,\n        files=None,\n        data=None,\n        params=None,\n        auth=None,\n        cookies=None,\n        hooks=None,\n        json=None,\n    ):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_method",
        "input": "Prepares the given HTTP method.",
        "output": "def prepare_method(self, method):\n        \"\"\"Prepares the given HTTP method.\"\"\"\n        self.method = method\n        if self.method is not None:\n            self.method = to_native_string(self.method.upper())"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_url",
        "input": "Prepares the given HTTP URL.",
        "output": "def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        #: Accept objects that have string representations.\n        #: We're unable to blindly call unicode/str functions\n        #: as this will include the bytestring indicator (b'')\n        #: on python 3.x.\n        #: https://github.com/psf/requests/pull/2238\n        if isinstance(url, bytes):\n            url = url.decode(\"utf8\")\n        else:\n            url = str(url)\n\n        # Remove leading whitespaces from url\n        url = url.lstrip()\n\n        # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n        # `data` etc to work around exceptions from `url_parse`, which\n        # handles RFC 3986 only.\n        if \":\" in url and not url.lower().startswith(\"http\"):\n            self.url = url\n            return\n\n        # Support for unicode domain names and paths.\n        try:\n            scheme, auth, host, port, path, query, fragment = parse_url(url)\n        except LocationParseError as e:\n            raise InvalidURL(*e.args)\n\n        if not scheme:\n            raise MissingSchema(\n                f\"Invalid URL {url!r}: No scheme supplied. \"\n                f\"Perhaps you meant https://{url}?\"\n            )\n\n        if not host:\n            raise InvalidURL(f\"Invalid URL {url!r}: No host supplied\")\n\n        # In general, we want to try IDNA encoding the hostname if the string contains\n        # non-ASCII characters. This allows users to automatically get the correct IDNA\n        # behaviour. For strings containing only ASCII characters, we need to also verify\n        # it doesn't start with a wildcard (*), before allowing the unencoded hostname.\n        if not unicode_is_ascii(host):\n            try:\n                host = self._get_idna_encoded_host(host)\n            except UnicodeError:\n                raise InvalidURL(\"URL has an invalid label.\")\n        elif host.startswith((\"*\", \".\")):\n            raise InvalidURL(\"URL has an invalid label.\")\n\n        # Carefully reconstruct the network location\n        netloc = auth or \"\"\n        if netloc:\n            netloc += \"@\"\n        netloc += host\n        if port:\n            netloc += f\":{port}\"\n\n        # Bare domains aren't valid URLs.\n        if not path:\n            path = \"/\"\n\n        if isinstance(params, (str, bytes)):\n            params = to_native_string(params)\n\n        enc_params = self._encode_params(params)\n        if enc_params:\n            if query:\n                query = f\"{query}&{enc_params}\"\n            else:\n                query = enc_params\n\n        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n        self.url = url"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_headers",
        "input": "Prepares the given HTTP headers.",
        "output": "def prepare_headers(self, headers):\n        \"\"\"Prepares the given HTTP headers.\"\"\"\n\n        self.headers = CaseInsensitiveDict()\n        if headers:\n            for header in headers.items():\n                # Raise exception on invalid header value.\n                check_header_validity(header)\n                name, value = header\n                self.headers[to_native_string(name)] = value"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_body",
        "input": "Prepares the given HTTP body data.",
        "output": "def prepare_body(self, data, files, json=None):\n        \"\"\"Prepares the given HTTP body data.\"\"\"\n\n        # Check if file, fo, generator, iterator.\n        # If not, run through normal process.\n\n        # Nottin' on you.\n        body = None\n        content_type = None\n\n        if not data and json is not None:\n            # urllib3 requires a bytes-like body. Python 2's json.dumps\n            # provides this natively, but Python 3 gives a Unicode string.\n            content_type = \"application/json\"\n\n            try:\n                body = complexjson.dumps(json, allow_nan=False)\n            except ValueError as ve:\n                raise InvalidJSONError(ve, request=self)\n\n            if not isinstance(body, bytes):\n                body = body.encode(\"utf-8\")\n\n        is_stream = all(\n            [\n                hasattr(data, \"__iter__\"),\n                not isinstance(data, (basestring, list, tuple, Mapping)),\n            ]\n        )\n\n        if is_stream:\n            try:\n                length = super_len(data)\n            except (TypeError, AttributeError, UnsupportedOperation):\n                length = None\n\n            body = data\n\n            if getattr(body, \"tell\", None) is not None:\n                # Record the current file position before reading.\n                # This will allow us to rewind a file in the event\n                # of a redirect.\n                try:\n                    self._body_position = body.tell()\n                except OSError:\n                    # This differentiates from None, allowing us to catch\n                    # a failed `tell()` later when trying to rewind the body\n                    self._body_position = object()\n\n            if files:\n                raise NotImplementedError(\n                    \"Streamed bodies and files are mutually exclusive.\"\n                )\n\n            if length:\n                self.headers[\"Content-Length\"] = builtin_str(length)\n            else:\n                self.headers[\"Transfer-Encoding\"] = \"chunked\"\n        else:\n            # Multi-part file uploads.\n            if files:\n                (body, content_type) = self._encode_files(files, data)\n            else:\n                if data:\n                    body = self._encode_params(data)\n                    if isinstance(data, basestring) or hasattr(data, \"read\"):\n                        content_type = None\n                    else:\n                        content_type = \"application/x-www-form-urlencoded\"\n\n            self.prepare_content_length(body)\n\n            # Add content-type if it wasn't explicitly provided.\n            if content_type and (\"content-type\" not in self.headers):\n                self.headers[\"Content-Type\"] = content_type\n\n        self.body = body"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_content_length",
        "input": "Prepare Content-Length header based on request method and body",
        "output": "def prepare_content_length(self, body):\n        \"\"\"Prepare Content-Length header based on request method and body\"\"\"\n        if body is not None:\n            length = super_len(body)\n            if length:\n                # If length exists, set it. Otherwise, we fallback\n                # to Transfer-Encoding: chunked.\n                self.headers[\"Content-Length\"] = builtin_str(length)\n        elif (\n            self.method not in (\"GET\", \"HEAD\")\n            and self.headers.get(\"Content-Length\") is None\n        ):\n            # Set Content-Length to 0 for methods that can have a body\n            # but don't provide one. (i.e. not GET or HEAD)\n            self.headers[\"Content-Length\"] = \"0\""
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_auth",
        "input": "Prepares the given HTTP auth data.",
        "output": "def prepare_auth(self, auth, url=\"\"):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth is explicitly provided, extract it from the URL first.\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            if isinstance(auth, tuple) and len(auth) == 2:\n                # special-case basic HTTP auth\n                auth = HTTPBasicAuth(*auth)\n\n            # Allow auth to make its changes.\n            r = auth(self)\n\n            # Update self to reflect the auth changes.\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length\n            self.prepare_content_length(self.body)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_cookies",
        "input": "Prepares the given HTTP cookie data.\n\nThis function eventually generates a ``Cookie`` header from the\ngiven cookies using cookielib. Due to cookielib's design, the header\nwill not be regenerated if it already exists, meaning this function\ncan only be called once for the life of the\n:class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\nto ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\nheader is removed beforehand.",
        "output": "def prepare_cookies(self, cookies):\n        \"\"\"Prepares the given HTTP cookie data.\n\n        This function eventually generates a ``Cookie`` header from the\n        given cookies using cookielib. Due to cookielib's design, the header\n        will not be regenerated if it already exists, meaning this function\n        can only be called once for the life of the\n        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\n        to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\n        header is removed beforehand.\n        \"\"\"\n        if isinstance(cookies, cookielib.CookieJar):\n            self._cookies = cookies\n        else:\n            self._cookies = cookiejar_from_dict(cookies)\n\n        cookie_header = get_cookie_header(self._cookies, self)\n        if cookie_header is not None:\n            self.headers[\"Cookie\"] = cookie_header"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_hooks",
        "input": "Prepares the given hooks.",
        "output": "def prepare_hooks(self, hooks):\n        \"\"\"Prepares the given hooks.\"\"\"\n        # hooks can be passed as None to the prepare method and to this\n        # method. To prevent iterating over None, simply use an empty list\n        # if hooks is False-y\n        hooks = hooks or []\n        for event in hooks:\n            self.register_hook(event, hooks[event])"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__bool__",
        "input": "Returns True if :attr:`status_code` is less than 400.\n\nThis attribute checks if the status code of the response is between\n400 and 600 to see if there was a client error or a server error. If\nthe status code, is between 200 and 400, this will return True. This\nis **not** a check to see if the response code is ``200 OK``.",
        "output": "def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__nonzero__",
        "input": "Returns True if :attr:`status_code` is less than 400.\n\nThis attribute checks if the status code of the response is between\n400 and 600 to see if there was a client error or a server error. If\nthe status code, is between 200 and 400, this will return True. This\nis **not** a check to see if the response code is ``200 OK``.",
        "output": "def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__iter__",
        "input": "Allows you to use a response as an iterator.",
        "output": "def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "ok",
        "input": "Returns True if :attr:`status_code` is less than 400, False if not.\n\nThis attribute checks if the status code of the response is between\n400 and 600 to see if there was a client error or a server error. If\nthe status code is between 200 and 400, this will return True. This\nis **not** a check to see if the response code is ``200 OK``.",
        "output": "def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, False if not.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        try:\n            self.raise_for_status()\n        except HTTPError:\n            return False\n        return True"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "is_redirect",
        "input": "True if this Response is a well-formed HTTP redirect that could have\nbeen processed automatically (by :meth:`Session.resolve_redirects`).",
        "output": "def is_redirect(self):\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\n        been processed automatically (by :meth:`Session.resolve_redirects`).\n        \"\"\"\n        return \"location\" in self.headers and self.status_code in REDIRECT_STATI"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "is_permanent_redirect",
        "input": "True if this Response one of the permanent versions of redirect.",
        "output": "def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return \"location\" in self.headers and self.status_code in (\n            codes.moved_permanently,\n            codes.permanent_redirect,\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "next",
        "input": "Returns a PreparedRequest for the next request in a redirect chain, if there is one.",
        "output": "def next(self):\n        \"\"\"Returns a PreparedRequest for the next request in a redirect chain, if there is one.\"\"\"\n        return self._next"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "apparent_encoding",
        "input": "The apparent encoding, provided by the charset_normalizer or chardet libraries.",
        "output": "def apparent_encoding(self):\n        \"\"\"The apparent encoding, provided by the charset_normalizer or chardet libraries.\"\"\"\n        if chardet is not None:\n            return chardet.detect(self.content)[\"encoding\"]\n        else:\n            # If no character detection library is available, we'll fall back\n            # to a standard Python utf-8 str.\n            return \"utf-8\""
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "iter_content",
        "input": "Iterates over the response data.  When stream=True is set on the\nrequest, this avoids reading the content at once into memory for\nlarge responses.  The chunk size is the number of bytes it should\nread into memory.  This is not necessarily the length of each item\nreturned as decoding can take place.\n\nchunk_size must be of type int or None. A value of None will\nfunction differently depending on the value of `stream`.\nstream=True will read data as it arrives in whatever size the\nchunks are received. If stream=False, data is returned as\na single chunk.\n\nIf decode_unicode is True, content will be decoded using the best\navailable encoding based on the response.",
        "output": "def iter_content(self, chunk_size=1, decode_unicode=False):\n        \"\"\"Iterates over the response data.  When stream=True is set on the\n        request, this avoids reading the content at once into memory for\n        large responses.  The chunk size is the number of bytes it should\n        read into memory.  This is not necessarily the length of each item\n        returned as decoding can take place.\n\n        chunk_size must be of type int or None. A value of None will\n        function differently depending on the value of `stream`.\n        stream=True will read data as it arrives in whatever size the\n        chunks are received. If stream=False, data is returned as\n        a single chunk.\n\n        If decode_unicode is True, content will be decoded using the best\n        available encoding based on the response.\n        \"\"\"\n\n        def generate():\n            # Special case for urllib3.\n            if hasattr(self.raw, \"stream\"):\n                try:\n                    yield from self.raw.stream(chunk_size, decode_content=True)\n                except ProtocolError as e:\n                    raise ChunkedEncodingError(e)\n                except DecodeError as e:\n                    raise ContentDecodingError(e)\n                except ReadTimeoutError as e:\n                    raise ConnectionError(e)\n                except SSLError as e:\n                    raise RequestsSSLError(e)\n            else:\n                # Standard file-like object.\n                while True:\n                    chunk = self.raw.read(chunk_size)\n                    if not chunk:\n                        break\n                    yield chunk\n\n            self._content_consumed = True\n\n        if self._content_consumed and isinstance(self._content, bool):\n            raise StreamConsumedError()\n        elif chunk_size is not None and not isinstance(chunk_size, int):\n            raise TypeError(\n                f\"chunk_size must be an int, it is instead a {type(chunk_size)}.\"\n            )\n        # simulate reading small chunks of the content\n        reused_chunks = iter_slices(self._content, chunk_size)\n\n        stream_chunks = generate()\n\n        chunks = reused_chunks if self._content_consumed else stream_chunks\n\n        if decode_unicode:\n            chunks = stream_decode_response_unicode(chunks, self)\n\n        return chunks"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "iter_lines",
        "input": "Iterates over the response data, one line at a time.  When\nstream=True is set on the request, this avoids reading the\ncontent at once into memory for large responses.\n\n.. note:: This method is not reentrant safe.",
        "output": "def iter_lines(\n        self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None\n    ):\n        \"\"\"Iterates over the response data, one line at a time.  When\n        stream=True is set on the request, this avoids reading the\n        content at once into memory for large responses.\n\n        .. note:: This method is not reentrant safe.\n        \"\"\"\n\n        pending = None\n\n        for chunk in self.iter_content(\n            chunk_size=chunk_size, decode_unicode=decode_unicode\n        ):\n            if pending is not None:\n                chunk = pending + chunk\n\n            if delimiter:\n                lines = chunk.split(delimiter)\n            else:\n                lines = chunk.splitlines()\n\n            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\n                pending = lines.pop()\n            else:\n                pending = None\n\n            yield from lines\n\n        if pending is not None:\n            yield pending"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "content",
        "input": "Content of the response, in bytes.",
        "output": "def content(self):\n        \"\"\"Content of the response, in bytes.\"\"\"\n\n        if self._content is False:\n            # Read the contents.\n            if self._content_consumed:\n                raise RuntimeError(\"The content for this response was already consumed\")\n\n            if self.status_code == 0 or self.raw is None:\n                self._content = None\n            else:\n                self._content = b\"\".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b\"\"\n\n        self._content_consumed = True\n        # don't need to release the connection; that's been handled by urllib3\n        # since we exhausted the data.\n        return self._content"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "text",
        "input": "Content of the response, in unicode.\n\nIf Response.encoding is None, encoding will be guessed using\n``charset_normalizer`` or ``chardet``.\n\nThe encoding of the response content is determined based solely on HTTP\nheaders, following RFC 2616 to the letter. If you can take advantage of\nnon-HTTP knowledge to make a better guess at the encoding, you should\nset ``r.encoding`` appropriately before accessing this property.",
        "output": "def text(self):\n        \"\"\"Content of the response, in unicode.\n\n        If Response.encoding is None, encoding will be guessed using\n        ``charset_normalizer`` or ``chardet``.\n\n        The encoding of the response content is determined based solely on HTTP\n        headers, following RFC 2616 to the letter. If you can take advantage of\n        non-HTTP knowledge to make a better guess at the encoding, you should\n        set ``r.encoding`` appropriately before accessing this property.\n        \"\"\"\n\n        # Try charset from content-type\n        content = None\n        encoding = self.encoding\n\n        if not self.content:\n            return \"\"\n\n        # Fallback to auto-detected encoding.\n        if self.encoding is None:\n            encoding = self.apparent_encoding\n\n        # Decode unicode from given encoding.\n        try:\n            content = str(self.content, encoding, errors=\"replace\")\n        except (LookupError, TypeError):\n            # A LookupError is raised if the encoding was not found which could\n            # indicate a misspelling or similar mistake.\n            #\n            # A TypeError can be raised if encoding is None\n            #\n            # So we try blindly encoding.\n            content = str(self.content, errors=\"replace\")\n\n        return content"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "json",
        "input": "Decodes the JSON response body (if any) as a Python object.\n\nThis may return a dictionary, list, etc. depending on what is in the response.\n\n:param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n:raises requests.exceptions.JSONDecodeError: If the response body does not\n    contain valid json.",
        "output": "def json(self, **kwargs):\n        r\"\"\"Decodes the JSON response body (if any) as a Python object.\n\n        This may return a dictionary, list, etc. depending on what is in the response.\n\n        :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n        :raises requests.exceptions.JSONDecodeError: If the response body does not\n            contain valid json.\n        \"\"\"\n\n        if not self.encoding and self.content and len(self.content) > 3:\n            # No encoding set. JSON RFC 4627 section 3 states we should expect\n            # UTF-8, -16 or -32. Detect which one to use; If the detection or\n            # decoding fails, fall back to `self.text` (using charset_normalizer to make\n            # a best guess).\n            encoding = guess_json_utf(self.content)\n            if encoding is not None:\n                try:\n                    return complexjson.loads(self.content.decode(encoding), **kwargs)\n                except UnicodeDecodeError:\n                    # Wrong UTF codec detected; usually because it's not UTF-8\n                    # but some other 8-bit codec.  This is an RFC violation,\n                    # and the server didn't bother to tell us what codec *was*\n                    # used.\n                    pass\n                except JSONDecodeError as e:\n                    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n\n        try:\n            return complexjson.loads(self.text, **kwargs)\n        except JSONDecodeError as e:\n            # Catch JSON-related errors and raise as requests.JSONDecodeError\n            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n            raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "links",
        "input": "Returns the parsed header links of the response, if any.",
        "output": "def links(self):\n        \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n\n        header = self.headers.get(\"link\")\n\n        resolved_links = {}\n\n        if header:\n            links = parse_header_links(header)\n\n            for link in links:\n                key = link.get(\"rel\") or link.get(\"url\")\n                resolved_links[key] = link\n\n        return resolved_links"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "raise_for_status",
        "input": "Raises :class:`HTTPError`, if one occurred.",
        "output": "def raise_for_status(self):\n        \"\"\"Raises :class:`HTTPError`, if one occurred.\"\"\"\n\n        http_error_msg = \"\"\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode(\"utf-8\")\n            except UnicodeDecodeError:\n                reason = self.reason.decode(\"iso-8859-1\")\n        else:\n            reason = self.reason\n\n        if 400 <= self.status_code < 500:\n            http_error_msg = (\n                f\"{self.status_code} Client Error: {reason} for url: {self.url}\"\n            )\n\n        elif 500 <= self.status_code < 600:\n            http_error_msg = (\n                f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\n            )\n\n        if http_error_msg:\n            raise HTTPError(http_error_msg, response=self)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "close",
        "input": "Releases the connection back to the pool. Once this method has been\ncalled the underlying ``raw`` object must not be accessed again.\n\n*Note: Should not normally need to be called explicitly.*",
        "output": "def close(self):\n        \"\"\"Releases the connection back to the pool. Once this method has been\n        called the underlying ``raw`` object must not be accessed again.\n\n        *Note: Should not normally need to be called explicitly.*\n        \"\"\"\n        if not self._content_consumed:\n            self.raw.close()\n\n        release_conn = getattr(self.raw, \"release_conn\", None)\n        if release_conn is not None:\n            release_conn()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "merge_setting",
        "input": "Determines appropriate setting for a given request, taking into account\nthe explicit setting on that request, and the setting in the session. If a\nsetting is a dictionary, they will be merged together using `dict_class`",
        "output": "def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n    \"\"\"Determines appropriate setting for a given request, taking into account\n    the explicit setting on that request, and the setting in the session. If a\n    setting is a dictionary, they will be merged together using `dict_class`\n    \"\"\"\n\n    if session_setting is None:\n        return request_setting\n\n    if request_setting is None:\n        return session_setting\n\n    # Bypass if not a dictionary (e.g. verify)\n    if not (\n        isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)\n    ):\n        return request_setting\n\n    merged_setting = dict_class(to_key_val_list(session_setting))\n    merged_setting.update(to_key_val_list(request_setting))\n\n    # Remove keys that are set to None. Extract keys first to avoid altering\n    # the dictionary during iteration.\n    none_keys = [k for (k, v) in merged_setting.items() if v is None]\n    for key in none_keys:\n        del merged_setting[key]\n\n    return merged_setting"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "merge_hooks",
        "input": "Properly merges both requests and session hooks.\n\nThis is necessary because when request_hooks == {'response': []}, the\nmerge breaks Session hooks entirely.",
        "output": "def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n    \"\"\"Properly merges both requests and session hooks.\n\n    This is necessary because when request_hooks == {'response': []}, the\n    merge breaks Session hooks entirely.\n    \"\"\"\n    if session_hooks is None or session_hooks.get(\"response\") == []:\n        return request_hooks\n\n    if request_hooks is None or request_hooks.get(\"response\") == []:\n        return session_hooks\n\n    return merge_setting(request_hooks, session_hooks, dict_class)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "session",
        "input": "Returns a :class:`Session` for context-management.\n\n.. deprecated:: 1.0.0\n\n    This method has been deprecated since version 1.0.0 and is only kept for\n    backwards compatibility. New code should use :class:`~requests.sessions.Session`\n    to create a session. This may be removed at a future date.\n\n:rtype: Session",
        "output": "def session():\n    \"\"\"\n    Returns a :class:`Session` for context-management.\n\n    .. deprecated:: 1.0.0\n\n        This method has been deprecated since version 1.0.0 and is only kept for\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\n        to create a session. This may be removed at a future date.\n\n    :rtype: Session\n    \"\"\"\n    return Session()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_redirect_target",
        "input": "Receives a Response. Returns a redirect URI or ``None``",
        "output": "def get_redirect_target(self, resp):\n        \"\"\"Receives a Response. Returns a redirect URI or ``None``\"\"\"\n        # Due to the nature of how requests processes redirects this method will\n        # be called at least once upon the original response and at least twice\n        # on each subsequent redirect response (if any).\n        # If a custom mixin is used to handle this logic, it may be advantageous\n        # to cache the redirect location onto the response object as a private\n        # attribute.\n        if resp.is_redirect:\n            location = resp.headers[\"location\"]\n            # Currently the underlying http module on py3 decode headers\n            # in latin1, but empirical evidence suggests that latin1 is very\n            # rarely used with non-ASCII characters in HTTP headers.\n            # It is more likely to get UTF8 header rather than latin1.\n            # This causes incorrect handling of UTF8 encoded location headers.\n            # To solve this, we re-encode the location in latin1.\n            location = location.encode(\"latin1\")\n            return to_native_string(location, \"utf8\")\n        return None"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "should_strip_auth",
        "input": "Decide whether Authorization header should be removed when redirecting",
        "output": "def should_strip_auth(self, old_url, new_url):\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\n        old_parsed = urlparse(old_url)\n        new_parsed = urlparse(new_url)\n        if old_parsed.hostname != new_parsed.hostname:\n            return True\n        # Special case: allow http -> https redirect when using the standard\n        # ports. This isn't specified by RFC 7235, but is kept to avoid\n        # breaking backwards compatibility with older versions of requests\n        # that allowed any redirects on the same host.\n        if (\n            old_parsed.scheme == \"http\"\n            and old_parsed.port in (80, None)\n            and new_parsed.scheme == \"https\"\n            and new_parsed.port in (443, None)\n        ):\n            return False\n\n        # Handle default port usage corresponding to scheme.\n        changed_port = old_parsed.port != new_parsed.port\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\n        if (\n            not changed_scheme\n            and old_parsed.port in default_port\n            and new_parsed.port in default_port\n        ):\n            return False\n\n        # Standard case: root URI must match\n        return changed_port or changed_scheme"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "resolve_redirects",
        "input": "Receives a Response. Returns a generator of Responses or Requests.",
        "output": "def resolve_redirects(\n        self,\n        resp,\n        req,\n        stream=False,\n        timeout=None,\n        verify=True,\n        cert=None,\n        proxies=None,\n        yield_requests=False,\n        **adapter_kwargs,\n    ):\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\n\n        hist = []  # keep track of history\n\n        url = self.get_redirect_target(resp)\n        previous_fragment = urlparse(req.url).fragment\n        while url:\n            prepared_request = req.copy()\n\n            # Update history and keep track of redirects.\n            # resp.history must ignore the original request in this loop\n            hist.append(resp)\n            resp.history = hist[1:]\n\n            try:\n                resp.content  # Consume socket so it can be released\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n                resp.raw.read(decode_content=False)\n\n            if len(resp.history) >= self.max_redirects:\n                raise TooManyRedirects(\n                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\n                )\n\n            # Release the connection back into the pool.\n            resp.close()\n\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\n            if url.startswith(\"//\"):\n                parsed_rurl = urlparse(resp.url)\n                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\n\n            # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)\n            parsed = urlparse(url)\n            if parsed.fragment == \"\" and previous_fragment:\n                parsed = parsed._replace(fragment=previous_fragment)\n            elif parsed.fragment:\n                previous_fragment = parsed.fragment\n            url = parsed.geturl()\n\n            # Facilitate relative 'location' headers, as allowed by RFC 7231.\n            # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n            # Compliant with RFC3986, we percent encode the url.\n            if not parsed.netloc:\n                url = urljoin(resp.url, requote_uri(url))\n            else:\n                url = requote_uri(url)\n\n            prepared_request.url = to_native_string(url)\n\n            self.rebuild_method(prepared_request, resp)\n\n            # https://github.com/psf/requests/issues/1084\n            if resp.status_code not in (\n                codes.temporary_redirect,\n                codes.permanent_redirect,\n            ):\n                # https://github.com/psf/requests/issues/3490\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\n                for header in purged_headers:\n                    prepared_request.headers.pop(header, None)\n                prepared_request.body = None\n\n            headers = prepared_request.headers\n            headers.pop(\"Cookie\", None)\n\n            # Extract any cookies sent on the response to the cookiejar\n            # in the new request. Because we've mutated our copied prepared\n            # request, use the old one that we haven't yet touched.\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n            merge_cookies(prepared_request._cookies, self.cookies)\n            prepared_request.prepare_cookies(prepared_request._cookies)\n\n            # Rebuild auth and proxy information.\n            proxies = self.rebuild_proxies(prepared_request, proxies)\n            self.rebuild_auth(prepared_request, resp)\n\n            # A failed tell() sets `_body_position` to `object()`. This non-None\n            # value ensures `rewindable` will be True, allowing us to raise an\n            # UnrewindableBodyError, instead of hanging the connection.\n            rewindable = prepared_request._body_position is not None and (\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\n            )\n\n            # Attempt to rewind consumed file-like object.\n            if rewindable:\n                rewind_body(prepared_request)\n\n            # Override the original request.\n            req = prepared_request\n\n            if yield_requests:\n                yield req\n            else:\n                resp = self.send(\n                    req,\n                    stream=stream,\n                    timeout=timeout,\n                    verify=verify,\n                    cert=cert,\n                    proxies=proxies,\n                    allow_redirects=False,\n                    **adapter_kwargs,\n                )\n\n                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n\n                # extract redirect url, if any, for the next loop\n                url = self.get_redirect_target(resp)\n                yield resp"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "rebuild_auth",
        "input": "When being redirected we may want to strip authentication from the\nrequest to avoid leaking credentials. This method intelligently removes\nand reapplies authentication where possible to avoid credential loss.",
        "output": "def rebuild_auth(self, prepared_request, response):\n        \"\"\"When being redirected we may want to strip authentication from the\n        request to avoid leaking credentials. This method intelligently removes\n        and reapplies authentication where possible to avoid credential loss.\n        \"\"\"\n        headers = prepared_request.headers\n        url = prepared_request.url\n\n        if \"Authorization\" in headers and self.should_strip_auth(\n            response.request.url, url\n        ):\n            # If we get redirected to a new host, we should strip out any\n            # authentication headers.\n            del headers[\"Authorization\"]\n\n        # .netrc might have more auth for us on our new host.\n        new_auth = get_netrc_auth(url) if self.trust_env else None\n        if new_auth is not None:\n            prepared_request.prepare_auth(new_auth)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "rebuild_proxies",
        "input": "This method re-evaluates the proxy configuration by considering the\nenvironment variables. If we are redirected to a URL covered by\nNO_PROXY, we strip the proxy configuration. Otherwise, we set missing\nproxy keys for this URL (in case they were stripped by a previous\nredirect).\n\nThis method also replaces the Proxy-Authorization header where\nnecessary.\n\n:rtype: dict",
        "output": "def rebuild_proxies(self, prepared_request, proxies):\n        \"\"\"This method re-evaluates the proxy configuration by considering the\n        environment variables. If we are redirected to a URL covered by\n        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n        proxy keys for this URL (in case they were stripped by a previous\n        redirect).\n\n        This method also replaces the Proxy-Authorization header where\n        necessary.\n\n        :rtype: dict\n        \"\"\"\n        headers = prepared_request.headers\n        scheme = urlparse(prepared_request.url).scheme\n        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)\n\n        if \"Proxy-Authorization\" in headers:\n            del headers[\"Proxy-Authorization\"]\n\n        try:\n            username, password = get_auth_from_url(new_proxies[scheme])\n        except KeyError:\n            username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith(\"https\") and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "rebuild_method",
        "input": "When being redirected we may want to change the method of the request\nbased on certain specs or browser behavior.",
        "output": "def rebuild_method(self, prepared_request, response):\n        \"\"\"When being redirected we may want to change the method of the request\n        based on certain specs or browser behavior.\n        \"\"\"\n        method = prepared_request.method\n\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\n        if response.status_code == codes.see_other and method != \"HEAD\":\n            method = \"GET\"\n\n        # Do what the browsers do, despite standards...\n        # First, turn 302s into GETs.\n        if response.status_code == codes.found and method != \"HEAD\":\n            method = \"GET\"\n\n        # Second, if a POST is responded to with a 301, turn it into a GET.\n        # This bizarre behaviour is explained in Issue 1704.\n        if response.status_code == codes.moved and method == \"POST\":\n            method = \"GET\"\n\n        prepared_request.method = method"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_request",
        "input": "Constructs a :class:`PreparedRequest <PreparedRequest>` for\ntransmission and returns it. The :class:`PreparedRequest` has settings\nmerged from the :class:`Request <Request>` instance and those of the\n:class:`Session`.\n\n:param request: :class:`Request` instance to prepare with this\n    session's settings.\n:rtype: requests.PreparedRequest",
        "output": "def prepare_request(self, request):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n        transmission and returns it. The :class:`PreparedRequest` has settings\n        merged from the :class:`Request <Request>` instance and those of the\n        :class:`Session`.\n\n        :param request: :class:`Request` instance to prepare with this\n            session's settings.\n        :rtype: requests.PreparedRequest\n        \"\"\"\n        cookies = request.cookies or {}\n\n        # Bootstrap CookieJar.\n        if not isinstance(cookies, cookielib.CookieJar):\n            cookies = cookiejar_from_dict(cookies)\n\n        # Merge with session cookies\n        merged_cookies = merge_cookies(\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\n        )\n\n        # Set environment's basic authentication if not explicitly set.\n        auth = request.auth\n        if self.trust_env and not auth and not self.auth:\n            auth = get_netrc_auth(request.url)\n\n        p = PreparedRequest()\n        p.prepare(\n            method=request.method.upper(),\n            url=request.url,\n            files=request.files,\n            data=request.data,\n            json=request.json,\n            headers=merge_setting(\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\n            ),\n            params=merge_setting(request.params, self.params),\n            auth=merge_setting(auth, self.auth),\n            cookies=merged_cookies,\n            hooks=merge_hooks(request.hooks, self.hooks),\n        )\n        return p"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "request",
        "input": "Constructs a :class:`Request <Request>`, prepares it and sends it.\nReturns :class:`Response <Response>` object.\n\n:param method: method for the new :class:`Request` object.\n:param url: URL for the new :class:`Request` object.\n:param params: (optional) Dictionary or bytes to be sent in the query\n    string for the :class:`Request`.\n:param data: (optional) Dictionary, list of tuples, bytes, or file-like\n    object to send in the body of the :class:`Request`.\n:param json: (optional) json to send in the body of the\n    :class:`Request`.\n:param headers: (optional) Dictionary of HTTP Headers to send with the\n    :class:`Request`.\n:param cookies: (optional) Dict or CookieJar object to send with the\n    :class:`Request`.\n:param files: (optional) Dictionary of ``'filename': file-like-objects``\n    for multipart encoding upload.\n:param auth: (optional) Auth tuple or callable to enable\n    Basic/Digest/Custom HTTP Auth.\n:param timeout: (optional) How long to wait for the server to send\n    data before giving up, as a float, or a :ref:`(connect timeout,\n    read timeout) <timeouts>` tuple.\n:type timeout: float or tuple\n:param allow_redirects: (optional) Set to True by default.\n:type allow_redirects: bool\n:param proxies: (optional) Dictionary mapping protocol or protocol and\n    hostname to the URL of the proxy.\n:param hooks: (optional) Dictionary mapping hook name to one event or\n    list of events, event must be callable.\n:param stream: (optional) whether to immediately download the response\n    content. Defaults to ``False``.\n:param verify: (optional) Either a boolean, in which case it controls whether we verify\n    the server's TLS certificate, or a string, in which case it must be a path\n    to a CA bundle to use. Defaults to ``True``. When set to\n    ``False``, requests will accept any TLS certificate presented by\n    the server, and will ignore hostname mismatches and/or expired\n    certificates, which will make your application vulnerable to\n    man-in-the-middle (MitM) attacks. Setting verify to ``False``\n    may be useful during local development or testing.\n:param cert: (optional) if String, path to ssl client cert file (.pem).\n    If Tuple, ('cert', 'key') pair.\n:rtype: requests.Response",
        "output": "def request(\n        self,\n        method,\n        url,\n        params=None,\n        data=None,\n        headers=None,\n        cookies=None,\n        files=None,\n        auth=None,\n        timeout=None,\n        allow_redirects=True,\n        proxies=None,\n        hooks=None,\n        stream=None,\n        verify=None,\n        cert=None,\n        json=None,\n    ):\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n        Returns :class:`Response <Response>` object.\n\n        :param method: method for the new :class:`Request` object.\n        :param url: URL for the new :class:`Request` object.\n        :param params: (optional) Dictionary or bytes to be sent in the query\n            string for the :class:`Request`.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the\n            :class:`Request`.\n        :param headers: (optional) Dictionary of HTTP Headers to send with the\n            :class:`Request`.\n        :param cookies: (optional) Dict or CookieJar object to send with the\n            :class:`Request`.\n        :param files: (optional) Dictionary of ``'filename': file-like-objects``\n            for multipart encoding upload.\n        :param auth: (optional) Auth tuple or callable to enable\n            Basic/Digest/Custom HTTP Auth.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param allow_redirects: (optional) Set to True by default.\n        :type allow_redirects: bool\n        :param proxies: (optional) Dictionary mapping protocol or protocol and\n            hostname to the URL of the proxy.\n        :param hooks: (optional) Dictionary mapping hook name to one event or\n            list of events, event must be callable.\n        :param stream: (optional) whether to immediately download the response\n            content. Defaults to ``False``.\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use. Defaults to ``True``. When set to\n            ``False``, requests will accept any TLS certificate presented by\n            the server, and will ignore hostname mismatches and/or expired\n            certificates, which will make your application vulnerable to\n            man-in-the-middle (MitM) attacks. Setting verify to ``False``\n            may be useful during local development or testing.\n        :param cert: (optional) if String, path to ssl client cert file (.pem).\n            If Tuple, ('cert', 'key') pair.\n        :rtype: requests.Response\n        \"\"\"\n        # Create the Request.\n        req = Request(\n            method=method.upper(),\n            url=url,\n            headers=headers,\n            files=files,\n            data=data or {},\n            json=json,\n            params=params or {},\n            auth=auth,\n            cookies=cookies,\n            hooks=hooks,\n        )\n        prep = self.prepare_request(req)\n\n        proxies = proxies or {}\n\n        settings = self.merge_environment_settings(\n            prep.url, proxies, stream, verify, cert\n        )\n\n        # Send the request.\n        send_kwargs = {\n            \"timeout\": timeout,\n            \"allow_redirects\": allow_redirects,\n        }\n        send_kwargs.update(settings)\n        resp = self.send(prep, **send_kwargs)\n\n        return resp"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get",
        "input": "Sends a GET request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:rtype: requests.Response",
        "output": "def get(self, url, **kwargs):\n        r\"\"\"Sends a GET request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"GET\", url, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "options",
        "input": "Sends a OPTIONS request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:rtype: requests.Response",
        "output": "def options(self, url, **kwargs):\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", True)\n        return self.request(\"OPTIONS\", url, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "head",
        "input": "Sends a HEAD request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:rtype: requests.Response",
        "output": "def head(self, url, **kwargs):\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        kwargs.setdefault(\"allow_redirects\", False)\n        return self.request(\"HEAD\", url, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "post",
        "input": "Sends a POST request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param data: (optional) Dictionary, list of tuples, bytes, or file-like\n    object to send in the body of the :class:`Request`.\n:param json: (optional) json to send in the body of the :class:`Request`.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:rtype: requests.Response",
        "output": "def post(self, url, data=None, json=None, **kwargs):\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "put",
        "input": "Sends a PUT request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param data: (optional) Dictionary, list of tuples, bytes, or file-like\n    object to send in the body of the :class:`Request`.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:rtype: requests.Response",
        "output": "def put(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PUT\", url, data=data, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "patch",
        "input": "Sends a PATCH request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param data: (optional) Dictionary, list of tuples, bytes, or file-like\n    object to send in the body of the :class:`Request`.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:rtype: requests.Response",
        "output": "def patch(self, url, data=None, **kwargs):\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\n            object to send in the body of the :class:`Request`.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"PATCH\", url, data=data, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "delete",
        "input": "Sends a DELETE request. Returns :class:`Response` object.\n\n:param url: URL for the new :class:`Request` object.\n:param \\*\\*kwargs: Optional arguments that ``request`` takes.\n:rtype: requests.Response",
        "output": "def delete(self, url, **kwargs):\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\n\n        :param url: URL for the new :class:`Request` object.\n        :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n        :rtype: requests.Response\n        \"\"\"\n\n        return self.request(\"DELETE\", url, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "send",
        "input": "Send a given PreparedRequest.\n\n:rtype: requests.Response",
        "output": "def send(self, request, **kwargs):\n        \"\"\"Send a given PreparedRequest.\n\n        :rtype: requests.Response\n        \"\"\"\n        # Set defaults that the hooks can utilize to ensure they always have\n        # the correct parameters to reproduce the previous request.\n        kwargs.setdefault(\"stream\", self.stream)\n        kwargs.setdefault(\"verify\", self.verify)\n        kwargs.setdefault(\"cert\", self.cert)\n        if \"proxies\" not in kwargs:\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\n\n        # It's possible that users might accidentally send a Request object.\n        # Guard against that specific failure case.\n        if isinstance(request, Request):\n            raise ValueError(\"You can only send PreparedRequests.\")\n\n        # Set up variables needed for resolve_redirects and dispatching of hooks\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\n        stream = kwargs.get(\"stream\")\n        hooks = request.hooks\n\n        # Get the appropriate adapter to use\n        adapter = self.get_adapter(url=request.url)\n\n        # Start time (approximately) of the request\n        start = preferred_clock()\n\n        # Send the request\n        r = adapter.send(request, **kwargs)\n\n        # Total elapsed time of the request (approximately)\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # Response manipulation hooks\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\n\n        # Persist cookies\n        if r.history:\n            # If the hooks create history then we want those cookies too\n            for resp in r.history:\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Resolve redirects if allowed.\n        if allow_redirects:\n            # Redirect resolving generator.\n            gen = self.resolve_redirects(r, request, **kwargs)\n            history = [resp for resp in gen]\n        else:\n            history = []\n\n        # Shuffle things around if there's history.\n        if history:\n            # Insert the first (original) request at the start\n            history.insert(0, r)\n            # Get the last request made\n            r = history.pop()\n            r.history = history\n\n        # If redirects aren't being followed, store the response on the Request for Response.next().\n        if not allow_redirects:\n            try:\n                r._next = next(\n                    self.resolve_redirects(r, request, yield_requests=True, **kwargs)\n                )\n            except StopIteration:\n                pass\n\n        if not stream:\n            r.content\n\n        return r"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "merge_environment_settings",
        "input": "Check the environment and merge it with some settings.\n\n:rtype: dict",
        "output": "def merge_environment_settings(self, url, proxies, stream, verify, cert):\n        \"\"\"\n        Check the environment and merge it with some settings.\n\n        :rtype: dict\n        \"\"\"\n        # Gather clues from the surrounding environment.\n        if self.trust_env:\n            # Set environment's proxies.\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n            for k, v in env_proxies.items():\n                proxies.setdefault(k, v)\n\n            # Look for requests environment configuration\n            # and be compatible with cURL.\n            if verify is True or verify is None:\n                verify = (\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\n                    or verify\n                )\n\n        # Merge all the kwargs.\n        proxies = merge_setting(proxies, self.proxies)\n        stream = merge_setting(stream, self.stream)\n        verify = merge_setting(verify, self.verify)\n        cert = merge_setting(cert, self.cert)\n\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_adapter",
        "input": "Returns the appropriate connection adapter for the given URL.\n\n:rtype: requests.adapters.BaseAdapter",
        "output": "def get_adapter(self, url):\n        \"\"\"\n        Returns the appropriate connection adapter for the given URL.\n\n        :rtype: requests.adapters.BaseAdapter\n        \"\"\"\n        for prefix, adapter in self.adapters.items():\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n\n        # Nothing matches :-/\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "close",
        "input": "Closes all adapters and as such the session",
        "output": "def close(self):\n        \"\"\"Closes all adapters and as such the session\"\"\"\n        for v in self.adapters.values():\n            v.close()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "mount",
        "input": "Registers a connection adapter to a prefix.\n\nAdapters are sorted in descending order by prefix length.",
        "output": "def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\n\n        Adapters are sorted in descending order by prefix length.\n        \"\"\"\n        self.adapters[prefix] = adapter\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n\n        for key in keys_to_move:\n            self.adapters[key] = self.adapters.pop(key)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "lower_items",
        "input": "Like iteritems(), but with all lowercase keys.",
        "output": "def lower_items(self):\n        \"\"\"Like iteritems(), but with all lowercase keys.\"\"\"\n        return ((lowerkey, keyval[1]) for (lowerkey, keyval) in self._store.items())"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dict_to_sequence",
        "input": "Returns an internal sequence dictionary update.",
        "output": "def dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, \"items\"):\n        d = d.items()\n\n    return d"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_netrc_auth",
        "input": "Returns the Requests tuple auth for a given url from netrc.",
        "output": "def get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n\n    try:\n        from netrc import NetrcParseError, netrc\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b\":\"\n        if isinstance(url, str):\n            splitstr = splitstr.decode(\"ascii\")\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = 0 if _netrc[0] else 1\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, OSError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "guess_filename",
        "input": "Tries to guess the filename of the given object.",
        "output": "def guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "extract_zipped_paths",
        "input": "Replace nonexistent paths that look like they refer to a member of a zip\narchive with the location of an extracted copy of the target, or else\njust return the provided path unchanged.",
        "output": "def extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = \"/\".join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "atomic_open",
        "input": "Write a file to the disk in an atomic fashion",
        "output": "def atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "from_key_val_list",
        "input": "Take an object and test to see if it can be represented as a\ndictionary. Unless it can not be represented as such, return an\nOrderedDict, e.g.,\n\n::\n\n    >>> from_key_val_list([('key', 'val')])\n    OrderedDict([('key', 'val')])\n    >>> from_key_val_list('string')\n    Traceback (most recent call last):\n    ...\n    ValueError: cannot encode objects that are not 2-tuples\n    >>> from_key_val_list({'key': 'val'})\n    OrderedDict([('key', 'val')])\n\n:rtype: OrderedDict",
        "output": "def from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    return OrderedDict(value)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "to_key_val_list",
        "input": "Take an object and test to see if it can be represented as a\ndictionary. If it can be, return a list of tuples, e.g.,\n\n::\n\n    >>> to_key_val_list([('key', 'val')])\n    [('key', 'val')]\n    >>> to_key_val_list({'key': 'val'})\n    [('key', 'val')]\n    >>> to_key_val_list('string')\n    Traceback (most recent call last):\n    ...\n    ValueError: cannot encode objects that are not 2-tuples\n\n:rtype: list",
        "output": "def to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "parse_list_header",
        "input": "Parse lists as described by RFC 2068 Section 2.\n\nIn particular, parse comma-separated lists where the elements of\nthe list may include quoted-strings.  A quoted-string could\ncontain a comma.  A non-quoted string could have quotes in the\nmiddle.  Quotes are removed automatically after parsing.\n\nIt basically works like :func:`parse_set_header` just that items\nmay appear multiple times and case sensitivity is preserved.\n\nThe return value is a standard :class:`list`:\n\n>>> parse_list_header('token, \"quoted value\"')\n['token', 'quoted value']\n\nTo create a header from the :class:`list` again, use the\n:func:`dump_header` function.\n\n:param value: a string with a list header.\n:return: :class:`list`\n:rtype: list",
        "output": "def parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "parse_dict_header",
        "input": "Parse lists of key, value pairs as described by RFC 2068 Section 2 and\nconvert them into a python dict:\n\n>>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n>>> type(d) is dict\nTrue\n>>> sorted(d.items())\n[('bar', 'as well'), ('foo', 'is a fish')]\n\nIf there is no value for a key it will be `None`:\n\n>>> parse_dict_header('key_without_value')\n{'key_without_value': None}\n\nTo create a header from the :class:`dict` again, use the\n:func:`dump_header` function.\n\n:param value: a string with a dict header.\n:return: :class:`dict`\n:rtype: dict",
        "output": "def parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if \"=\" not in item:\n            result[item] = None\n            continue\n        name, value = item.split(\"=\", 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "unquote_header_value",
        "input": "Unquotes a header value.  (Reversal of :func:`quote_header_value`).\nThis does not use the real unquoting but what browsers are actually\nusing for quoting.\n\n:param value: the header value to unquote.\n:rtype: str",
        "output": "def unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != \"\\\\\\\\\":\n            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n    return value"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dict_from_cookiejar",
        "input": "Returns a key/value dictionary from a CookieJar.\n\n:param cj: CookieJar object to extract cookies from.\n:rtype: dict",
        "output": "def dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {cookie.name: cookie.value for cookie in cj}\n    return cookie_dict"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "add_dict_to_cookiejar",
        "input": "Returns a CookieJar from a key/value dictionary.\n\n:param cj: CookieJar to insert cookies into.\n:param cookie_dict: Dict of key/values to insert into CookieJar.\n:rtype: CookieJar",
        "output": "def add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_encodings_from_content",
        "input": "Returns encodings from given content string.\n\n:param content: bytestring to extract encodings from.",
        "output": "def get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (\n        charset_re.findall(content)\n        + pragma_re.findall(content)\n        + xml_re.findall(content)\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_parse_content_type_header",
        "input": "Returns content type and parameters from given header\n\n:param header: string\n:return: tuple containing content type and dictionary of\n     parameters",
        "output": "def _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(\";\")\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_encoding_from_headers",
        "input": "Returns encodings from given HTTP Header Dict.\n\n:param headers: dictionary to extract encoding from.\n:rtype: str",
        "output": "def get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get(\"content-type\")\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if \"charset\" in params:\n        return params[\"charset\"].strip(\"'\\\"\")\n\n    if \"text\" in content_type:\n        return \"ISO-8859-1\"\n\n    if \"application/json\" in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return \"utf-8\""
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "stream_decode_response_unicode",
        "input": "Stream decodes an iterator.",
        "output": "def stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes an iterator.\"\"\"\n\n    if r.encoding is None:\n        yield from iterator\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b\"\", final=True)\n    if rv:\n        yield rv"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "iter_slices",
        "input": "Iterate over slices of a string.",
        "output": "def iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_unicode_from_response",
        "input": "Returns the requested content back in unicode.\n\n:param r: Response object to get unicode content from.\n\nTried:\n\n1. charset from content-type\n2. fall back and replace all unicode characters\n\n:rtype: str",
        "output": "def get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors=\"replace\")\n    except TypeError:\n        return r.content"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "unquote_unreserved",
        "input": "Un-escape any percent-escape sequences in a URI that are unreserved\ncharacters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n:rtype: str",
        "output": "def unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = f\"%{parts[i]}\"\n        else:\n            parts[i] = f\"%{parts[i]}\"\n    return \"\".join(parts)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "requote_uri",
        "input": "Re-quote the given URI.\n\nThis function passes the given URI through an unquote/quote cycle to\nensure that it is fully and consistently quoted.\n\n:rtype: str",
        "output": "def requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "address_in_network",
        "input": "This function allows you to check if an IP belongs to a network subnet\n\nExample: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n         returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n:rtype: bool",
        "output": "def address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dotted_netmask",
        "input": "Converts mask from /xx format to xxx.xxx.xxx.xxx\n\nExample: if mask is 24 function returns 255.255.255.0\n\n:rtype: str",
        "output": "def dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "is_ipv4_address",
        "input": ":rtype: bool",
        "output": "def is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "is_valid_cidr",
        "input": "Very simple check of the cidr format in no_proxy variable.\n\n:rtype: bool",
        "output": "def is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split(\"/\")[0])\n        except OSError:\n            return False\n    else:\n        return False\n    return True"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "set_environ",
        "input": "Set the environment variable 'env_name' to 'value'\n\nSave previous value, yield, and then restore the previous value stored in\nthe environment variable 'env_name'.\n\nIf 'value' is None, do nothing",
        "output": "def set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "should_bypass_proxies",
        "input": "Returns whether we should bypass proxies or not.\n\n:rtype: bool",
        "output": "def should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy(\"no_proxy\")\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += f\":{parsed.port}\"\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ(\"no_proxy\", no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_environ_proxies",
        "input": "Return a dict of environment proxies.\n\n:rtype: dict",
        "output": "def get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "select_proxy",
        "input": "Select a proxy for the url, if applicable.\n\n:param url: The url being for the request\n:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs",
        "output": "def select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n\n    proxy_keys = [\n        urlparts.scheme + \"://\" + urlparts.hostname,\n        urlparts.scheme,\n        \"all://\" + urlparts.hostname,\n        \"all\",\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "resolve_proxies",
        "input": "This method takes proxy information from a request and configuration\ninput to resolve a mapping of target proxies. This will consider settings\nsuch as NO_PROXY to strip proxy configurations.\n\n:param request: Request or PreparedRequest\n:param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n:param trust_env: Boolean declaring whether to trust environment configs\n\n:rtype: dict",
        "output": "def resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such as NO_PROXY to strip proxy configurations.\n\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}\n    url = request.url\n    scheme = urlparse(url).scheme\n    no_proxy = proxies.get(\"no_proxy\")\n    new_proxies = proxies.copy()\n\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n\n        if proxy:\n            new_proxies.setdefault(scheme, proxy)\n    return new_proxies"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "default_user_agent",
        "input": "Return a string representing the default user agent.\n\n:rtype: str",
        "output": "def default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\""
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "default_headers",
        "input": ":rtype: requests.structures.CaseInsensitiveDict",
        "output": "def default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",\n        }\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "parse_header_links",
        "input": "Return a list of parsed link headers proxies.\n\ni.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n:rtype: list",
        "output": "def parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = \" '\\\"\"\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "guess_json_utf",
        "input": ":rtype: str",
        "output": "def guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return \"utf-16\"  # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return \"utf-8\"\n    if nullcount == 2:\n        if sample[::2] == _null2:  # 1st and 3rd are null\n            return \"utf-16-be\"\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return \"utf-16-le\"\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return \"utf-32-be\"\n        if sample[1:] == _null3:\n            return \"utf-32-le\"\n        # Did not detect a valid UTF-32 ascii-range character\n    return None"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepend_scheme_if_needed",
        "input": "Given a URL that may or may not have a scheme, prepend the given scheme.\nDoes not replace a present scheme with the one provided as an argument.\n\n:rtype: str",
        "output": "def prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is\n    # maintained with parse_url for backwards compatibility.\n    netloc = parsed.netloc\n    if not netloc:\n        netloc, path = path, netloc\n\n    if auth:\n        # parse_url doesn't provide the netloc with auth\n        # so we'll add it ourselves.\n        netloc = \"@\".join([auth, netloc])\n    if scheme is None:\n        scheme = new_scheme\n    if path is None:\n        path = \"\"\n\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_auth_from_url",
        "input": "Given a url with authentication components, extract them into a tuple of\nusername,password.\n\n:rtype: (str,str)",
        "output": "def get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")\n\n    return auth"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "check_header_validity",
        "input": "Verifies that header parts don't contain leading whitespace\nreserved characters, or return characters.\n\n:param header: tuple, in the format (name, value).",
        "output": "def check_header_validity(header):\n    \"\"\"Verifies that header parts don't contain leading whitespace\n    reserved characters, or return characters.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n    _validate_header_part(header, name, 0)\n    _validate_header_part(header, value, 1)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "urldefragauth",
        "input": "Given a url remove the fragment and the authentication part.\n\n:rtype: str",
        "output": "def urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit(\"@\", 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, \"\"))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "rewind_body",
        "input": "Move file pointer back to its recorded starting position\nso it can be read again on redirect.",
        "output": "def rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)\n        except OSError:\n            raise UnrewindableBodyError(\n                \"An error occurred when rewinding request body for redirect.\"\n            )\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "proxy_bypass",
        "input": "Return True, if the host should be bypassed.\n\nChecks proxy settings gathered from the environment, if specified,\nor the registry.",
        "output": "def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "login_required",
        "input": "View decorator that redirects anonymous users to the login page.",
        "output": "def login_required(view):\n    \"\"\"View decorator that redirects anonymous users to the login page.\"\"\"\n\n    @functools.wraps(view)\n    def wrapped_view(**kwargs):\n        if g.user is None:\n            return redirect(url_for(\"auth.login\"))\n\n        return view(**kwargs)\n\n    return wrapped_view"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "load_logged_in_user",
        "input": "If a user id is stored in the session, load the user object from\nthe database into ``g.user``.",
        "output": "def load_logged_in_user():\n    \"\"\"If a user id is stored in the session, load the user object from\n    the database into ``g.user``.\"\"\"\n    user_id = session.get(\"user_id\")\n\n    if user_id is None:\n        g.user = None\n    else:\n        g.user = (\n            get_db().execute(\"SELECT * FROM user WHERE id = ?\", (user_id,)).fetchone()\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "register",
        "input": "Register a new user.\n\nValidates that the username is not already taken. Hashes the\npassword for security.",
        "output": "def register():\n    \"\"\"Register a new user.\n\n    Validates that the username is not already taken. Hashes the\n    password for security.\n    \"\"\"\n    if request.method == \"POST\":\n        username = request.form[\"username\"]\n        password = request.form[\"password\"]\n        db = get_db()\n        error = None\n\n        if not username:\n            error = \"Username is required.\"\n        elif not password:\n            error = \"Password is required.\"\n\n        if error is None:\n            try:\n                db.execute(\n                    \"INSERT INTO user (username, password) VALUES (?, ?)\",\n                    (username, generate_password_hash(password)),\n                )\n                db.commit()\n            except db.IntegrityError:\n                # The username was already taken, which caused the\n                # commit to fail. Show a validation error.\n                error = f\"User {username} is already registered.\"\n            else:\n                # Success, go to the login page.\n                return redirect(url_for(\"auth.login\"))\n\n        flash(error)\n\n    return render_template(\"auth/register.html\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "login",
        "input": "Log in a registered user by adding the user id to the session.",
        "output": "def login():\n    \"\"\"Log in a registered user by adding the user id to the session.\"\"\"\n    if request.method == \"POST\":\n        username = request.form[\"username\"]\n        password = request.form[\"password\"]\n        db = get_db()\n        error = None\n        user = db.execute(\n            \"SELECT * FROM user WHERE username = ?\", (username,)\n        ).fetchone()\n\n        if user is None:\n            error = \"Incorrect username.\"\n        elif not check_password_hash(user[\"password\"], password):\n            error = \"Incorrect password.\"\n\n        if error is None:\n            # store the user id in a new session and return to the index\n            session.clear()\n            session[\"user_id\"] = user[\"id\"]\n            return redirect(url_for(\"index\"))\n\n        flash(error)\n\n    return render_template(\"auth/login.html\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "logout",
        "input": "Clear the current session, including the stored user id.",
        "output": "def logout():\n    \"\"\"Clear the current session, including the stored user id.\"\"\"\n    session.clear()\n    return redirect(url_for(\"index\"))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "index",
        "input": "Show all the posts, most recent first.",
        "output": "def index():\n    \"\"\"Show all the posts, most recent first.\"\"\"\n    db = get_db()\n    posts = db.execute(\n        \"SELECT p.id, title, body, created, author_id, username\"\n        \" FROM post p JOIN user u ON p.author_id = u.id\"\n        \" ORDER BY created DESC\"\n    ).fetchall()\n    return render_template(\"blog/index.html\", posts=posts)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_post",
        "input": "Get a post and its author by id.\n\nChecks that the id exists and optionally that the current user is\nthe author.\n\n:param id: id of post to get\n:param check_author: require the current user to be the author\n:return: the post with author information\n:raise 404: if a post with the given id doesn't exist\n:raise 403: if the current user isn't the author",
        "output": "def get_post(id, check_author=True):\n    \"\"\"Get a post and its author by id.\n\n    Checks that the id exists and optionally that the current user is\n    the author.\n\n    :param id: id of post to get\n    :param check_author: require the current user to be the author\n    :return: the post with author information\n    :raise 404: if a post with the given id doesn't exist\n    :raise 403: if the current user isn't the author\n    \"\"\"\n    post = (\n        get_db()\n        .execute(\n            \"SELECT p.id, title, body, created, author_id, username\"\n            \" FROM post p JOIN user u ON p.author_id = u.id\"\n            \" WHERE p.id = ?\",\n            (id,),\n        )\n        .fetchone()\n    )\n\n    if post is None:\n        abort(404, f\"Post id {id} doesn't exist.\")\n\n    if check_author and post[\"author_id\"] != g.user[\"id\"]:\n        abort(403)\n\n    return post"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "create",
        "input": "Create a new post for the current user.",
        "output": "def create():\n    \"\"\"Create a new post for the current user.\"\"\"\n    if request.method == \"POST\":\n        title = request.form[\"title\"]\n        body = request.form[\"body\"]\n        error = None\n\n        if not title:\n            error = \"Title is required.\"\n\n        if error is not None:\n            flash(error)\n        else:\n            db = get_db()\n            db.execute(\n                \"INSERT INTO post (title, body, author_id) VALUES (?, ?, ?)\",\n                (title, body, g.user[\"id\"]),\n            )\n            db.commit()\n            return redirect(url_for(\"blog.index\"))\n\n    return render_template(\"blog/create.html\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "update",
        "input": "Update a post if the current user is the author.",
        "output": "def update(id):\n    \"\"\"Update a post if the current user is the author.\"\"\"\n    post = get_post(id)\n\n    if request.method == \"POST\":\n        title = request.form[\"title\"]\n        body = request.form[\"body\"]\n        error = None\n\n        if not title:\n            error = \"Title is required.\"\n\n        if error is not None:\n            flash(error)\n        else:\n            db = get_db()\n            db.execute(\n                \"UPDATE post SET title = ?, body = ? WHERE id = ?\", (title, body, id)\n            )\n            db.commit()\n            return redirect(url_for(\"blog.index\"))\n\n    return render_template(\"blog/update.html\", post=post)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "delete",
        "input": "Delete a post.\n\nEnsures that the post exists and that the logged in user is the\nauthor of the post.",
        "output": "def delete(id):\n    \"\"\"Delete a post.\n\n    Ensures that the post exists and that the logged in user is the\n    author of the post.\n    \"\"\"\n    get_post(id)\n    db = get_db()\n    db.execute(\"DELETE FROM post WHERE id = ?\", (id,))\n    db.commit()\n    return redirect(url_for(\"blog.index\"))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_db",
        "input": "Connect to the application's configured database. The connection\nis unique for each request and will be reused if this is called\nagain.",
        "output": "def get_db():\n    \"\"\"Connect to the application's configured database. The connection\n    is unique for each request and will be reused if this is called\n    again.\n    \"\"\"\n    if \"db\" not in g:\n        g.db = sqlite3.connect(\n            current_app.config[\"DATABASE\"], detect_types=sqlite3.PARSE_DECLTYPES\n        )\n        g.db.row_factory = sqlite3.Row\n\n    return g.db"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "close_db",
        "input": "If this request connected to the database, close the\nconnection.",
        "output": "def close_db(e=None):\n    \"\"\"If this request connected to the database, close the\n    connection.\n    \"\"\"\n    db = g.pop(\"db\", None)\n\n    if db is not None:\n        db.close()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "init_db",
        "input": "Clear existing data and create new tables.",
        "output": "def init_db():\n    \"\"\"Clear existing data and create new tables.\"\"\"\n    db = get_db()\n\n    with current_app.open_resource(\"schema.sql\") as f:\n        db.executescript(f.read().decode(\"utf8\"))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "init_db_command",
        "input": "Clear existing data and create new tables.",
        "output": "def init_db_command():\n    \"\"\"Clear existing data and create new tables.\"\"\"\n    init_db()\n    click.echo(\"Initialized the database.\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "init_app",
        "input": "Register database functions with the Flask app. This is called by\nthe application factory.",
        "output": "def init_app(app):\n    \"\"\"Register database functions with the Flask app. This is called by\n    the application factory.\n    \"\"\"\n    app.teardown_appcontext(close_db)\n    app.cli.add_command(init_db_command)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_send_file_max_age",
        "input": "Used by :func:`send_file` to determine the ``max_age`` cache\nvalue for a given file path if it wasn't passed.\n\nBy default, this returns :data:`SEND_FILE_MAX_AGE_DEFAULT` from\nthe configuration of :data:`~flask.current_app`. This defaults\nto ``None``, which tells the browser to use conditional requests\ninstead of a timed cache, which is usually preferable.\n\nNote this is a duplicate of the same method in the Flask\nclass.\n\n.. versionchanged:: 2.0\n    The default configuration is ``None`` instead of 12 hours.\n\n.. versionadded:: 0.9",
        "output": "def get_send_file_max_age(self, filename: str | None) -> int | None:\n        \"\"\"Used by :func:`send_file` to determine the ``max_age`` cache\n        value for a given file path if it wasn't passed.\n\n        By default, this returns :data:`SEND_FILE_MAX_AGE_DEFAULT` from\n        the configuration of :data:`~flask.current_app`. This defaults\n        to ``None``, which tells the browser to use conditional requests\n        instead of a timed cache, which is usually preferable.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionchanged:: 2.0\n            The default configuration is ``None`` instead of 12 hours.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        value = current_app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n\n        if value is None:\n            return None\n\n        if isinstance(value, timedelta):\n            return int(value.total_seconds())\n\n        return value  # type: ignore[no-any-return]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "send_static_file",
        "input": "The view function used to serve files from\n:attr:`static_folder`. A route is automatically registered for\nthis view at :attr:`static_url_path` if :attr:`static_folder` is\nset.\n\nNote this is a duplicate of the same method in the Flask\nclass.\n\n.. versionadded:: 0.5",
        "output": "def send_static_file(self, filename: str) -> Response:\n        \"\"\"The view function used to serve files from\n        :attr:`static_folder`. A route is automatically registered for\n        this view at :attr:`static_url_path` if :attr:`static_folder` is\n        set.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionadded:: 0.5\n\n        \"\"\"\n        if not self.has_static_folder:\n            raise RuntimeError(\"'static_folder' must be set to serve static_files.\")\n\n        # send_file only knows to call get_send_file_max_age on the app,\n        # call it here so it works for blueprints too.\n        max_age = self.get_send_file_max_age(filename)\n        return send_from_directory(\n            t.cast(str, self.static_folder), filename, max_age=max_age\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "open_resource",
        "input": "Open a resource file relative to :attr:`root_path` for reading.\n\nFor example, if the file ``schema.sql`` is next to the file\n``app.py`` where the ``Flask`` app is defined, it can be opened\nwith:\n\n.. code-block:: python\n\n    with app.open_resource(\"schema.sql\") as f:\n        conn.executescript(f.read())\n\n:param resource: Path to the resource relative to :attr:`root_path`.\n:param mode: Open the file in this mode. Only reading is supported,\n    valid values are ``\"r\"`` (or ``\"rt\"``) and ``\"rb\"``.\n:param encoding: Open the file with this encoding when opening in text\n    mode. This is ignored when opening in binary mode.\n\n.. versionchanged:: 3.1\n    Added the ``encoding`` parameter.",
        "output": "def open_resource(\n        self, resource: str, mode: str = \"rb\", encoding: str | None = None\n    ) -> t.IO[t.AnyStr]:\n        \"\"\"Open a resource file relative to :attr:`root_path` for reading.\n\n        For example, if the file ``schema.sql`` is next to the file\n        ``app.py`` where the ``Flask`` app is defined, it can be opened\n        with:\n\n        .. code-block:: python\n\n            with app.open_resource(\"schema.sql\") as f:\n                conn.executescript(f.read())\n\n        :param resource: Path to the resource relative to :attr:`root_path`.\n        :param mode: Open the file in this mode. Only reading is supported,\n            valid values are ``\"r\"`` (or ``\"rt\"``) and ``\"rb\"``.\n        :param encoding: Open the file with this encoding when opening in text\n            mode. This is ignored when opening in binary mode.\n\n        .. versionchanged:: 3.1\n            Added the ``encoding`` parameter.\n        \"\"\"\n        if mode not in {\"r\", \"rt\", \"rb\"}:\n            raise ValueError(\"Resources can only be opened for reading.\")\n\n        path = os.path.join(self.root_path, resource)\n\n        if mode == \"rb\":\n            return open(path, mode)  # pyright: ignore\n\n        return open(path, mode, encoding=encoding)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "open_instance_resource",
        "input": "Open a resource file relative to the application's instance folder\n:attr:`instance_path`. Unlike :meth:`open_resource`, files in the\ninstance folder can be opened for writing.\n\n:param resource: Path to the resource relative to :attr:`instance_path`.\n:param mode: Open the file in this mode.\n:param encoding: Open the file with this encoding when opening in text\n    mode. This is ignored when opening in binary mode.\n\n.. versionchanged:: 3.1\n    Added the ``encoding`` parameter.",
        "output": "def open_instance_resource(\n        self, resource: str, mode: str = \"rb\", encoding: str | None = \"utf-8\"\n    ) -> t.IO[t.AnyStr]:\n        \"\"\"Open a resource file relative to the application's instance folder\n        :attr:`instance_path`. Unlike :meth:`open_resource`, files in the\n        instance folder can be opened for writing.\n\n        :param resource: Path to the resource relative to :attr:`instance_path`.\n        :param mode: Open the file in this mode.\n        :param encoding: Open the file with this encoding when opening in text\n            mode. This is ignored when opening in binary mode.\n\n        .. versionchanged:: 3.1\n            Added the ``encoding`` parameter.\n        \"\"\"\n        path = os.path.join(self.instance_path, resource)\n\n        if \"b\" in mode:\n            return open(path, mode)\n\n        return open(path, mode, encoding=encoding)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "create_jinja_environment",
        "input": "Create the Jinja environment based on :attr:`jinja_options`\nand the various Jinja-related methods of the app. Changing\n:attr:`jinja_options` after this will have no effect. Also adds\nFlask-related globals and filters to the environment.\n\n.. versionchanged:: 0.11\n   ``Environment.auto_reload`` set in accordance with\n   ``TEMPLATES_AUTO_RELOAD`` configuration option.\n\n.. versionadded:: 0.5",
        "output": "def create_jinja_environment(self) -> Environment:\n        \"\"\"Create the Jinja environment based on :attr:`jinja_options`\n        and the various Jinja-related methods of the app. Changing\n        :attr:`jinja_options` after this will have no effect. Also adds\n        Flask-related globals and filters to the environment.\n\n        .. versionchanged:: 0.11\n           ``Environment.auto_reload`` set in accordance with\n           ``TEMPLATES_AUTO_RELOAD`` configuration option.\n\n        .. versionadded:: 0.5\n        \"\"\"\n        options = dict(self.jinja_options)\n\n        if \"autoescape\" not in options:\n            options[\"autoescape\"] = self.select_jinja_autoescape\n\n        if \"auto_reload\" not in options:\n            auto_reload = self.config[\"TEMPLATES_AUTO_RELOAD\"]\n\n            if auto_reload is None:\n                auto_reload = self.debug\n\n            options[\"auto_reload\"] = auto_reload\n\n        rv = self.jinja_environment(self, **options)\n        rv.globals.update(\n            url_for=self.url_for,\n            get_flashed_messages=get_flashed_messages,\n            config=self.config,\n            # request, session and g are normally added with the\n            # context processor for efficiency reasons but for imported\n            # templates we also want the proxies in there.\n            request=request,\n            session=session,\n            g=g,\n        )\n        rv.policies[\"json.dumps_function\"] = self.json.dumps\n        return rv"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "create_url_adapter",
        "input": "Creates a URL adapter for the given request. The URL adapter\nis created at a point where the request context is not yet set\nup so the request is passed explicitly.\n\n.. versionchanged:: 3.1\n    If :data:`SERVER_NAME` is set, it does not restrict requests to\n    only that domain, for both ``subdomain_matching`` and\n    ``host_matching``.\n\n.. versionchanged:: 1.0\n    :data:`SERVER_NAME` no longer implicitly enables subdomain\n    matching. Use :attr:`subdomain_matching` instead.\n\n.. versionchanged:: 0.9\n   This can be called outside a request when the URL adapter is created\n   for an application context.\n\n.. versionadded:: 0.6",
        "output": "def create_url_adapter(self, request: Request | None) -> MapAdapter | None:\n        \"\"\"Creates a URL adapter for the given request. The URL adapter\n        is created at a point where the request context is not yet set\n        up so the request is passed explicitly.\n\n        .. versionchanged:: 3.1\n            If :data:`SERVER_NAME` is set, it does not restrict requests to\n            only that domain, for both ``subdomain_matching`` and\n            ``host_matching``.\n\n        .. versionchanged:: 1.0\n            :data:`SERVER_NAME` no longer implicitly enables subdomain\n            matching. Use :attr:`subdomain_matching` instead.\n\n        .. versionchanged:: 0.9\n           This can be called outside a request when the URL adapter is created\n           for an application context.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        if request is not None:\n            if (trusted_hosts := self.config[\"TRUSTED_HOSTS\"]) is not None:\n                request.trusted_hosts = trusted_hosts\n\n            # Check trusted_hosts here until bind_to_environ does.\n            request.host = get_host(request.environ, request.trusted_hosts)  # pyright: ignore\n            subdomain = None\n            server_name = self.config[\"SERVER_NAME\"]\n\n            if self.url_map.host_matching:\n                # Don't pass SERVER_NAME, otherwise it's used and the actual\n                # host is ignored, which breaks host matching.\n                server_name = None\n            elif not self.subdomain_matching:\n                # Werkzeug doesn't implement subdomain matching yet. Until then,\n                # disable it by forcing the current subdomain to the default, or\n                # the empty string.\n                subdomain = self.url_map.default_subdomain or \"\"\n\n            return self.url_map.bind_to_environ(\n                request.environ, server_name=server_name, subdomain=subdomain\n            )\n\n        # Need at least SERVER_NAME to match/build outside a request.\n        if self.config[\"SERVER_NAME\"] is not None:\n            return self.url_map.bind(\n                self.config[\"SERVER_NAME\"],\n                script_name=self.config[\"APPLICATION_ROOT\"],\n                url_scheme=self.config[\"PREFERRED_URL_SCHEME\"],\n            )\n\n        return None"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "raise_routing_exception",
        "input": "Intercept routing exceptions and possibly do something else.\n\nIn debug mode, intercept a routing redirect and replace it with\nan error if the body will be discarded.\n\nWith modern Werkzeug this shouldn't occur, since it now uses a\n308 status which tells the browser to resend the method and\nbody.\n\n.. versionchanged:: 2.1\n    Don't intercept 307 and 308 redirects.\n\n:meta private:\n:internal:",
        "output": "def raise_routing_exception(self, request: Request) -> t.NoReturn:\n        \"\"\"Intercept routing exceptions and possibly do something else.\n\n        In debug mode, intercept a routing redirect and replace it with\n        an error if the body will be discarded.\n\n        With modern Werkzeug this shouldn't occur, since it now uses a\n        308 status which tells the browser to resend the method and\n        body.\n\n        .. versionchanged:: 2.1\n            Don't intercept 307 and 308 redirects.\n\n        :meta private:\n        :internal:\n        \"\"\"\n        if (\n            not self.debug\n            or not isinstance(request.routing_exception, RequestRedirect)\n            or request.routing_exception.code in {307, 308}\n            or request.method in {\"GET\", \"HEAD\", \"OPTIONS\"}\n        ):\n            raise request.routing_exception  # type: ignore[misc]\n\n        from .debughelpers import FormDataRoutingRedirect\n\n        raise FormDataRoutingRedirect(request)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "update_template_context",
        "input": "Update the template context with some commonly used variables.\nThis injects request, session, config and g into the template\ncontext as well as everything template context processors want\nto inject.  Note that the as of Flask 0.6, the original values\nin the context will not be overridden if a context processor\ndecides to return a value with the same key.\n\n:param context: the context as a dictionary that is updated in place\n                to add extra variables.",
        "output": "def update_template_context(self, context: dict[str, t.Any]) -> None:\n        \"\"\"Update the template context with some commonly used variables.\n        This injects request, session, config and g into the template\n        context as well as everything template context processors want\n        to inject.  Note that the as of Flask 0.6, the original values\n        in the context will not be overridden if a context processor\n        decides to return a value with the same key.\n\n        :param context: the context as a dictionary that is updated in place\n                        to add extra variables.\n        \"\"\"\n        names: t.Iterable[str | None] = (None,)\n\n        # A template may be rendered outside a request context.\n        if request:\n            names = chain(names, reversed(request.blueprints))\n\n        # The values passed to render_template take precedence. Keep a\n        # copy to re-apply after all context functions.\n        orig_ctx = context.copy()\n\n        for name in names:\n            if name in self.template_context_processors:\n                for func in self.template_context_processors[name]:\n                    context.update(self.ensure_sync(func)())\n\n        context.update(orig_ctx)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "make_shell_context",
        "input": "Returns the shell context for an interactive shell for this\napplication.  This runs all the registered shell context\nprocessors.\n\n.. versionadded:: 0.11",
        "output": "def make_shell_context(self) -> dict[str, t.Any]:\n        \"\"\"Returns the shell context for an interactive shell for this\n        application.  This runs all the registered shell context\n        processors.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        rv = {\"app\": self, \"g\": g}\n        for processor in self.shell_context_processors:\n            rv.update(processor())\n        return rv"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "run",
        "input": "Runs the application on a local development server.\n\nDo not use ``run()`` in a production setting. It is not intended to\nmeet security and performance requirements for a production server.\nInstead, see :doc:`/deploying/index` for WSGI server recommendations.\n\nIf the :attr:`debug` flag is set the server will automatically reload\nfor code changes and show a debugger in case an exception happened.\n\nIf you want to run the application in debug mode, but disable the\ncode execution on the interactive debugger, you can pass\n``use_evalex=False`` as parameter.  This will keep the debugger's\ntraceback screen active, but disable code execution.\n\nIt is not recommended to use this function for development with\nautomatic reloading as this is badly supported.  Instead you should\nbe using the :command:`flask` command line script's ``run`` support.\n\n.. admonition:: Keep in Mind\n\n   Flask will suppress any server error with a generic error page\n   unless it is in debug mode.  As such to enable just the\n   interactive debugger without the code reloading, you have to\n   invoke :meth:`run` with ``debug=True`` and ``use_reloader=False``.\n   Setting ``use_debugger`` to ``True`` without being in debug mode\n   won't catch any exceptions because there won't be any to\n   catch.\n\n:param host: the hostname to listen on. Set this to ``'0.0.0.0'`` to\n    have the server available externally as well. Defaults to\n    ``'127.0.0.1'`` or the host in the ``SERVER_NAME`` config variable\n    if present.\n:param port: the port of the webserver. Defaults to ``5000`` or the\n    port defined in the ``SERVER_NAME`` config variable if present.\n:param debug: if given, enable or disable debug mode. See\n    :attr:`debug`.\n:param load_dotenv: Load the nearest :file:`.env` and :file:`.flaskenv`\n    files to set environment variables. Will also change the working\n    directory to the directory containing the first file found.\n:param options: the options to be forwarded to the underlying Werkzeug\n    server. See :func:`werkzeug.serving.run_simple` for more\n    information.\n\n.. versionchanged:: 1.0\n    If installed, python-dotenv will be used to load environment\n    variables from :file:`.env` and :file:`.flaskenv` files.\n\n    The :envvar:`FLASK_DEBUG` environment variable will override :attr:`debug`.\n\n    Threaded mode is enabled by default.\n\n.. versionchanged:: 0.10\n    The default port is now picked from the ``SERVER_NAME``\n    variable.",
        "output": "def run(\n        self,\n        host: str | None = None,\n        port: int | None = None,\n        debug: bool | None = None,\n        load_dotenv: bool = True,\n        **options: t.Any,\n    ) -> None:\n        \"\"\"Runs the application on a local development server.\n\n        Do not use ``run()`` in a production setting. It is not intended to\n        meet security and performance requirements for a production server.\n        Instead, see :doc:`/deploying/index` for WSGI server recommendations.\n\n        If the :attr:`debug` flag is set the server will automatically reload\n        for code changes and show a debugger in case an exception happened.\n\n        If you want to run the application in debug mode, but disable the\n        code execution on the interactive debugger, you can pass\n        ``use_evalex=False`` as parameter.  This will keep the debugger's\n        traceback screen active, but disable code execution.\n\n        It is not recommended to use this function for development with\n        automatic reloading as this is badly supported.  Instead you should\n        be using the :command:`flask` command line script's ``run`` support.\n\n        .. admonition:: Keep in Mind\n\n           Flask will suppress any server error with a generic error page\n           unless it is in debug mode.  As such to enable just the\n           interactive debugger without the code reloading, you have to\n           invoke :meth:`run` with ``debug=True`` and ``use_reloader=False``.\n           Setting ``use_debugger`` to ``True`` without being in debug mode\n           won't catch any exceptions because there won't be any to\n           catch.\n\n        :param host: the hostname to listen on. Set this to ``'0.0.0.0'`` to\n            have the server available externally as well. Defaults to\n            ``'127.0.0.1'`` or the host in the ``SERVER_NAME`` config variable\n            if present.\n        :param port: the port of the webserver. Defaults to ``5000`` or the\n            port defined in the ``SERVER_NAME`` config variable if present.\n        :param debug: if given, enable or disable debug mode. See\n            :attr:`debug`.\n        :param load_dotenv: Load the nearest :file:`.env` and :file:`.flaskenv`\n            files to set environment variables. Will also change the working\n            directory to the directory containing the first file found.\n        :param options: the options to be forwarded to the underlying Werkzeug\n            server. See :func:`werkzeug.serving.run_simple` for more\n            information.\n\n        .. versionchanged:: 1.0\n            If installed, python-dotenv will be used to load environment\n            variables from :file:`.env` and :file:`.flaskenv` files.\n\n            The :envvar:`FLASK_DEBUG` environment variable will override :attr:`debug`.\n\n            Threaded mode is enabled by default.\n\n        .. versionchanged:: 0.10\n            The default port is now picked from the ``SERVER_NAME``\n            variable.\n        \"\"\"\n        # Ignore this call so that it doesn't start another server if\n        # the 'flask run' command is used.\n        if os.environ.get(\"FLASK_RUN_FROM_CLI\") == \"true\":\n            if not is_running_from_reloader():\n                click.secho(\n                    \" * Ignoring a call to 'app.run()' that would block\"\n                    \" the current 'flask' CLI command.\\n\"\n                    \"   Only call 'app.run()' in an 'if __name__ ==\"\n                    ' \"__main__\"\\' guard.',\n                    fg=\"red\",\n                )\n\n            return\n\n        if get_load_dotenv(load_dotenv):\n            cli.load_dotenv()\n\n            # if set, env var overrides existing value\n            if \"FLASK_DEBUG\" in os.environ:\n                self.debug = get_debug_flag()\n\n        # debug passed to method overrides all other sources\n        if debug is not None:\n            self.debug = bool(debug)\n\n        server_name = self.config.get(\"SERVER_NAME\")\n        sn_host = sn_port = None\n\n        if server_name:\n            sn_host, _, sn_port = server_name.partition(\":\")\n\n        if not host:\n            if sn_host:\n                host = sn_host\n            else:\n                host = \"127.0.0.1\"\n\n        if port or port == 0:\n            port = int(port)\n        elif sn_port:\n            port = int(sn_port)\n        else:\n            port = 5000\n\n        options.setdefault(\"use_reloader\", self.debug)\n        options.setdefault(\"use_debugger\", self.debug)\n        options.setdefault(\"threaded\", True)\n\n        cli.show_server_banner(self.debug, self.name)\n\n        from werkzeug.serving import run_simple\n\n        try:\n            run_simple(t.cast(str, host), port, self, **options)\n        finally:\n            # reset the first request information if the development server\n            # reset normally.  This makes it possible to restart the server\n            # without reloader and that stuff from an interactive shell.\n            self._got_first_request = False"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "test_client",
        "input": "Creates a test client for this application.  For information\nabout unit testing head over to :doc:`/testing`.\n\nNote that if you are testing for assertions or exceptions in your\napplication code, you must set ``app.testing = True`` in order for the\nexceptions to propagate to the test client.  Otherwise, the exception\nwill be handled by the application (not visible to the test client) and\nthe only indication of an AssertionError or other exception will be a\n500 status code response to the test client.  See the :attr:`testing`\nattribute.  For example::\n\n    app.testing = True\n    client = app.test_client()\n\nThe test client can be used in a ``with`` block to defer the closing down\nof the context until the end of the ``with`` block.  This is useful if\nyou want to access the context locals for testing::\n\n    with app.test_client() as c:\n        rv = c.get('/?vodka=42')\n        assert request.args['vodka'] == '42'\n\nAdditionally, you may pass optional keyword arguments that will then\nbe passed to the application's :attr:`test_client_class` constructor.\nFor example::\n\n    from flask.testing import FlaskClient\n\n    class CustomClient(FlaskClient):\n        def __init__(self, *args, **kwargs):\n            self._authentication = kwargs.pop(\"authentication\")\n            super(CustomClient,self).__init__( *args, **kwargs)\n\n    app.test_client_class = CustomClient\n    client = app.test_client(authentication='Basic ....')\n\nSee :class:`~flask.testing.FlaskClient` for more information.\n\n.. versionchanged:: 0.4\n   added support for ``with`` block usage for the client.\n\n.. versionadded:: 0.7\n   The `use_cookies` parameter was added as well as the ability\n   to override the client to be used by setting the\n   :attr:`test_client_class` attribute.\n\n.. versionchanged:: 0.11\n   Added `**kwargs` to support passing additional keyword arguments to\n   the constructor of :attr:`test_client_class`.",
        "output": "def test_client(self, use_cookies: bool = True, **kwargs: t.Any) -> FlaskClient:\n        \"\"\"Creates a test client for this application.  For information\n        about unit testing head over to :doc:`/testing`.\n\n        Note that if you are testing for assertions or exceptions in your\n        application code, you must set ``app.testing = True`` in order for the\n        exceptions to propagate to the test client.  Otherwise, the exception\n        will be handled by the application (not visible to the test client) and\n        the only indication of an AssertionError or other exception will be a\n        500 status code response to the test client.  See the :attr:`testing`\n        attribute.  For example::\n\n            app.testing = True\n            client = app.test_client()\n\n        The test client can be used in a ``with`` block to defer the closing down\n        of the context until the end of the ``with`` block.  This is useful if\n        you want to access the context locals for testing::\n\n            with app.test_client() as c:\n                rv = c.get('/?vodka=42')\n                assert request.args['vodka'] == '42'\n\n        Additionally, you may pass optional keyword arguments that will then\n        be passed to the application's :attr:`test_client_class` constructor.\n        For example::\n\n            from flask.testing import FlaskClient\n\n            class CustomClient(FlaskClient):\n                def __init__(self, *args, **kwargs):\n                    self._authentication = kwargs.pop(\"authentication\")\n                    super(CustomClient,self).__init__( *args, **kwargs)\n\n            app.test_client_class = CustomClient\n            client = app.test_client(authentication='Basic ....')\n\n        See :class:`~flask.testing.FlaskClient` for more information.\n\n        .. versionchanged:: 0.4\n           added support for ``with`` block usage for the client.\n\n        .. versionadded:: 0.7\n           The `use_cookies` parameter was added as well as the ability\n           to override the client to be used by setting the\n           :attr:`test_client_class` attribute.\n\n        .. versionchanged:: 0.11\n           Added `**kwargs` to support passing additional keyword arguments to\n           the constructor of :attr:`test_client_class`.\n        \"\"\"\n        cls = self.test_client_class\n        if cls is None:\n            from .testing import FlaskClient as cls\n        return cls(  # type: ignore\n            self, self.response_class, use_cookies=use_cookies, **kwargs\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "test_cli_runner",
        "input": "Create a CLI runner for testing CLI commands.\nSee :ref:`testing-cli`.\n\nReturns an instance of :attr:`test_cli_runner_class`, by default\n:class:`~flask.testing.FlaskCliRunner`. The Flask app object is\npassed as the first argument.\n\n.. versionadded:: 1.0",
        "output": "def test_cli_runner(self, **kwargs: t.Any) -> FlaskCliRunner:\n        \"\"\"Create a CLI runner for testing CLI commands.\n        See :ref:`testing-cli`.\n\n        Returns an instance of :attr:`test_cli_runner_class`, by default\n        :class:`~flask.testing.FlaskCliRunner`. The Flask app object is\n        passed as the first argument.\n\n        .. versionadded:: 1.0\n        \"\"\"\n        cls = self.test_cli_runner_class\n\n        if cls is None:\n            from .testing import FlaskCliRunner as cls\n\n        return cls(self, **kwargs)  # type: ignore"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "handle_http_exception",
        "input": "Handles an HTTP exception.  By default this will invoke the\nregistered error handlers and fall back to returning the\nexception as response.\n\n.. versionchanged:: 1.0.3\n    ``RoutingException``, used internally for actions such as\n     slash redirects during routing, is not passed to error\n     handlers.\n\n.. versionchanged:: 1.0\n    Exceptions are looked up by code *and* by MRO, so\n    ``HTTPException`` subclasses can be handled with a catch-all\n    handler for the base ``HTTPException``.\n\n.. versionadded:: 0.3",
        "output": "def handle_http_exception(\n        self, e: HTTPException\n    ) -> HTTPException | ft.ResponseReturnValue:\n        \"\"\"Handles an HTTP exception.  By default this will invoke the\n        registered error handlers and fall back to returning the\n        exception as response.\n\n        .. versionchanged:: 1.0.3\n            ``RoutingException``, used internally for actions such as\n             slash redirects during routing, is not passed to error\n             handlers.\n\n        .. versionchanged:: 1.0\n            Exceptions are looked up by code *and* by MRO, so\n            ``HTTPException`` subclasses can be handled with a catch-all\n            handler for the base ``HTTPException``.\n\n        .. versionadded:: 0.3\n        \"\"\"\n        # Proxy exceptions don't have error codes.  We want to always return\n        # those unchanged as errors\n        if e.code is None:\n            return e\n\n        # RoutingExceptions are used internally to trigger routing\n        # actions, such as slash redirects raising RequestRedirect. They\n        # are not raised or handled in user code.\n        if isinstance(e, RoutingException):\n            return e\n\n        handler = self._find_error_handler(e, request.blueprints)\n        if handler is None:\n            return e\n        return self.ensure_sync(handler)(e)  # type: ignore[no-any-return]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "handle_user_exception",
        "input": "This method is called whenever an exception occurs that\nshould be handled. A special case is :class:`~werkzeug\n.exceptions.HTTPException` which is forwarded to the\n:meth:`handle_http_exception` method. This function will either\nreturn a response value or reraise the exception with the same\ntraceback.\n\n.. versionchanged:: 1.0\n    Key errors raised from request data like ``form`` show the\n    bad key in debug mode rather than a generic bad request\n    message.\n\n.. versionadded:: 0.7",
        "output": "def handle_user_exception(\n        self, e: Exception\n    ) -> HTTPException | ft.ResponseReturnValue:\n        \"\"\"This method is called whenever an exception occurs that\n        should be handled. A special case is :class:`~werkzeug\n        .exceptions.HTTPException` which is forwarded to the\n        :meth:`handle_http_exception` method. This function will either\n        return a response value or reraise the exception with the same\n        traceback.\n\n        .. versionchanged:: 1.0\n            Key errors raised from request data like ``form`` show the\n            bad key in debug mode rather than a generic bad request\n            message.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        if isinstance(e, BadRequestKeyError) and (\n            self.debug or self.config[\"TRAP_BAD_REQUEST_ERRORS\"]\n        ):\n            e.show_exception = True\n\n        if isinstance(e, HTTPException) and not self.trap_http_exception(e):\n            return self.handle_http_exception(e)\n\n        handler = self._find_error_handler(e, request.blueprints)\n\n        if handler is None:\n            raise\n\n        return self.ensure_sync(handler)(e)  # type: ignore[no-any-return]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "handle_exception",
        "input": "Handle an exception that did not have an error handler\nassociated with it, or that was raised from an error handler.\nThis always causes a 500 ``InternalServerError``.\n\nAlways sends the :data:`got_request_exception` signal.\n\nIf :data:`PROPAGATE_EXCEPTIONS` is ``True``, such as in debug\nmode, the error will be re-raised so that the debugger can\ndisplay it. Otherwise, the original exception is logged, and\nan :exc:`~werkzeug.exceptions.InternalServerError` is returned.\n\nIf an error handler is registered for ``InternalServerError`` or\n``500``, it will be used. For consistency, the handler will\nalways receive the ``InternalServerError``. The original\nunhandled exception is available as ``e.original_exception``.\n\n.. versionchanged:: 1.1.0\n    Always passes the ``InternalServerError`` instance to the\n    handler, setting ``original_exception`` to the unhandled\n    error.\n\n.. versionchanged:: 1.1.0\n    ``after_request`` functions and other finalization is done\n    even for the default 500 response when there is no handler.\n\n.. versionadded:: 0.3",
        "output": "def handle_exception(self, e: Exception) -> Response:\n        \"\"\"Handle an exception that did not have an error handler\n        associated with it, or that was raised from an error handler.\n        This always causes a 500 ``InternalServerError``.\n\n        Always sends the :data:`got_request_exception` signal.\n\n        If :data:`PROPAGATE_EXCEPTIONS` is ``True``, such as in debug\n        mode, the error will be re-raised so that the debugger can\n        display it. Otherwise, the original exception is logged, and\n        an :exc:`~werkzeug.exceptions.InternalServerError` is returned.\n\n        If an error handler is registered for ``InternalServerError`` or\n        ``500``, it will be used. For consistency, the handler will\n        always receive the ``InternalServerError``. The original\n        unhandled exception is available as ``e.original_exception``.\n\n        .. versionchanged:: 1.1.0\n            Always passes the ``InternalServerError`` instance to the\n            handler, setting ``original_exception`` to the unhandled\n            error.\n\n        .. versionchanged:: 1.1.0\n            ``after_request`` functions and other finalization is done\n            even for the default 500 response when there is no handler.\n\n        .. versionadded:: 0.3\n        \"\"\"\n        exc_info = sys.exc_info()\n        got_request_exception.send(self, _async_wrapper=self.ensure_sync, exception=e)\n        propagate = self.config[\"PROPAGATE_EXCEPTIONS\"]\n\n        if propagate is None:\n            propagate = self.testing or self.debug\n\n        if propagate:\n            # Re-raise if called with an active exception, otherwise\n            # raise the passed in exception.\n            if exc_info[1] is e:\n                raise\n\n            raise e\n\n        self.log_exception(exc_info)\n        server_error: InternalServerError | ft.ResponseReturnValue\n        server_error = InternalServerError(original_exception=e)\n        handler = self._find_error_handler(server_error, request.blueprints)\n\n        if handler is not None:\n            server_error = self.ensure_sync(handler)(server_error)\n\n        return self.finalize_request(server_error, from_error_handler=True)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "log_exception",
        "input": "Logs an exception.  This is called by :meth:`handle_exception`\nif debugging is disabled and right before the handler is called.\nThe default implementation logs the exception as error on the\n:attr:`logger`.\n\n.. versionadded:: 0.8",
        "output": "def log_exception(\n        self,\n        exc_info: (tuple[type, BaseException, TracebackType] | tuple[None, None, None]),\n    ) -> None:\n        \"\"\"Logs an exception.  This is called by :meth:`handle_exception`\n        if debugging is disabled and right before the handler is called.\n        The default implementation logs the exception as error on the\n        :attr:`logger`.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        self.logger.error(\n            f\"Exception on {request.path} [{request.method}]\", exc_info=exc_info\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dispatch_request",
        "input": "Does the request dispatching.  Matches the URL and returns the\nreturn value of the view or error handler.  This does not have to\nbe a response object.  In order to convert the return value to a\nproper response object, call :func:`make_response`.\n\n.. versionchanged:: 0.7\n   This no longer does the exception handling, this code was\n   moved to the new :meth:`full_dispatch_request`.",
        "output": "def dispatch_request(self) -> ft.ResponseReturnValue:\n        \"\"\"Does the request dispatching.  Matches the URL and returns the\n        return value of the view or error handler.  This does not have to\n        be a response object.  In order to convert the return value to a\n        proper response object, call :func:`make_response`.\n\n        .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.\n        \"\"\"\n        req = request_ctx.request\n        if req.routing_exception is not None:\n            self.raise_routing_exception(req)\n        rule: Rule = req.url_rule  # type: ignore[assignment]\n        # if we provide automatic options for this URL and the\n        # request came with the OPTIONS method, reply automatically\n        if (\n            getattr(rule, \"provide_automatic_options\", False)\n            and req.method == \"OPTIONS\"\n        ):\n            return self.make_default_options_response()\n        # otherwise dispatch to the handler for that endpoint\n        view_args: dict[str, t.Any] = req.view_args  # type: ignore[assignment]\n        return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "full_dispatch_request",
        "input": "Dispatches the request and on top of that performs request\npre and postprocessing as well as HTTP exception catching and\nerror handling.\n\n.. versionadded:: 0.7",
        "output": "def full_dispatch_request(self) -> Response:\n        \"\"\"Dispatches the request and on top of that performs request\n        pre and postprocessing as well as HTTP exception catching and\n        error handling.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        self._got_first_request = True\n\n        try:\n            request_started.send(self, _async_wrapper=self.ensure_sync)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n        except Exception as e:\n            rv = self.handle_user_exception(e)\n        return self.finalize_request(rv)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "finalize_request",
        "input": "Given the return value from a view function this finalizes\nthe request by converting it into a response and invoking the\npostprocessing functions.  This is invoked for both normal\nrequest dispatching as well as error handlers.\n\nBecause this means that it might be called as a result of a\nfailure a special safe mode is available which can be enabled\nwith the `from_error_handler` flag.  If enabled, failures in\nresponse processing will be logged and otherwise ignored.\n\n:internal:",
        "output": "def finalize_request(\n        self,\n        rv: ft.ResponseReturnValue | HTTPException,\n        from_error_handler: bool = False,\n    ) -> Response:\n        \"\"\"Given the return value from a view function this finalizes\n        the request by converting it into a response and invoking the\n        postprocessing functions.  This is invoked for both normal\n        request dispatching as well as error handlers.\n\n        Because this means that it might be called as a result of a\n        failure a special safe mode is available which can be enabled\n        with the `from_error_handler` flag.  If enabled, failures in\n        response processing will be logged and otherwise ignored.\n\n        :internal:\n        \"\"\"\n        response = self.make_response(rv)\n        try:\n            response = self.process_response(response)\n            request_finished.send(\n                self, _async_wrapper=self.ensure_sync, response=response\n            )\n        except Exception:\n            if not from_error_handler:\n                raise\n            self.logger.exception(\n                \"Request finalizing failed with an error while handling an error\"\n            )\n        return response"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "make_default_options_response",
        "input": "This method is called to create the default ``OPTIONS`` response.\nThis can be changed through subclassing to change the default\nbehavior of ``OPTIONS`` responses.\n\n.. versionadded:: 0.7",
        "output": "def make_default_options_response(self) -> Response:\n        \"\"\"This method is called to create the default ``OPTIONS`` response.\n        This can be changed through subclassing to change the default\n        behavior of ``OPTIONS`` responses.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        adapter = request_ctx.url_adapter\n        methods = adapter.allowed_methods()  # type: ignore[union-attr]\n        rv = self.response_class()\n        rv.allow.update(methods)\n        return rv"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "ensure_sync",
        "input": "Ensure that the function is synchronous for WSGI workers.\nPlain ``def`` functions are returned as-is. ``async def``\nfunctions are wrapped to run and wait for the response.\n\nOverride this method to change how the app runs async views.\n\n.. versionadded:: 2.0",
        "output": "def ensure_sync(self, func: t.Callable[..., t.Any]) -> t.Callable[..., t.Any]:\n        \"\"\"Ensure that the function is synchronous for WSGI workers.\n        Plain ``def`` functions are returned as-is. ``async def``\n        functions are wrapped to run and wait for the response.\n\n        Override this method to change how the app runs async views.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        if iscoroutinefunction(func):\n            return self.async_to_sync(func)\n\n        return func"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "async_to_sync",
        "input": "Return a sync function that will run the coroutine function.\n\n.. code-block:: python\n\n    result = app.async_to_sync(func)(*args, **kwargs)\n\nOverride this method to change how the app converts async code\nto be synchronously callable.\n\n.. versionadded:: 2.0",
        "output": "def async_to_sync(\n        self, func: t.Callable[..., t.Coroutine[t.Any, t.Any, t.Any]]\n    ) -> t.Callable[..., t.Any]:\n        \"\"\"Return a sync function that will run the coroutine function.\n\n        .. code-block:: python\n\n            result = app.async_to_sync(func)(*args, **kwargs)\n\n        Override this method to change how the app converts async code\n        to be synchronously callable.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        try:\n            from asgiref.sync import async_to_sync as asgiref_async_to_sync\n        except ImportError:\n            raise RuntimeError(\n                \"Install Flask with the 'async' extra in order to use async views.\"\n            ) from None\n\n        return asgiref_async_to_sync(func)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "url_for",
        "input": "Generate a URL to the given endpoint with the given values.\n\nThis is called by :func:`flask.url_for`, and can be called\ndirectly as well.\n\nAn *endpoint* is the name of a URL rule, usually added with\n:meth:`@app.route() <route>`, and usually the same name as the\nview function. A route defined in a :class:`~flask.Blueprint`\nwill prepend the blueprint's name separated by a ``.`` to the\nendpoint.\n\nIn some cases, such as email messages, you want URLs to include\nthe scheme and domain, like ``https://example.com/hello``. When\nnot in an active request, URLs will be external by default, but\nthis requires setting :data:`SERVER_NAME` so Flask knows what\ndomain to use. :data:`APPLICATION_ROOT` and\n:data:`PREFERRED_URL_SCHEME` should also be configured as\nneeded. This config is only used when not in an active request.\n\nFunctions can be decorated with :meth:`url_defaults` to modify\nkeyword arguments before the URL is built.\n\nIf building fails for some reason, such as an unknown endpoint\nor incorrect values, the app's :meth:`handle_url_build_error`\nmethod is called. If that returns a string, that is returned,\notherwise a :exc:`~werkzeug.routing.BuildError` is raised.\n\n:param endpoint: The endpoint name associated with the URL to\n    generate. If this starts with a ``.``, the current blueprint\n    name (if any) will be used.\n:param _anchor: If given, append this as ``#anchor`` to the URL.\n:param _method: If given, generate the URL associated with this\n    method for the endpoint.\n:param _scheme: If given, the URL will have this scheme if it\n    is external.\n:param _external: If given, prefer the URL to be internal\n    (False) or require it to be external (True). External URLs\n    include the scheme and domain. When not in an active\n    request, URLs are external by default.\n:param values: Values to use for the variable parts of the URL\n    rule. Unknown keys are appended as query string arguments,\n    like ``?a=b&c=d``.\n\n.. versionadded:: 2.2\n    Moved from ``flask.url_for``, which calls this method.",
        "output": "def url_for(\n        self,\n        /,\n        endpoint: str,\n        *,\n        _anchor: str | None = None,\n        _method: str | None = None,\n        _scheme: str | None = None,\n        _external: bool | None = None,\n        **values: t.Any,\n    ) -> str:\n        \"\"\"Generate a URL to the given endpoint with the given values.\n\n        This is called by :func:`flask.url_for`, and can be called\n        directly as well.\n\n        An *endpoint* is the name of a URL rule, usually added with\n        :meth:`@app.route() <route>`, and usually the same name as the\n        view function. A route defined in a :class:`~flask.Blueprint`\n        will prepend the blueprint's name separated by a ``.`` to the\n        endpoint.\n\n        In some cases, such as email messages, you want URLs to include\n        the scheme and domain, like ``https://example.com/hello``. When\n        not in an active request, URLs will be external by default, but\n        this requires setting :data:`SERVER_NAME` so Flask knows what\n        domain to use. :data:`APPLICATION_ROOT` and\n        :data:`PREFERRED_URL_SCHEME` should also be configured as\n        needed. This config is only used when not in an active request.\n\n        Functions can be decorated with :meth:`url_defaults` to modify\n        keyword arguments before the URL is built.\n\n        If building fails for some reason, such as an unknown endpoint\n        or incorrect values, the app's :meth:`handle_url_build_error`\n        method is called. If that returns a string, that is returned,\n        otherwise a :exc:`~werkzeug.routing.BuildError` is raised.\n\n        :param endpoint: The endpoint name associated with the URL to\n            generate. If this starts with a ``.``, the current blueprint\n            name (if any) will be used.\n        :param _anchor: If given, append this as ``#anchor`` to the URL.\n        :param _method: If given, generate the URL associated with this\n            method for the endpoint.\n        :param _scheme: If given, the URL will have this scheme if it\n            is external.\n        :param _external: If given, prefer the URL to be internal\n            (False) or require it to be external (True). External URLs\n            include the scheme and domain. When not in an active\n            request, URLs are external by default.\n        :param values: Values to use for the variable parts of the URL\n            rule. Unknown keys are appended as query string arguments,\n            like ``?a=b&c=d``.\n\n        .. versionadded:: 2.2\n            Moved from ``flask.url_for``, which calls this method.\n        \"\"\"\n        req_ctx = _cv_request.get(None)\n\n        if req_ctx is not None:\n            url_adapter = req_ctx.url_adapter\n            blueprint_name = req_ctx.request.blueprint\n\n            # If the endpoint starts with \".\" and the request matches a\n            # blueprint, the endpoint is relative to the blueprint.\n            if endpoint[:1] == \".\":\n                if blueprint_name is not None:\n                    endpoint = f\"{blueprint_name}{endpoint}\"\n                else:\n                    endpoint = endpoint[1:]\n\n            # When in a request, generate a URL without scheme and\n            # domain by default, unless a scheme is given.\n            if _external is None:\n                _external = _scheme is not None\n        else:\n            app_ctx = _cv_app.get(None)\n\n            # If called by helpers.url_for, an app context is active,\n            # use its url_adapter. Otherwise, app.url_for was called\n            # directly, build an adapter.\n            if app_ctx is not None:\n                url_adapter = app_ctx.url_adapter\n            else:\n                url_adapter = self.create_url_adapter(None)\n\n            if url_adapter is None:\n                raise RuntimeError(\n                    \"Unable to build URLs outside an active request\"\n                    \" without 'SERVER_NAME' configured. Also configure\"\n                    \" 'APPLICATION_ROOT' and 'PREFERRED_URL_SCHEME' as\"\n                    \" needed.\"\n                )\n\n            # When outside a request, generate a URL with scheme and\n            # domain by default.\n            if _external is None:\n                _external = True\n\n        # It is an error to set _scheme when _external=False, in order\n        # to avoid accidental insecure URLs.\n        if _scheme is not None and not _external:\n            raise ValueError(\"When specifying '_scheme', '_external' must be True.\")\n\n        self.inject_url_defaults(endpoint, values)\n\n        try:\n            rv = url_adapter.build(  # type: ignore[union-attr]\n                endpoint,\n                values,\n                method=_method,\n                url_scheme=_scheme,\n                force_external=_external,\n            )\n        except BuildError as error:\n            values.update(\n                _anchor=_anchor, _method=_method, _scheme=_scheme, _external=_external\n            )\n            return self.handle_url_build_error(error, endpoint, values)\n\n        if _anchor is not None:\n            _anchor = _url_quote(_anchor, safe=\"%!#$&'()*+,/:;=?@\")\n            rv = f\"{rv}#{_anchor}\"\n\n        return rv"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "make_response",
        "input": "Convert the return value from a view function to an instance of\n:attr:`response_class`.\n\n:param rv: the return value from the view function. The view function\n    must return a response. Returning ``None``, or the view ending\n    without returning, is not allowed. The following types are allowed\n    for ``view_rv``:\n\n    ``str``\n        A response object is created with the string encoded to UTF-8\n        as the body.\n\n    ``bytes``\n        A response object is created with the bytes as the body.\n\n    ``dict``\n        A dictionary that will be jsonify'd before being returned.\n\n    ``list``\n        A list that will be jsonify'd before being returned.\n\n    ``generator`` or ``iterator``\n        A generator that returns ``str`` or ``bytes`` to be\n        streamed as the response.\n\n    ``tuple``\n        Either ``(body, status, headers)``, ``(body, status)``, or\n        ``(body, headers)``, where ``body`` is any of the other types\n        allowed here, ``status`` is a string or an integer, and\n        ``headers`` is a dictionary or a list of ``(key, value)``\n        tuples. If ``body`` is a :attr:`response_class` instance,\n        ``status`` overwrites the exiting value and ``headers`` are\n        extended.\n\n    :attr:`response_class`\n        The object is returned unchanged.\n\n    other :class:`~werkzeug.wrappers.Response` class\n        The object is coerced to :attr:`response_class`.\n\n    :func:`callable`\n        The function is called as a WSGI application. The result is\n        used to create a response object.\n\n.. versionchanged:: 2.2\n    A generator will be converted to a streaming response.\n    A list will be converted to a JSON response.\n\n.. versionchanged:: 1.1\n    A dict will be converted to a JSON response.\n\n.. versionchanged:: 0.9\n   Previously a tuple was interpreted as the arguments for the\n   response object.",
        "output": "def make_response(self, rv: ft.ResponseReturnValue) -> Response:\n        \"\"\"Convert the return value from a view function to an instance of\n        :attr:`response_class`.\n\n        :param rv: the return value from the view function. The view function\n            must return a response. Returning ``None``, or the view ending\n            without returning, is not allowed. The following types are allowed\n            for ``view_rv``:\n\n            ``str``\n                A response object is created with the string encoded to UTF-8\n                as the body.\n\n            ``bytes``\n                A response object is created with the bytes as the body.\n\n            ``dict``\n                A dictionary that will be jsonify'd before being returned.\n\n            ``list``\n                A list that will be jsonify'd before being returned.\n\n            ``generator`` or ``iterator``\n                A generator that returns ``str`` or ``bytes`` to be\n                streamed as the response.\n\n            ``tuple``\n                Either ``(body, status, headers)``, ``(body, status)``, or\n                ``(body, headers)``, where ``body`` is any of the other types\n                allowed here, ``status`` is a string or an integer, and\n                ``headers`` is a dictionary or a list of ``(key, value)``\n                tuples. If ``body`` is a :attr:`response_class` instance,\n                ``status`` overwrites the exiting value and ``headers`` are\n                extended.\n\n            :attr:`response_class`\n                The object is returned unchanged.\n\n            other :class:`~werkzeug.wrappers.Response` class\n                The object is coerced to :attr:`response_class`.\n\n            :func:`callable`\n                The function is called as a WSGI application. The result is\n                used to create a response object.\n\n        .. versionchanged:: 2.2\n            A generator will be converted to a streaming response.\n            A list will be converted to a JSON response.\n\n        .. versionchanged:: 1.1\n            A dict will be converted to a JSON response.\n\n        .. versionchanged:: 0.9\n           Previously a tuple was interpreted as the arguments for the\n           response object.\n        \"\"\"\n\n        status: int | None = None\n        headers: HeadersValue | None = None\n\n        # unpack tuple returns\n        if isinstance(rv, tuple):\n            len_rv = len(rv)\n\n            # a 3-tuple is unpacked directly\n            if len_rv == 3:\n                rv, status, headers = rv  # type: ignore[misc]\n            # decide if a 2-tuple has status or headers\n            elif len_rv == 2:\n                if isinstance(rv[1], (Headers, dict, tuple, list)):\n                    rv, headers = rv  # pyright: ignore\n                else:\n                    rv, status = rv  # type: ignore[assignment,misc]\n            # other sized tuples are not allowed\n            else:\n                raise TypeError(\n                    \"The view function did not return a valid response tuple.\"\n                    \" The tuple must have the form (body, status, headers),\"\n                    \" (body, status), or (body, headers).\"\n                )\n\n        # the body must not be None\n        if rv is None:\n            raise TypeError(\n                f\"The view function for {request.endpoint!r} did not\"\n                \" return a valid response. The function either returned\"\n                \" None or ended without a return statement.\"\n            )\n\n        # make sure the body is an instance of the response class\n        if not isinstance(rv, self.response_class):\n            if isinstance(rv, (str, bytes, bytearray)) or isinstance(rv, cabc.Iterator):\n                # let the response class set the status and headers instead of\n                # waiting to do it manually, so that the class can handle any\n                # special logic\n                rv = self.response_class(\n                    rv,\n                    status=status,\n                    headers=headers,  # type: ignore[arg-type]\n                )\n                status = headers = None\n            elif isinstance(rv, (dict, list)):\n                rv = self.json.response(rv)\n            elif isinstance(rv, BaseResponse) or callable(rv):\n                # evaluate a WSGI callable, or coerce a different response\n                # class to the correct type\n                try:\n                    rv = self.response_class.force_type(\n                        rv,  # type: ignore[arg-type]\n                        request.environ,\n                    )\n                except TypeError as e:\n                    raise TypeError(\n                        f\"{e}\\nThe view function did not return a valid\"\n                        \" response. The return type must be a string,\"\n                        \" dict, list, tuple with headers or status,\"\n                        \" Response instance, or WSGI callable, but it\"\n                        f\" was a {type(rv).__name__}.\"\n                    ).with_traceback(sys.exc_info()[2]) from None\n            else:\n                raise TypeError(\n                    \"The view function did not return a valid\"\n                    \" response. The return type must be a string,\"\n                    \" dict, list, tuple with headers or status,\"\n                    \" Response instance, or WSGI callable, but it was a\"\n                    f\" {type(rv).__name__}.\"\n                )\n\n        rv = t.cast(Response, rv)\n        # prefer the status if it was provided\n        if status is not None:\n            if isinstance(status, (str, bytes, bytearray)):\n                rv.status = status\n            else:\n                rv.status_code = status\n\n        # extend existing headers with provided headers\n        if headers:\n            rv.headers.update(headers)\n\n        return rv"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "preprocess_request",
        "input": "Called before the request is dispatched. Calls\n:attr:`url_value_preprocessors` registered with the app and the\ncurrent blueprint (if any). Then calls :attr:`before_request_funcs`\nregistered with the app and the blueprint.\n\nIf any :meth:`before_request` handler returns a non-None value, the\nvalue is handled as if it was the return value from the view, and\nfurther request handling is stopped.",
        "output": "def preprocess_request(self) -> ft.ResponseReturnValue | None:\n        \"\"\"Called before the request is dispatched. Calls\n        :attr:`url_value_preprocessors` registered with the app and the\n        current blueprint (if any). Then calls :attr:`before_request_funcs`\n        registered with the app and the blueprint.\n\n        If any :meth:`before_request` handler returns a non-None value, the\n        value is handled as if it was the return value from the view, and\n        further request handling is stopped.\n        \"\"\"\n        names = (None, *reversed(request.blueprints))\n\n        for name in names:\n            if name in self.url_value_preprocessors:\n                for url_func in self.url_value_preprocessors[name]:\n                    url_func(request.endpoint, request.view_args)\n\n        for name in names:\n            if name in self.before_request_funcs:\n                for before_func in self.before_request_funcs[name]:\n                    rv = self.ensure_sync(before_func)()\n\n                    if rv is not None:\n                        return rv  # type: ignore[no-any-return]\n\n        return None"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "process_response",
        "input": "Can be overridden in order to modify the response object\nbefore it's sent to the WSGI server.  By default this will\ncall all the :meth:`after_request` decorated functions.\n\n.. versionchanged:: 0.5\n   As of Flask 0.5 the functions registered for after request\n   execution are called in reverse order of registration.\n\n:param response: a :attr:`response_class` object.\n:return: a new response object or the same, has to be an\n         instance of :attr:`response_class`.",
        "output": "def process_response(self, response: Response) -> Response:\n        \"\"\"Can be overridden in order to modify the response object\n        before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions.\n\n        .. versionchanged:: 0.5\n           As of Flask 0.5 the functions registered for after request\n           execution are called in reverse order of registration.\n\n        :param response: a :attr:`response_class` object.\n        :return: a new response object or the same, has to be an\n                 instance of :attr:`response_class`.\n        \"\"\"\n        ctx = request_ctx._get_current_object()  # type: ignore[attr-defined]\n\n        for func in ctx._after_request_functions:\n            response = self.ensure_sync(func)(response)\n\n        for name in chain(request.blueprints, (None,)):\n            if name in self.after_request_funcs:\n                for func in reversed(self.after_request_funcs[name]):\n                    response = self.ensure_sync(func)(response)\n\n        if not self.session_interface.is_null_session(ctx.session):\n            self.session_interface.save_session(self, ctx.session, response)\n\n        return response"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "do_teardown_request",
        "input": "Called after the request is dispatched and the response is\nreturned, right before the request context is popped.\n\nThis calls all functions decorated with\n:meth:`teardown_request`, and :meth:`Blueprint.teardown_request`\nif a blueprint handled the request. Finally, the\n:data:`request_tearing_down` signal is sent.\n\nThis is called by\n:meth:`RequestContext.pop() <flask.ctx.RequestContext.pop>`,\nwhich may be delayed during testing to maintain access to\nresources.\n\n:param exc: An unhandled exception raised while dispatching the\n    request. Detected from the current exception information if\n    not passed. Passed to each teardown function.\n\n.. versionchanged:: 0.9\n    Added the ``exc`` argument.",
        "output": "def do_teardown_request(\n        self,\n        exc: BaseException | None = _sentinel,  # type: ignore[assignment]\n    ) -> None:\n        \"\"\"Called after the request is dispatched and the response is\n        returned, right before the request context is popped.\n\n        This calls all functions decorated with\n        :meth:`teardown_request`, and :meth:`Blueprint.teardown_request`\n        if a blueprint handled the request. Finally, the\n        :data:`request_tearing_down` signal is sent.\n\n        This is called by\n        :meth:`RequestContext.pop() <flask.ctx.RequestContext.pop>`,\n        which may be delayed during testing to maintain access to\n        resources.\n\n        :param exc: An unhandled exception raised while dispatching the\n            request. Detected from the current exception information if\n            not passed. Passed to each teardown function.\n\n        .. versionchanged:: 0.9\n            Added the ``exc`` argument.\n        \"\"\"\n        if exc is _sentinel:\n            exc = sys.exc_info()[1]\n\n        for name in chain(request.blueprints, (None,)):\n            if name in self.teardown_request_funcs:\n                for func in reversed(self.teardown_request_funcs[name]):\n                    self.ensure_sync(func)(exc)\n\n        request_tearing_down.send(self, _async_wrapper=self.ensure_sync, exc=exc)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "do_teardown_appcontext",
        "input": "Called right before the application context is popped.\n\nWhen handling a request, the application context is popped\nafter the request context. See :meth:`do_teardown_request`.\n\nThis calls all functions decorated with\n:meth:`teardown_appcontext`. Then the\n:data:`appcontext_tearing_down` signal is sent.\n\nThis is called by\n:meth:`AppContext.pop() <flask.ctx.AppContext.pop>`.\n\n.. versionadded:: 0.9",
        "output": "def do_teardown_appcontext(\n        self,\n        exc: BaseException | None = _sentinel,  # type: ignore[assignment]\n    ) -> None:\n        \"\"\"Called right before the application context is popped.\n\n        When handling a request, the application context is popped\n        after the request context. See :meth:`do_teardown_request`.\n\n        This calls all functions decorated with\n        :meth:`teardown_appcontext`. Then the\n        :data:`appcontext_tearing_down` signal is sent.\n\n        This is called by\n        :meth:`AppContext.pop() <flask.ctx.AppContext.pop>`.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        if exc is _sentinel:\n            exc = sys.exc_info()[1]\n\n        for func in reversed(self.teardown_appcontext_funcs):\n            self.ensure_sync(func)(exc)\n\n        appcontext_tearing_down.send(self, _async_wrapper=self.ensure_sync, exc=exc)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "app_context",
        "input": "Create an :class:`~flask.ctx.AppContext`. Use as a ``with``\nblock to push the context, which will make :data:`current_app`\npoint at this application.\n\nAn application context is automatically pushed by\n:meth:`RequestContext.push() <flask.ctx.RequestContext.push>`\nwhen handling a request, and when running a CLI command. Use\nthis to manually create a context outside of these situations.\n\n::\n\n    with app.app_context():\n        init_db()\n\nSee :doc:`/appcontext`.\n\n.. versionadded:: 0.9",
        "output": "def app_context(self) -> AppContext:\n        \"\"\"Create an :class:`~flask.ctx.AppContext`. Use as a ``with``\n        block to push the context, which will make :data:`current_app`\n        point at this application.\n\n        An application context is automatically pushed by\n        :meth:`RequestContext.push() <flask.ctx.RequestContext.push>`\n        when handling a request, and when running a CLI command. Use\n        this to manually create a context outside of these situations.\n\n        ::\n\n            with app.app_context():\n                init_db()\n\n        See :doc:`/appcontext`.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        return AppContext(self)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "request_context",
        "input": "Create a :class:`~flask.ctx.RequestContext` representing a\nWSGI environment. Use a ``with`` block to push the context,\nwhich will make :data:`request` point at this request.\n\nSee :doc:`/reqcontext`.\n\nTypically you should not call this from your own code. A request\ncontext is automatically pushed by the :meth:`wsgi_app` when\nhandling a request. Use :meth:`test_request_context` to create\nan environment and context instead of this method.\n\n:param environ: a WSGI environment",
        "output": "def request_context(self, environ: WSGIEnvironment) -> RequestContext:\n        \"\"\"Create a :class:`~flask.ctx.RequestContext` representing a\n        WSGI environment. Use a ``with`` block to push the context,\n        which will make :data:`request` point at this request.\n\n        See :doc:`/reqcontext`.\n\n        Typically you should not call this from your own code. A request\n        context is automatically pushed by the :meth:`wsgi_app` when\n        handling a request. Use :meth:`test_request_context` to create\n        an environment and context instead of this method.\n\n        :param environ: a WSGI environment\n        \"\"\"\n        return RequestContext(self, environ)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "test_request_context",
        "input": "Create a :class:`~flask.ctx.RequestContext` for a WSGI\nenvironment created from the given values. This is mostly useful\nduring testing, where you may want to run a function that uses\nrequest data without dispatching a full request.\n\nSee :doc:`/reqcontext`.\n\nUse a ``with`` block to push the context, which will make\n:data:`request` point at the request for the created\nenvironment. ::\n\n    with app.test_request_context(...):\n        generate_report()\n\nWhen using the shell, it may be easier to push and pop the\ncontext manually to avoid indentation. ::\n\n    ctx = app.test_request_context(...)\n    ctx.push()\n    ...\n    ctx.pop()\n\nTakes the same arguments as Werkzeug's\n:class:`~werkzeug.test.EnvironBuilder`, with some defaults from\nthe application. See the linked Werkzeug docs for most of the\navailable arguments. Flask-specific behavior is listed here.\n\n:param path: URL path being requested.\n:param base_url: Base URL where the app is being served, which\n    ``path`` is relative to. If not given, built from\n    :data:`PREFERRED_URL_SCHEME`, ``subdomain``,\n    :data:`SERVER_NAME`, and :data:`APPLICATION_ROOT`.\n:param subdomain: Subdomain name to append to\n    :data:`SERVER_NAME`.\n:param url_scheme: Scheme to use instead of\n    :data:`PREFERRED_URL_SCHEME`.\n:param data: The request body, either as a string or a dict of\n    form keys and values.\n:param json: If given, this is serialized as JSON and passed as\n    ``data``. Also defaults ``content_type`` to\n    ``application/json``.\n:param args: other positional arguments passed to\n    :class:`~werkzeug.test.EnvironBuilder`.\n:param kwargs: other keyword arguments passed to\n    :class:`~werkzeug.test.EnvironBuilder`.",
        "output": "def test_request_context(self, *args: t.Any, **kwargs: t.Any) -> RequestContext:\n        \"\"\"Create a :class:`~flask.ctx.RequestContext` for a WSGI\n        environment created from the given values. This is mostly useful\n        during testing, where you may want to run a function that uses\n        request data without dispatching a full request.\n\n        See :doc:`/reqcontext`.\n\n        Use a ``with`` block to push the context, which will make\n        :data:`request` point at the request for the created\n        environment. ::\n\n            with app.test_request_context(...):\n                generate_report()\n\n        When using the shell, it may be easier to push and pop the\n        context manually to avoid indentation. ::\n\n            ctx = app.test_request_context(...)\n            ctx.push()\n            ...\n            ctx.pop()\n\n        Takes the same arguments as Werkzeug's\n        :class:`~werkzeug.test.EnvironBuilder`, with some defaults from\n        the application. See the linked Werkzeug docs for most of the\n        available arguments. Flask-specific behavior is listed here.\n\n        :param path: URL path being requested.\n        :param base_url: Base URL where the app is being served, which\n            ``path`` is relative to. If not given, built from\n            :data:`PREFERRED_URL_SCHEME`, ``subdomain``,\n            :data:`SERVER_NAME`, and :data:`APPLICATION_ROOT`.\n        :param subdomain: Subdomain name to append to\n            :data:`SERVER_NAME`.\n        :param url_scheme: Scheme to use instead of\n            :data:`PREFERRED_URL_SCHEME`.\n        :param data: The request body, either as a string or a dict of\n            form keys and values.\n        :param json: If given, this is serialized as JSON and passed as\n            ``data``. Also defaults ``content_type`` to\n            ``application/json``.\n        :param args: other positional arguments passed to\n            :class:`~werkzeug.test.EnvironBuilder`.\n        :param kwargs: other keyword arguments passed to\n            :class:`~werkzeug.test.EnvironBuilder`.\n        \"\"\"\n        from .testing import EnvironBuilder\n\n        builder = EnvironBuilder(self, *args, **kwargs)\n\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "wsgi_app",
        "input": "The actual WSGI application. This is not implemented in\n:meth:`__call__` so that middlewares can be applied without\nlosing a reference to the app object. Instead of doing this::\n\n    app = MyMiddleware(app)\n\nIt's a better idea to do this instead::\n\n    app.wsgi_app = MyMiddleware(app.wsgi_app)\n\nThen you still have the original application object around and\ncan continue to call methods on it.\n\n.. versionchanged:: 0.7\n    Teardown events for the request and app contexts are called\n    even if an unhandled error occurs. Other events may not be\n    called depending on when an error occurs during dispatch.\n    See :ref:`callbacks-and-errors`.\n\n:param environ: A WSGI environment.\n:param start_response: A callable accepting a status code,\n    a list of headers, and an optional exception context to\n    start the response.",
        "output": "def wsgi_app(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> cabc.Iterable[bytes]:\n        \"\"\"The actual WSGI application. This is not implemented in\n        :meth:`__call__` so that middlewares can be applied without\n        losing a reference to the app object. Instead of doing this::\n\n            app = MyMiddleware(app)\n\n        It's a better idea to do this instead::\n\n            app.wsgi_app = MyMiddleware(app.wsgi_app)\n\n        Then you still have the original application object around and\n        can continue to call methods on it.\n\n        .. versionchanged:: 0.7\n            Teardown events for the request and app contexts are called\n            even if an unhandled error occurs. Other events may not be\n            called depending on when an error occurs during dispatch.\n            See :ref:`callbacks-and-errors`.\n\n        :param environ: A WSGI environment.\n        :param start_response: A callable accepting a status code,\n            a list of headers, and an optional exception context to\n            start the response.\n        \"\"\"\n        ctx = self.request_context(environ)\n        error: BaseException | None = None\n        try:\n            try:\n                ctx.push()\n                response = self.full_dispatch_request()\n            except Exception as e:\n                error = e\n                response = self.handle_exception(e)\n            except:  # noqa: B001\n                error = sys.exc_info()[1]\n                raise\n            return response(environ, start_response)\n        finally:\n            if \"werkzeug.debug.preserve_context\" in environ:\n                environ[\"werkzeug.debug.preserve_context\"](_cv_app.get())\n                environ[\"werkzeug.debug.preserve_context\"](_cv_request.get())\n\n            if error is not None and self.should_ignore_error(error):\n                error = None\n\n            ctx.pop(error)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__call__",
        "input": "The WSGI server calls the Flask application object as the\nWSGI application. This calls :meth:`wsgi_app`, which can be\nwrapped to apply middleware.",
        "output": "def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> cabc.Iterable[bytes]:\n        \"\"\"The WSGI server calls the Flask application object as the\n        WSGI application. This calls :meth:`wsgi_app`, which can be\n        wrapped to apply middleware.\n        \"\"\"\n        return self.wsgi_app(environ, start_response)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_send_file_max_age",
        "input": "Used by :func:`send_file` to determine the ``max_age`` cache\nvalue for a given file path if it wasn't passed.\n\nBy default, this returns :data:`SEND_FILE_MAX_AGE_DEFAULT` from\nthe configuration of :data:`~flask.current_app`. This defaults\nto ``None``, which tells the browser to use conditional requests\ninstead of a timed cache, which is usually preferable.\n\nNote this is a duplicate of the same method in the Flask\nclass.\n\n.. versionchanged:: 2.0\n    The default configuration is ``None`` instead of 12 hours.\n\n.. versionadded:: 0.9",
        "output": "def get_send_file_max_age(self, filename: str | None) -> int | None:\n        \"\"\"Used by :func:`send_file` to determine the ``max_age`` cache\n        value for a given file path if it wasn't passed.\n\n        By default, this returns :data:`SEND_FILE_MAX_AGE_DEFAULT` from\n        the configuration of :data:`~flask.current_app`. This defaults\n        to ``None``, which tells the browser to use conditional requests\n        instead of a timed cache, which is usually preferable.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionchanged:: 2.0\n            The default configuration is ``None`` instead of 12 hours.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        value = current_app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n\n        if value is None:\n            return None\n\n        if isinstance(value, timedelta):\n            return int(value.total_seconds())\n\n        return value  # type: ignore[no-any-return]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "send_static_file",
        "input": "The view function used to serve files from\n:attr:`static_folder`. A route is automatically registered for\nthis view at :attr:`static_url_path` if :attr:`static_folder` is\nset.\n\nNote this is a duplicate of the same method in the Flask\nclass.\n\n.. versionadded:: 0.5",
        "output": "def send_static_file(self, filename: str) -> Response:\n        \"\"\"The view function used to serve files from\n        :attr:`static_folder`. A route is automatically registered for\n        this view at :attr:`static_url_path` if :attr:`static_folder` is\n        set.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionadded:: 0.5\n\n        \"\"\"\n        if not self.has_static_folder:\n            raise RuntimeError(\"'static_folder' must be set to serve static_files.\")\n\n        # send_file only knows to call get_send_file_max_age on the app,\n        # call it here so it works for blueprints too.\n        max_age = self.get_send_file_max_age(filename)\n        return send_from_directory(\n            t.cast(str, self.static_folder), filename, max_age=max_age\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "open_resource",
        "input": "Open a resource file relative to :attr:`root_path` for reading. The\nblueprint-relative equivalent of the app's :meth:`~.Flask.open_resource`\nmethod.\n\n:param resource: Path to the resource relative to :attr:`root_path`.\n:param mode: Open the file in this mode. Only reading is supported,\n    valid values are ``\"r\"`` (or ``\"rt\"``) and ``\"rb\"``.\n:param encoding: Open the file with this encoding when opening in text\n    mode. This is ignored when opening in binary mode.\n\n.. versionchanged:: 3.1\n    Added the ``encoding`` parameter.",
        "output": "def open_resource(\n        self, resource: str, mode: str = \"rb\", encoding: str | None = \"utf-8\"\n    ) -> t.IO[t.AnyStr]:\n        \"\"\"Open a resource file relative to :attr:`root_path` for reading. The\n        blueprint-relative equivalent of the app's :meth:`~.Flask.open_resource`\n        method.\n\n        :param resource: Path to the resource relative to :attr:`root_path`.\n        :param mode: Open the file in this mode. Only reading is supported,\n            valid values are ``\"r\"`` (or ``\"rt\"``) and ``\"rb\"``.\n        :param encoding: Open the file with this encoding when opening in text\n            mode. This is ignored when opening in binary mode.\n\n        .. versionchanged:: 3.1\n            Added the ``encoding`` parameter.\n        \"\"\"\n        if mode not in {\"r\", \"rt\", \"rb\"}:\n            raise ValueError(\"Resources can only be opened for reading.\")\n\n        path = os.path.join(self.root_path, resource)\n\n        if mode == \"rb\":\n            return open(path, mode)  # pyright: ignore\n\n        return open(path, mode, encoding=encoding)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "find_best_app",
        "input": "Given a module instance this tries to find the best possible\napplication in the module or raises an exception.",
        "output": "def find_best_app(module: ModuleType) -> Flask:\n    \"\"\"Given a module instance this tries to find the best possible\n    application in the module or raises an exception.\n    \"\"\"\n    from . import Flask\n\n    # Search for the most common names first.\n    for attr_name in (\"app\", \"application\"):\n        app = getattr(module, attr_name, None)\n\n        if isinstance(app, Flask):\n            return app\n\n    # Otherwise find the only object that is a Flask instance.\n    matches = [v for v in module.__dict__.values() if isinstance(v, Flask)]\n\n    if len(matches) == 1:\n        return matches[0]\n    elif len(matches) > 1:\n        raise NoAppException(\n            \"Detected multiple Flask applications in module\"\n            f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n            \" to specify the correct one.\"\n        )\n\n    # Search for app factory functions.\n    for attr_name in (\"create_app\", \"make_app\"):\n        app_factory = getattr(module, attr_name, None)\n\n        if inspect.isfunction(app_factory):\n            try:\n                app = app_factory()\n\n                if isinstance(app, Flask):\n                    return app\n            except TypeError as e:\n                if not _called_with_wrong_args(app_factory):\n                    raise\n\n                raise NoAppException(\n                    f\"Detected factory '{attr_name}' in module '{module.__name__}',\"\n                    \" but could not call it without arguments. Use\"\n                    f\" '{module.__name__}:{attr_name}(args)'\"\n                    \" to specify arguments.\"\n                ) from e\n\n    raise NoAppException(\n        \"Failed to find Flask application or factory in module\"\n        f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n        \" to specify one.\"\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_called_with_wrong_args",
        "input": "Check whether calling a function raised a ``TypeError`` because\nthe call failed or because something in the factory raised the\nerror.\n\n:param f: The function that was called.\n:return: ``True`` if the call failed.",
        "output": "def _called_with_wrong_args(f: t.Callable[..., Flask]) -> bool:\n    \"\"\"Check whether calling a function raised a ``TypeError`` because\n    the call failed or because something in the factory raised the\n    error.\n\n    :param f: The function that was called.\n    :return: ``True`` if the call failed.\n    \"\"\"\n    tb = sys.exc_info()[2]\n\n    try:\n        while tb is not None:\n            if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully.\n                return False\n\n            tb = tb.tb_next\n\n        # Didn't reach the function.\n        return True\n    finally:\n        # Delete tb to break a circular reference.\n        # https://docs.python.org/2/library/sys.html#sys.exc_info\n        del tb"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "find_app_by_string",
        "input": "Check if the given string is a variable name or a function. Call\na function to get the app instance, or return the variable directly.",
        "output": "def find_app_by_string(module: ModuleType, app_name: str) -> Flask:\n    \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.\n    \"\"\"\n    from . import Flask\n\n    # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) from None\n\n    if isinstance(expr, ast.Name):\n        name = expr.id\n        args = []\n        kwargs = {}\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {\n                kw.arg: ast.literal_eval(kw.value)\n                for kw in expr.keywords\n                if kw.arg is not None\n            }\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            ) from None\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        )\n\n    try:\n        attr = getattr(module, name)\n    except AttributeError as e:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) from e\n\n    # If the attribute is a function, call it with any args and kwargs\n    # to get the real application.\n    if inspect.isfunction(attr):\n        try:\n            app = attr(*args, **kwargs)\n        except TypeError as e:\n            if not _called_with_wrong_args(attr):\n                raise\n\n            raise NoAppException(\n                f\"The factory {app_name!r} in module\"\n                f\" {module.__name__!r} could not be called with the\"\n                \" specified arguments.\"\n            ) from e\n    else:\n        app = attr\n\n    if isinstance(app, Flask):\n        return app\n\n    raise NoAppException(\n        \"A valid Flask application was not obtained from\"\n        f\" '{module.__name__}:{app_name}'.\"\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_import",
        "input": "Given a filename this will try to calculate the python path, add it\nto the search path and return the actual module name that is expected.",
        "output": "def prepare_import(path: str) -> str:\n    \"\"\"Given a filename this will try to calculate the python path, add it\n    to the search path and return the actual module name that is expected.\n    \"\"\"\n    path = os.path.realpath(path)\n\n    fname, ext = os.path.splitext(path)\n    if ext == \".py\":\n        path = fname\n\n    if os.path.basename(path) == \"__init__\":\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, \"__init__.py\")):\n            break\n\n    if sys.path[0] != path:\n        sys.path.insert(0, path)\n\n    return \".\".join(module_name[::-1])"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "with_appcontext",
        "input": "Wraps a callback so that it's guaranteed to be executed with the\nscript's application context.\n\nCustom commands (and their options) registered under ``app.cli`` or\n``blueprint.cli`` will always have an app context available, this\ndecorator is not required in that case.\n\n.. versionchanged:: 2.2\n    The app context is active for subcommands as well as the\n    decorated callback. The app context is always available to\n    ``app.cli`` command and parameter callbacks.",
        "output": "def with_appcontext(f: F) -> F:\n    \"\"\"Wraps a callback so that it's guaranteed to be executed with the\n    script's application context.\n\n    Custom commands (and their options) registered under ``app.cli`` or\n    ``blueprint.cli`` will always have an app context available, this\n    decorator is not required in that case.\n\n    .. versionchanged:: 2.2\n        The app context is active for subcommands as well as the\n        decorated callback. The app context is always available to\n        ``app.cli`` command and parameter callbacks.\n    \"\"\"\n\n    @click.pass_context\n    def decorator(ctx: click.Context, /, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        if not current_app:\n            app = ctx.ensure_object(ScriptInfo).load_app()\n            ctx.with_resource(app.app_context())\n\n        return ctx.invoke(f, *args, **kwargs)\n\n    return update_wrapper(decorator, f)  # type: ignore[return-value]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_path_is_ancestor",
        "input": "Take ``other`` and remove the length of ``path`` from it. Then join it\nto ``path``. If it is the original value, ``path`` is an ancestor of\n``other``.",
        "output": "def _path_is_ancestor(path: str, other: str) -> bool:\n    \"\"\"Take ``other`` and remove the length of ``path`` from it. Then join it\n    to ``path``. If it is the original value, ``path`` is an ancestor of\n    ``other``.\"\"\"\n    return os.path.join(path, other[len(path) :].lstrip(os.sep)) == other"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "load_dotenv",
        "input": "Load \"dotenv\" files to set environment variables. A given path takes\nprecedence over ``.env``, which takes precedence over ``.flaskenv``. After\nloading and combining these files, values are only set if the key is not\nalready set in ``os.environ``.\n\nThis is a no-op if `python-dotenv`_ is not installed.\n\n.. _python-dotenv: https://github.com/theskumar/python-dotenv#readme\n\n:param path: Load the file at this location.\n:param load_defaults: Search for and load the default ``.flaskenv`` and\n    ``.env`` files.\n:return: ``True`` if at least one env var was loaded.\n\n.. versionchanged:: 3.1\n    Added the ``load_defaults`` parameter. A given path takes precedence\n    over default files.\n\n.. versionchanged:: 2.0\n    The current directory is not changed to the location of the\n    loaded file.\n\n.. versionchanged:: 2.0\n    When loading the env files, set the default encoding to UTF-8.\n\n.. versionchanged:: 1.1.0\n    Returns ``False`` when python-dotenv is not installed, or when\n    the given path isn't a file.\n\n.. versionadded:: 1.0",
        "output": "def load_dotenv(\n    path: str | os.PathLike[str] | None = None, load_defaults: bool = True\n) -> bool:\n    \"\"\"Load \"dotenv\" files to set environment variables. A given path takes\n    precedence over ``.env``, which takes precedence over ``.flaskenv``. After\n    loading and combining these files, values are only set if the key is not\n    already set in ``os.environ``.\n\n    This is a no-op if `python-dotenv`_ is not installed.\n\n    .. _python-dotenv: https://github.com/theskumar/python-dotenv#readme\n\n    :param path: Load the file at this location.\n    :param load_defaults: Search for and load the default ``.flaskenv`` and\n        ``.env`` files.\n    :return: ``True`` if at least one env var was loaded.\n\n    .. versionchanged:: 3.1\n        Added the ``load_defaults`` parameter. A given path takes precedence\n        over default files.\n\n    .. versionchanged:: 2.0\n        The current directory is not changed to the location of the\n        loaded file.\n\n    .. versionchanged:: 2.0\n        When loading the env files, set the default encoding to UTF-8.\n\n    .. versionchanged:: 1.1.0\n        Returns ``False`` when python-dotenv is not installed, or when\n        the given path isn't a file.\n\n    .. versionadded:: 1.0\n    \"\"\"\n    try:\n        import dotenv\n    except ImportError:\n        if path or os.path.isfile(\".env\") or os.path.isfile(\".flaskenv\"):\n            click.secho(\n                \" * Tip: There are .env files present. Install python-dotenv\"\n                \" to use them.\",\n                fg=\"yellow\",\n                err=True,\n            )\n\n        return False\n\n    data: dict[str, str | None] = {}\n\n    if load_defaults:\n        for default_name in (\".flaskenv\", \".env\"):\n            if not (default_path := dotenv.find_dotenv(default_name, usecwd=True)):\n                continue\n\n            data |= dotenv.dotenv_values(default_path, encoding=\"utf-8\")\n\n    if path is not None and os.path.isfile(path):\n        data |= dotenv.dotenv_values(path, encoding=\"utf-8\")\n\n    for key, value in data.items():\n        if key in os.environ or value is None:\n            continue\n\n        os.environ[key] = value\n\n    return bool(data)  # True if at least one env var was loaded."
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "show_server_banner",
        "input": "Show extra startup messages the first time the server is run,\nignoring the reloader.",
        "output": "def show_server_banner(debug: bool, app_import_path: str | None) -> None:\n    \"\"\"Show extra startup messages the first time the server is run,\n    ignoring the reloader.\n    \"\"\"\n    if is_running_from_reloader():\n        return\n\n    if app_import_path is not None:\n        click.echo(f\" * Serving Flask app '{app_import_path}'\")\n\n    if debug is not None:\n        click.echo(f\" * Debug mode: {'on' if debug else 'off'}\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_validate_key",
        "input": "The ``--key`` option must be specified when ``--cert`` is a file.\nModifies the ``cert`` param to be a ``(cert, key)`` pair if needed.",
        "output": "def _validate_key(ctx: click.Context, param: click.Parameter, value: t.Any) -> t.Any:\n    \"\"\"The ``--key`` option must be specified when ``--cert`` is a file.\n    Modifies the ``cert`` param to be a ``(cert, key)`` pair if needed.\n    \"\"\"\n    cert = ctx.params.get(\"cert\")\n    is_adhoc = cert == \"adhoc\"\n\n    try:\n        import ssl\n    except ImportError:\n        is_context = False\n    else:\n        is_context = isinstance(cert, ssl.SSLContext)\n\n    if value is not None:\n        if is_adhoc:\n            raise click.BadParameter(\n                'When \"--cert\" is \"adhoc\", \"--key\" is not used.', ctx, param\n            )\n\n        if is_context:\n            raise click.BadParameter(\n                'When \"--cert\" is an SSLContext object, \"--key\" is not used.',\n                ctx,\n                param,\n            )\n\n        if not cert:\n            raise click.BadParameter('\"--cert\" must also be specified.', ctx, param)\n\n        ctx.params[\"cert\"] = cert, value\n\n    else:\n        if cert and not (is_adhoc or is_context):\n            raise click.BadParameter('Required when using \"--cert\".', ctx, param)\n\n    return value"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "run_command",
        "input": "Run a local development server.\n\nThis server is for development purposes only. It does not provide\nthe stability, security, or performance of production WSGI servers.\n\nThe reloader and debugger are enabled by default with the '--debug'\noption.",
        "output": "def run_command(\n    info: ScriptInfo,\n    host: str,\n    port: int,\n    reload: bool,\n    debugger: bool,\n    with_threads: bool,\n    cert: ssl.SSLContext | tuple[str, str | None] | t.Literal[\"adhoc\"] | None,\n    extra_files: list[str] | None,\n    exclude_patterns: list[str] | None,\n) -> None:\n    \"\"\"Run a local development server.\n\n    This server is for development purposes only. It does not provide\n    the stability, security, or performance of production WSGI servers.\n\n    The reloader and debugger are enabled by default with the '--debug'\n    option.\n    \"\"\"\n    try:\n        app: WSGIApplication = info.load_app()  # pyright: ignore\n    except Exception as e:\n        if is_running_from_reloader():\n            # When reloading, print out the error immediately, but raise\n            # it later so the debugger or server can handle it.\n            traceback.print_exc()\n            err = e\n\n            def app(\n                environ: WSGIEnvironment, start_response: StartResponse\n            ) -> cabc.Iterable[bytes]:\n                raise err from None\n\n        else:\n            # When not reloading, raise the error immediately so the\n            # command fails.\n            raise e from None\n\n    debug = get_debug_flag()\n\n    if reload is None:\n        reload = debug\n\n    if debugger is None:\n        debugger = debug\n\n    show_server_banner(debug, info.app_import_path)\n\n    run_simple(\n        host,\n        port,\n        app,\n        use_reloader=reload,\n        use_debugger=debugger,\n        threaded=with_threads,\n        ssl_context=cert,\n        extra_files=extra_files,\n        exclude_patterns=exclude_patterns,\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "shell_command",
        "input": "Run an interactive Python shell in the context of a given\nFlask application.  The application will populate the default\nnamespace of this shell according to its configuration.\n\nThis is useful for executing small snippets of management code\nwithout having to manually configure the application.",
        "output": "def shell_command() -> None:\n    \"\"\"Run an interactive Python shell in the context of a given\n    Flask application.  The application will populate the default\n    namespace of this shell according to its configuration.\n\n    This is useful for executing small snippets of management code\n    without having to manually configure the application.\n    \"\"\"\n    import code\n\n    banner = (\n        f\"Python {sys.version} on {sys.platform}\\n\"\n        f\"App: {current_app.import_name}\\n\"\n        f\"Instance: {current_app.instance_path}\"\n    )\n    ctx: dict[str, t.Any] = {}\n\n    # Support the regular Python interpreter startup script if someone\n    # is using it.\n    startup = os.environ.get(\"PYTHONSTARTUP\")\n    if startup and os.path.isfile(startup):\n        with open(startup) as f:\n            eval(compile(f.read(), startup, \"exec\"), ctx)\n\n    ctx.update(current_app.make_shell_context())\n\n    # Site, customize, or startup script can set a hook to call when\n    # entering interactive mode. The default one sets up readline with\n    # tab and history completion.\n    interactive_hook = getattr(sys, \"__interactivehook__\", None)\n\n    if interactive_hook is not None:\n        try:\n            import readline\n            from rlcompleter import Completer\n        except ImportError:\n            pass\n        else:\n            # rlcompleter uses __main__.__dict__ by default, which is\n            # flask.__main__. Use the shell context instead.\n            readline.set_completer(Completer(ctx).complete)\n\n        interactive_hook()\n\n    code.interact(banner=banner, local=ctx)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "routes_command",
        "input": "Show all registered routes with endpoints and methods.",
        "output": "def routes_command(sort: str, all_methods: bool) -> None:\n    \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n    rules = list(current_app.url_map.iter_rules())\n\n    if not rules:\n        click.echo(\"No routes were registered.\")\n        return\n\n    ignored_methods = set() if all_methods else {\"HEAD\", \"OPTIONS\"}\n    host_matching = current_app.url_map.host_matching\n    has_domain = any(rule.host if host_matching else rule.subdomain for rule in rules)\n    rows = []\n\n    for rule in rules:\n        row = [\n            rule.endpoint,\n            \", \".join(sorted((rule.methods or set()) - ignored_methods)),\n        ]\n\n        if has_domain:\n            row.append((rule.host if host_matching else rule.subdomain) or \"\")\n\n        row.append(rule.rule)\n        rows.append(row)\n\n    headers = [\"Endpoint\", \"Methods\"]\n    sorts = [\"endpoint\", \"methods\"]\n\n    if has_domain:\n        headers.append(\"Host\" if host_matching else \"Subdomain\")\n        sorts.append(\"domain\")\n\n    headers.append(\"Rule\")\n    sorts.append(\"rule\")\n\n    try:\n        rows.sort(key=itemgetter(sorts.index(sort)))\n    except ValueError:\n        pass\n\n    rows.insert(0, headers)\n    widths = [max(len(row[i]) for row in rows) for i in range(len(headers))]\n    rows.insert(1, [\"-\" * w for w in widths])\n    template = \"  \".join(f\"{{{i}:<{w}}}\" for i, w in enumerate(widths))\n\n    for row in rows:\n        click.echo(template.format(*row))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "load_app",
        "input": "Loads the Flask app (if not yet loaded) and returns it.  Calling\nthis multiple times will just result in the already loaded app to\nbe returned.",
        "output": "def load_app(self) -> Flask:\n        \"\"\"Loads the Flask app (if not yet loaded) and returns it.  Calling\n        this multiple times will just result in the already loaded app to\n        be returned.\n        \"\"\"\n        if self._loaded_app is not None:\n            return self._loaded_app\n        app: Flask | None = None\n        if self.create_app is not None:\n            app = self.create_app()\n        else:\n            if self.app_import_path:\n                path, name = (\n                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                )[:2]\n                import_name = prepare_import(path)\n                app = locate_app(import_name, name)\n            else:\n                for path in (\"wsgi.py\", \"app.py\"):\n                    import_name = prepare_import(path)\n                    app = locate_app(import_name, None, raise_if_not_found=False)\n\n                    if app is not None:\n                        break\n\n        if app is None:\n            raise NoAppException(\n                \"Could not locate a Flask application. Use the\"\n                \" 'flask --app' option, 'FLASK_APP' environment\"\n                \" variable, or a 'wsgi.py' or 'app.py' file in the\"\n                \" current directory.\"\n            )\n\n        if self.set_debug_flag:\n            # Update the app's debug flag through the descriptor so that\n            # other values repopulate as well.\n            app.debug = get_debug_flag()\n\n        self._loaded_app = app\n        return app"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "command",
        "input": "This works exactly like the method of the same name on a regular\n:class:`click.Group` but it wraps callbacks in :func:`with_appcontext`\nunless it's disabled by passing ``with_appcontext=False``.",
        "output": "def command(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Command]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it wraps callbacks in :func:`with_appcontext`\n        unless it's disabled by passing ``with_appcontext=False``.\n        \"\"\"\n        wrap_for_ctx = kwargs.pop(\"with_appcontext\", True)\n\n        def decorator(f: t.Callable[..., t.Any]) -> click.Command:\n            if wrap_for_ctx:\n                f = with_appcontext(f)\n            return super(AppGroup, self).command(*args, **kwargs)(f)  # type: ignore[no-any-return]\n\n        return decorator"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "group",
        "input": "This works exactly like the method of the same name on a regular\n:class:`click.Group` but it defaults the group class to\n:class:`AppGroup`.",
        "output": "def group(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Group]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it defaults the group class to\n        :class:`AppGroup`.\n        \"\"\"\n        kwargs.setdefault(\"cls\", AppGroup)\n        return super().group(*args, **kwargs)  # type: ignore[no-any-return]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "from_envvar",
        "input": "Loads a configuration from an environment variable pointing to\na configuration file.  This is basically just a shortcut with nicer\nerror messages for this line of code::\n\n    app.config.from_pyfile(os.environ['YOURAPPLICATION_SETTINGS'])\n\n:param variable_name: name of the environment variable\n:param silent: set to ``True`` if you want silent failure for missing\n               files.\n:return: ``True`` if the file was loaded successfully.",
        "output": "def from_envvar(self, variable_name: str, silent: bool = False) -> bool:\n        \"\"\"Loads a configuration from an environment variable pointing to\n        a configuration file.  This is basically just a shortcut with nicer\n        error messages for this line of code::\n\n            app.config.from_pyfile(os.environ['YOURAPPLICATION_SETTINGS'])\n\n        :param variable_name: name of the environment variable\n        :param silent: set to ``True`` if you want silent failure for missing\n                       files.\n        :return: ``True`` if the file was loaded successfully.\n        \"\"\"\n        rv = os.environ.get(variable_name)\n        if not rv:\n            if silent:\n                return False\n            raise RuntimeError(\n                f\"The environment variable {variable_name!r} is not set\"\n                \" and as such configuration could not be loaded. Set\"\n                \" this variable and make it point to a configuration\"\n                \" file\"\n            )\n        return self.from_pyfile(rv, silent=silent)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "from_prefixed_env",
        "input": "Load any environment variables that start with ``FLASK_``,\ndropping the prefix from the env key for the config key. Values\nare passed through a loading function to attempt to convert them\nto more specific types than strings.\n\nKeys are loaded in :func:`sorted` order.\n\nThe default loading function attempts to parse values as any\nvalid JSON type, including dicts and lists.\n\nSpecific items in nested dicts can be set by separating the\nkeys with double underscores (``__``). If an intermediate key\ndoesn't exist, it will be initialized to an empty dict.\n\n:param prefix: Load env vars that start with this prefix,\n    separated with an underscore (``_``).\n:param loads: Pass each string value to this function and use\n    the returned value as the config value. If any error is\n    raised it is ignored and the value remains a string. The\n    default is :func:`json.loads`.\n\n.. versionadded:: 2.1",
        "output": "def from_prefixed_env(\n        self, prefix: str = \"FLASK\", *, loads: t.Callable[[str], t.Any] = json.loads\n    ) -> bool:\n        \"\"\"Load any environment variables that start with ``FLASK_``,\n        dropping the prefix from the env key for the config key. Values\n        are passed through a loading function to attempt to convert them\n        to more specific types than strings.\n\n        Keys are loaded in :func:`sorted` order.\n\n        The default loading function attempts to parse values as any\n        valid JSON type, including dicts and lists.\n\n        Specific items in nested dicts can be set by separating the\n        keys with double underscores (``__``). If an intermediate key\n        doesn't exist, it will be initialized to an empty dict.\n\n        :param prefix: Load env vars that start with this prefix,\n            separated with an underscore (``_``).\n        :param loads: Pass each string value to this function and use\n            the returned value as the config value. If any error is\n            raised it is ignored and the value remains a string. The\n            default is :func:`json.loads`.\n\n        .. versionadded:: 2.1\n        \"\"\"\n        prefix = f\"{prefix}_\"\n\n        for key in sorted(os.environ):\n            if not key.startswith(prefix):\n                continue\n\n            value = os.environ[key]\n            key = key.removeprefix(prefix)\n\n            try:\n                value = loads(value)\n            except Exception:\n                # Keep the value as a string if loading failed.\n                pass\n\n            if \"__\" not in key:\n                # A non-nested key, set directly.\n                self[key] = value\n                continue\n\n            # Traverse nested dictionaries with keys separated by \"__\".\n            current = self\n            *parts, tail = key.split(\"__\")\n\n            for part in parts:\n                # If an intermediate dict does not exist, create it.\n                if part not in current:\n                    current[part] = {}\n\n                current = current[part]\n\n            current[tail] = value\n\n        return True"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "from_pyfile",
        "input": "Updates the values in the config from a Python file.  This function\nbehaves as if the file was imported as module with the\n:meth:`from_object` function.\n\n:param filename: the filename of the config.  This can either be an\n                 absolute filename or a filename relative to the\n                 root path.\n:param silent: set to ``True`` if you want silent failure for missing\n               files.\n:return: ``True`` if the file was loaded successfully.\n\n.. versionadded:: 0.7\n   `silent` parameter.",
        "output": "def from_pyfile(\n        self, filename: str | os.PathLike[str], silent: bool = False\n    ) -> bool:\n        \"\"\"Updates the values in the config from a Python file.  This function\n        behaves as if the file was imported as module with the\n        :meth:`from_object` function.\n\n        :param filename: the filename of the config.  This can either be an\n                         absolute filename or a filename relative to the\n                         root path.\n        :param silent: set to ``True`` if you want silent failure for missing\n                       files.\n        :return: ``True`` if the file was loaded successfully.\n\n        .. versionadded:: 0.7\n           `silent` parameter.\n        \"\"\"\n        filename = os.path.join(self.root_path, filename)\n        d = types.ModuleType(\"config\")\n        d.__file__ = filename\n        try:\n            with open(filename, mode=\"rb\") as config_file:\n                exec(compile(config_file.read(), filename, \"exec\"), d.__dict__)\n        except OSError as e:\n            if silent and e.errno in (errno.ENOENT, errno.EISDIR, errno.ENOTDIR):\n                return False\n            e.strerror = f\"Unable to load configuration file ({e.strerror})\"\n            raise\n        self.from_object(d)\n        return True"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "from_object",
        "input": "Updates the values from the given object.  An object can be of one\nof the following two types:\n\n-   a string: in this case the object with that name will be imported\n-   an actual object reference: that object is used directly\n\nObjects are usually either modules or classes. :meth:`from_object`\nloads only the uppercase attributes of the module/class. A ``dict``\nobject will not work with :meth:`from_object` because the keys of a\n``dict`` are not attributes of the ``dict`` class.\n\nExample of module-based configuration::\n\n    app.config.from_object('yourapplication.default_config')\n    from yourapplication import default_config\n    app.config.from_object(default_config)\n\nNothing is done to the object before loading. If the object is a\nclass and has ``@property`` attributes, it needs to be\ninstantiated before being passed to this method.\n\nYou should not use this function to load the actual configuration but\nrather configuration defaults.  The actual config should be loaded\nwith :meth:`from_pyfile` and ideally from a location not within the\npackage because the package might be installed system wide.\n\nSee :ref:`config-dev-prod` for an example of class-based configuration\nusing :meth:`from_object`.\n\n:param obj: an import name or object",
        "output": "def from_object(self, obj: object | str) -> None:\n        \"\"\"Updates the values from the given object.  An object can be of one\n        of the following two types:\n\n        -   a string: in this case the object with that name will be imported\n        -   an actual object reference: that object is used directly\n\n        Objects are usually either modules or classes. :meth:`from_object`\n        loads only the uppercase attributes of the module/class. A ``dict``\n        object will not work with :meth:`from_object` because the keys of a\n        ``dict`` are not attributes of the ``dict`` class.\n\n        Example of module-based configuration::\n\n            app.config.from_object('yourapplication.default_config')\n            from yourapplication import default_config\n            app.config.from_object(default_config)\n\n        Nothing is done to the object before loading. If the object is a\n        class and has ``@property`` attributes, it needs to be\n        instantiated before being passed to this method.\n\n        You should not use this function to load the actual configuration but\n        rather configuration defaults.  The actual config should be loaded\n        with :meth:`from_pyfile` and ideally from a location not within the\n        package because the package might be installed system wide.\n\n        See :ref:`config-dev-prod` for an example of class-based configuration\n        using :meth:`from_object`.\n\n        :param obj: an import name or object\n        \"\"\"\n        if isinstance(obj, str):\n            obj = import_string(obj)\n        for key in dir(obj):\n            if key.isupper():\n                self[key] = getattr(obj, key)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "from_file",
        "input": "Update the values in the config from a file that is loaded\nusing the ``load`` parameter. The loaded data is passed to the\n:meth:`from_mapping` method.\n\n.. code-block:: python\n\n    import json\n    app.config.from_file(\"config.json\", load=json.load)\n\n    import tomllib\n    app.config.from_file(\"config.toml\", load=tomllib.load, text=False)\n\n:param filename: The path to the data file. This can be an\n    absolute path or relative to the config root path.\n:param load: A callable that takes a file handle and returns a\n    mapping of loaded data from the file.\n:type load: ``Callable[[Reader], Mapping]`` where ``Reader``\n    implements a ``read`` method.\n:param silent: Ignore the file if it doesn't exist.\n:param text: Open the file in text or binary mode.\n:return: ``True`` if the file was loaded successfully.\n\n.. versionchanged:: 2.3\n    The ``text`` parameter was added.\n\n.. versionadded:: 2.0",
        "output": "def from_file(\n        self,\n        filename: str | os.PathLike[str],\n        load: t.Callable[[t.IO[t.Any]], t.Mapping[str, t.Any]],\n        silent: bool = False,\n        text: bool = True,\n    ) -> bool:\n        \"\"\"Update the values in the config from a file that is loaded\n        using the ``load`` parameter. The loaded data is passed to the\n        :meth:`from_mapping` method.\n\n        .. code-block:: python\n\n            import json\n            app.config.from_file(\"config.json\", load=json.load)\n\n            import tomllib\n            app.config.from_file(\"config.toml\", load=tomllib.load, text=False)\n\n        :param filename: The path to the data file. This can be an\n            absolute path or relative to the config root path.\n        :param load: A callable that takes a file handle and returns a\n            mapping of loaded data from the file.\n        :type load: ``Callable[[Reader], Mapping]`` where ``Reader``\n            implements a ``read`` method.\n        :param silent: Ignore the file if it doesn't exist.\n        :param text: Open the file in text or binary mode.\n        :return: ``True`` if the file was loaded successfully.\n\n        .. versionchanged:: 2.3\n            The ``text`` parameter was added.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        filename = os.path.join(self.root_path, filename)\n\n        try:\n            with open(filename, \"r\" if text else \"rb\") as f:\n                obj = load(f)\n        except OSError as e:\n            if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n                return False\n\n            e.strerror = f\"Unable to load configuration file ({e.strerror})\"\n            raise\n\n        return self.from_mapping(obj)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "from_mapping",
        "input": "Updates the config like :meth:`update` ignoring items with\nnon-upper keys.\n\n:return: Always returns ``True``.\n\n.. versionadded:: 0.11",
        "output": "def from_mapping(\n        self, mapping: t.Mapping[str, t.Any] | None = None, **kwargs: t.Any\n    ) -> bool:\n        \"\"\"Updates the config like :meth:`update` ignoring items with\n        non-upper keys.\n\n        :return: Always returns ``True``.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        mappings: dict[str, t.Any] = {}\n        if mapping is not None:\n            mappings.update(mapping)\n        mappings.update(kwargs)\n        for key, value in mappings.items():\n            if key.isupper():\n                self[key] = value\n        return True"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_namespace",
        "input": "Returns a dictionary containing a subset of configuration options\nthat match the specified namespace/prefix. Example usage::\n\n    app.config['IMAGE_STORE_TYPE'] = 'fs'\n    app.config['IMAGE_STORE_PATH'] = '/var/app/images'\n    app.config['IMAGE_STORE_BASE_URL'] = 'http://img.website.com'\n    image_store_config = app.config.get_namespace('IMAGE_STORE_')\n\nThe resulting dictionary `image_store_config` would look like::\n\n    {\n        'type': 'fs',\n        'path': '/var/app/images',\n        'base_url': 'http://img.website.com'\n    }\n\nThis is often useful when configuration options map directly to\nkeyword arguments in functions or class constructors.\n\n:param namespace: a configuration namespace\n:param lowercase: a flag indicating if the keys of the resulting\n                  dictionary should be lowercase\n:param trim_namespace: a flag indicating if the keys of the resulting\n                  dictionary should not include the namespace\n\n.. versionadded:: 0.11",
        "output": "def get_namespace(\n        self, namespace: str, lowercase: bool = True, trim_namespace: bool = True\n    ) -> dict[str, t.Any]:\n        \"\"\"Returns a dictionary containing a subset of configuration options\n        that match the specified namespace/prefix. Example usage::\n\n            app.config['IMAGE_STORE_TYPE'] = 'fs'\n            app.config['IMAGE_STORE_PATH'] = '/var/app/images'\n            app.config['IMAGE_STORE_BASE_URL'] = 'http://img.website.com'\n            image_store_config = app.config.get_namespace('IMAGE_STORE_')\n\n        The resulting dictionary `image_store_config` would look like::\n\n            {\n                'type': 'fs',\n                'path': '/var/app/images',\n                'base_url': 'http://img.website.com'\n            }\n\n        This is often useful when configuration options map directly to\n        keyword arguments in functions or class constructors.\n\n        :param namespace: a configuration namespace\n        :param lowercase: a flag indicating if the keys of the resulting\n                          dictionary should be lowercase\n        :param trim_namespace: a flag indicating if the keys of the resulting\n                          dictionary should not include the namespace\n\n        .. versionadded:: 0.11\n        \"\"\"\n        rv = {}\n        for k, v in self.items():\n            if not k.startswith(namespace):\n                continue\n            if trim_namespace:\n                key = k[len(namespace) :]\n            else:\n                key = k\n            if lowercase:\n                key = key.lower()\n            rv[key] = v\n        return rv"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "after_this_request",
        "input": "Executes a function after this request.  This is useful to modify\nresponse objects.  The function is passed the response object and has\nto return the same or a new one.\n\nExample::\n\n    @app.route('/')\n    def index():\n        @after_this_request\n        def add_header(response):\n            response.headers['X-Foo'] = 'Parachute'\n            return response\n        return 'Hello World!'\n\nThis is more useful if a function other than the view function wants to\nmodify a response.  For instance think of a decorator that wants to add\nsome headers without converting the return value into a response object.\n\n.. versionadded:: 0.9",
        "output": "def after_this_request(\n    f: ft.AfterRequestCallable[t.Any],\n) -> ft.AfterRequestCallable[t.Any]:\n    \"\"\"Executes a function after this request.  This is useful to modify\n    response objects.  The function is passed the response object and has\n    to return the same or a new one.\n\n    Example::\n\n        @app.route('/')\n        def index():\n            @after_this_request\n            def add_header(response):\n                response.headers['X-Foo'] = 'Parachute'\n                return response\n            return 'Hello World!'\n\n    This is more useful if a function other than the view function wants to\n    modify a response.  For instance think of a decorator that wants to add\n    some headers without converting the return value into a response object.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    ctx = _cv_request.get(None)\n\n    if ctx is None:\n        raise RuntimeError(\n            \"'after_this_request' can only be used when a request\"\n            \" context is active, such as in a view function.\"\n        )\n\n    ctx._after_request_functions.append(f)\n    return f"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "copy_current_request_context",
        "input": "A helper function that decorates a function to retain the current\nrequest context.  This is useful when working with greenlets.  The moment\nthe function is decorated a copy of the request context is created and\nthen pushed when the function is called.  The current session is also\nincluded in the copied request context.\n\nExample::\n\n    import gevent\n    from flask import copy_current_request_context\n\n    @app.route('/')\n    def index():\n        @copy_current_request_context\n        def do_some_work():\n            # do some work here, it can access flask.request or\n            # flask.session like you would otherwise in the view function.\n            ...\n        gevent.spawn(do_some_work)\n        return 'Regular response'\n\n.. versionadded:: 0.10",
        "output": "def copy_current_request_context(f: F) -> F:\n    \"\"\"A helper function that decorates a function to retain the current\n    request context.  This is useful when working with greenlets.  The moment\n    the function is decorated a copy of the request context is created and\n    then pushed when the function is called.  The current session is also\n    included in the copied request context.\n\n    Example::\n\n        import gevent\n        from flask import copy_current_request_context\n\n        @app.route('/')\n        def index():\n            @copy_current_request_context\n            def do_some_work():\n                # do some work here, it can access flask.request or\n                # flask.session like you would otherwise in the view function.\n                ...\n            gevent.spawn(do_some_work)\n            return 'Regular response'\n\n    .. versionadded:: 0.10\n    \"\"\"\n    ctx = _cv_request.get(None)\n\n    if ctx is None:\n        raise RuntimeError(\n            \"'copy_current_request_context' can only be used when a\"\n            \" request context is active, such as in a view function.\"\n        )\n\n    ctx = ctx.copy()\n\n    def wrapper(*args: t.Any, **kwargs: t.Any) -> t.Any:\n        with ctx:  # type: ignore[union-attr]\n            return ctx.app.ensure_sync(f)(*args, **kwargs)  # type: ignore[union-attr]\n\n    return update_wrapper(wrapper, f)  # type: ignore[return-value]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "has_request_context",
        "input": "If you have code that wants to test if a request context is there or\nnot this function can be used.  For instance, you may want to take advantage\nof request information if the request object is available, but fail\nsilently if it is unavailable.\n\n::\n\n    class User(db.Model):\n\n        def __init__(self, username, remote_addr=None):\n            self.username = username\n            if remote_addr is None and has_request_context():\n                remote_addr = request.remote_addr\n            self.remote_addr = remote_addr\n\nAlternatively you can also just test any of the context bound objects\n(such as :class:`request` or :class:`g`) for truthness::\n\n    class User(db.Model):\n\n        def __init__(self, username, remote_addr=None):\n            self.username = username\n            if remote_addr is None and request:\n                remote_addr = request.remote_addr\n            self.remote_addr = remote_addr\n\n.. versionadded:: 0.7",
        "output": "def has_request_context() -> bool:\n    \"\"\"If you have code that wants to test if a request context is there or\n    not this function can be used.  For instance, you may want to take advantage\n    of request information if the request object is available, but fail\n    silently if it is unavailable.\n\n    ::\n\n        class User(db.Model):\n\n            def __init__(self, username, remote_addr=None):\n                self.username = username\n                if remote_addr is None and has_request_context():\n                    remote_addr = request.remote_addr\n                self.remote_addr = remote_addr\n\n    Alternatively you can also just test any of the context bound objects\n    (such as :class:`request` or :class:`g`) for truthness::\n\n        class User(db.Model):\n\n            def __init__(self, username, remote_addr=None):\n                self.username = username\n                if remote_addr is None and request:\n                    remote_addr = request.remote_addr\n                self.remote_addr = remote_addr\n\n    .. versionadded:: 0.7\n    \"\"\"\n    return _cv_request.get(None) is not None"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "has_app_context",
        "input": "Works like :func:`has_request_context` but for the application\ncontext.  You can also just do a boolean check on the\n:data:`current_app` object instead.\n\n.. versionadded:: 0.9",
        "output": "def has_app_context() -> bool:\n    \"\"\"Works like :func:`has_request_context` but for the application\n    context.  You can also just do a boolean check on the\n    :data:`current_app` object instead.\n\n    .. versionadded:: 0.9\n    \"\"\"\n    return _cv_app.get(None) is not None"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get",
        "input": "Get an attribute by name, or a default value. Like\n:meth:`dict.get`.\n\n:param name: Name of attribute to get.\n:param default: Value to return if the attribute is not present.\n\n.. versionadded:: 0.10",
        "output": "def get(self, name: str, default: t.Any | None = None) -> t.Any:\n        \"\"\"Get an attribute by name, or a default value. Like\n        :meth:`dict.get`.\n\n        :param name: Name of attribute to get.\n        :param default: Value to return if the attribute is not present.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return self.__dict__.get(name, default)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "pop",
        "input": "Get and remove an attribute by name. Like :meth:`dict.pop`.\n\n:param name: Name of attribute to pop.\n:param default: Value to return if the attribute is not present,\n    instead of raising a ``KeyError``.\n\n.. versionadded:: 0.11",
        "output": "def pop(self, name: str, default: t.Any = _sentinel) -> t.Any:\n        \"\"\"Get and remove an attribute by name. Like :meth:`dict.pop`.\n\n        :param name: Name of attribute to pop.\n        :param default: Value to return if the attribute is not present,\n            instead of raising a ``KeyError``.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        if default is _sentinel:\n            return self.__dict__.pop(name)\n        else:\n            return self.__dict__.pop(name, default)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "setdefault",
        "input": "Get the value of an attribute if it is present, otherwise\nset and return a default value. Like :meth:`dict.setdefault`.\n\n:param name: Name of attribute to get.\n:param default: Value to set and return if the attribute is not\n    present.\n\n.. versionadded:: 0.11",
        "output": "def setdefault(self, name: str, default: t.Any = None) -> t.Any:\n        \"\"\"Get the value of an attribute if it is present, otherwise\n        set and return a default value. Like :meth:`dict.setdefault`.\n\n        :param name: Name of attribute to get.\n        :param default: Value to set and return if the attribute is not\n            present.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        return self.__dict__.setdefault(name, default)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "push",
        "input": "Binds the app context to the current context.",
        "output": "def push(self) -> None:\n        \"\"\"Binds the app context to the current context.\"\"\"\n        self._cv_tokens.append(_cv_app.set(self))\n        appcontext_pushed.send(self.app, _async_wrapper=self.app.ensure_sync)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "pop",
        "input": "Pops the app context.",
        "output": "def pop(self, exc: BaseException | None = _sentinel) -> None:  # type: ignore\n        \"\"\"Pops the app context.\"\"\"\n        try:\n            if len(self._cv_tokens) == 1:\n                if exc is _sentinel:\n                    exc = sys.exc_info()[1]\n                self.app.do_teardown_appcontext(exc)\n        finally:\n            ctx = _cv_app.get()\n            _cv_app.reset(self._cv_tokens.pop())\n\n        if ctx is not self:\n            raise AssertionError(\n                f\"Popped wrong app context. ({ctx!r} instead of {self!r})\"\n            )\n\n        appcontext_popped.send(self.app, _async_wrapper=self.app.ensure_sync)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "copy",
        "input": "Creates a copy of this request context with the same request object.\nThis can be used to move a request context to a different greenlet.\nBecause the actual request object is the same this cannot be used to\nmove a request context to a different thread unless access to the\nrequest object is locked.\n\n.. versionadded:: 0.10\n\n.. versionchanged:: 1.1\n   The current session object is used instead of reloading the original\n   data. This prevents `flask.session` pointing to an out-of-date object.",
        "output": "def copy(self) -> RequestContext:\n        \"\"\"Creates a copy of this request context with the same request object.\n        This can be used to move a request context to a different greenlet.\n        Because the actual request object is the same this cannot be used to\n        move a request context to a different thread unless access to the\n        request object is locked.\n\n        .. versionadded:: 0.10\n\n        .. versionchanged:: 1.1\n           The current session object is used instead of reloading the original\n           data. This prevents `flask.session` pointing to an out-of-date object.\n        \"\"\"\n        return self.__class__(\n            self.app,\n            environ=self.request.environ,\n            request=self.request,\n            session=self.session,\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "match_request",
        "input": "Can be overridden by a subclass to hook into the matching\nof the request.",
        "output": "def match_request(self) -> None:\n        \"\"\"Can be overridden by a subclass to hook into the matching\n        of the request.\n        \"\"\"\n        try:\n            result = self.url_adapter.match(return_rule=True)  # type: ignore\n            self.request.url_rule, self.request.view_args = result  # type: ignore\n        except HTTPException as e:\n            self.request.routing_exception = e"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "pop",
        "input": "Pops the request context and unbinds it by doing that.  This will\nalso trigger the execution of functions registered by the\n:meth:`~flask.Flask.teardown_request` decorator.\n\n.. versionchanged:: 0.9\n   Added the `exc` argument.",
        "output": "def pop(self, exc: BaseException | None = _sentinel) -> None:  # type: ignore\n        \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n\n        .. versionchanged:: 0.9\n           Added the `exc` argument.\n        \"\"\"\n        clear_request = len(self._cv_tokens) == 1\n\n        try:\n            if clear_request:\n                if exc is _sentinel:\n                    exc = sys.exc_info()[1]\n                self.app.do_teardown_request(exc)\n\n                request_close = getattr(self.request, \"close\", None)\n                if request_close is not None:\n                    request_close()\n        finally:\n            ctx = _cv_request.get()\n            token, app_ctx = self._cv_tokens.pop()\n            _cv_request.reset(token)\n\n            # get rid of circular dependencies at the end of the request\n            # so that we don't require the GC to be active.\n            if clear_request:\n                ctx.request.environ[\"werkzeug.request\"] = None\n\n            if app_ctx is not None:\n                app_ctx.pop(exc)\n\n            if ctx is not self:\n                raise AssertionError(\n                    f\"Popped wrong request context. ({ctx!r} instead of {self!r})\"\n                )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "attach_enctype_error_multidict",
        "input": "Patch ``request.files.__getitem__`` to raise a descriptive error\nabout ``enctype=multipart/form-data``.\n\n:param request: The request to patch.\n:meta private:",
        "output": "def attach_enctype_error_multidict(request: Request) -> None:\n    \"\"\"Patch ``request.files.__getitem__`` to raise a descriptive error\n    about ``enctype=multipart/form-data``.\n\n    :param request: The request to patch.\n    :meta private:\n    \"\"\"\n    oldcls = request.files.__class__\n\n    class newcls(oldcls):  # type: ignore[valid-type, misc]\n        def __getitem__(self, key: str) -> t.Any:\n            try:\n                return super().__getitem__(key)\n            except KeyError as e:\n                if key not in request.form:\n                    raise\n\n                raise DebugFilesKeyError(request, key).with_traceback(\n                    e.__traceback__\n                ) from None\n\n    newcls.__name__ = oldcls.__name__\n    newcls.__module__ = oldcls.__module__\n    request.files.__class__ = newcls"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "explain_template_loading_attempts",
        "input": "This should help developers understand what failed",
        "output": "def explain_template_loading_attempts(\n    app: App,\n    template: str,\n    attempts: list[\n        tuple[\n            BaseLoader,\n            Scaffold,\n            tuple[str, str | None, t.Callable[[], bool] | None] | None,\n        ]\n    ],\n) -> None:\n    \"\"\"This should help developers understand what failed\"\"\"\n    info = [f\"Locating template {template!r}:\"]\n    total_found = 0\n    blueprint = None\n    if request_ctx and request_ctx.request.blueprint is not None:\n        blueprint = request_ctx.request.blueprint\n\n    for idx, (loader, srcobj, triple) in enumerate(attempts):\n        if isinstance(srcobj, App):\n            src_info = f\"application {srcobj.import_name!r}\"\n        elif isinstance(srcobj, Blueprint):\n            src_info = f\"blueprint {srcobj.name!r} ({srcobj.import_name})\"\n        else:\n            src_info = repr(srcobj)\n\n        info.append(f\"{idx + 1:5}: trying loader of {src_info}\")\n\n        for line in _dump_loader_info(loader):\n            info.append(f\"       {line}\")\n\n        if triple is None:\n            detail = \"no match\"\n        else:\n            detail = f\"found ({triple[1] or '<string>'!r})\"\n            total_found += 1\n        info.append(f\"       -> {detail}\")\n\n    seems_fishy = False\n    if total_found == 0:\n        info.append(\"Error: the template could not be found.\")\n        seems_fishy = True\n    elif total_found > 1:\n        info.append(\"Warning: multiple loaders returned a match for the template.\")\n        seems_fishy = True\n\n    if blueprint is not None and seems_fishy:\n        info.append(\n            \"  The template was looked up from an endpoint that belongs\"\n            f\" to the blueprint {blueprint!r}.\"\n        )\n        info.append(\"  Maybe you did not place a template in the right folder?\")\n        info.append(\"  See https://flask.palletsprojects.com/blueprints/#templates\")\n\n    app.logger.info(\"\\n\".join(info))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_debug_flag",
        "input": "Get whether debug mode should be enabled for the app, indicated by the\n:envvar:`FLASK_DEBUG` environment variable. The default is ``False``.",
        "output": "def get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_load_dotenv",
        "input": "Get whether the user has disabled loading default dotenv files by\nsetting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\nthe files.\n\n:param default: What to return if the env var isn't set.",
        "output": "def get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "stream_with_context",
        "input": "Request contexts disappear when the response is started on the server.\nThis is done for efficiency reasons and to make it less likely to encounter\nmemory leaks with badly written WSGI middlewares.  The downside is that if\nyou are using streamed responses, the generator cannot access request bound\ninformation any more.\n\nThis function however can help you keep the context around for longer::\n\n    from flask import stream_with_context, request, Response\n\n    @app.route('/stream')\n    def streamed_response():\n        @stream_with_context\n        def generate():\n            yield 'Hello '\n            yield request.args['name']\n            yield '!'\n        return Response(generate())\n\nAlternatively it can also be used around a specific generator::\n\n    from flask import stream_with_context, request, Response\n\n    @app.route('/stream')\n    def streamed_response():\n        def generate():\n            yield 'Hello '\n            yield request.args['name']\n            yield '!'\n        return Response(stream_with_context(generate()))\n\n.. versionadded:: 0.9",
        "output": "def stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr] | t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "make_response",
        "input": "Sometimes it is necessary to set additional headers in a view.  Because\nviews do not have to return response objects but can return a value that\nis converted into a response object by Flask itself, it becomes tricky to\nadd headers to it.  This function can be called instead of using a return\nand you will get a response object which you can use to attach headers.\n\nIf view looked like this and you want to add a new header::\n\n    def index():\n        return render_template('index.html', foo=42)\n\nYou can now do something like this::\n\n    def index():\n        response = make_response(render_template('index.html', foo=42))\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n        return response\n\nThis function accepts the very same arguments you can return from a\nview function.  This for example creates a response with a 404 error\ncode::\n\n    response = make_response(render_template('not_found.html'), 404)\n\nThe other use case of this function is to force the return value of a\nview function into a response which is helpful with view\ndecorators::\n\n    response = make_response(view_function())\n    response.headers['X-Parachutes'] = 'parachutes are cool'\n\nInternally this function does the following things:\n\n-   if no arguments are passed, it creates a new response argument\n-   if one argument is passed, :meth:`flask.Flask.make_response`\n    is invoked with it.\n-   if more than one argument is passed, the arguments are passed\n    to the :meth:`flask.Flask.make_response` function as tuple.\n\n.. versionadded:: 0.6",
        "output": "def make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "url_for",
        "input": "Generate a URL to the given endpoint with the given values.\n\nThis requires an active request or application context, and calls\n:meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\nfor full documentation.\n\n:param endpoint: The endpoint name associated with the URL to\n    generate. If this starts with a ``.``, the current blueprint\n    name (if any) will be used.\n:param _anchor: If given, append this as ``#anchor`` to the URL.\n:param _method: If given, generate the URL associated with this\n    method for the endpoint.\n:param _scheme: If given, the URL will have this scheme if it is\n    external.\n:param _external: If given, prefer the URL to be internal (False) or\n    require it to be external (True). External URLs include the\n    scheme and domain. When not in an active request, URLs are\n    external by default.\n:param values: Values to use for the variable parts of the URL rule.\n    Unknown keys are appended as query string arguments, like\n    ``?a=b&c=d``.\n\n.. versionchanged:: 2.2\n    Calls ``current_app.url_for``, allowing an app to override the\n    behavior.\n\n.. versionchanged:: 0.10\n   The ``_scheme`` parameter was added.\n\n.. versionchanged:: 0.9\n   The ``_anchor`` and ``_method`` parameters were added.\n\n.. versionchanged:: 0.9\n   Calls ``app.handle_url_build_error`` on build errors.",
        "output": "def url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "redirect",
        "input": "Create a redirect response object.\n\nIf :data:`~flask.current_app` is available, it will use its\n:meth:`~flask.Flask.redirect` method, otherwise it will use\n:func:`werkzeug.utils.redirect`.\n\n:param location: The URL to redirect to.\n:param code: The status code for the redirect.\n:param Response: The response class to use. Not used when\n    ``current_app`` is active, which uses ``app.response_class``.\n\n.. versionadded:: 2.2\n    Calls ``current_app.redirect`` if available instead of always\n    using Werkzeug's default ``redirect``.",
        "output": "def redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "abort",
        "input": "Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\nstatus code.\n\nIf :data:`~flask.current_app` is available, it will call its\n:attr:`~flask.Flask.aborter` object, otherwise it will use\n:func:`werkzeug.exceptions.abort`.\n\n:param code: The status code for the exception, which must be\n    registered in ``app.aborter``.\n:param args: Passed to the exception.\n:param kwargs: Passed to the exception.\n\n.. versionadded:: 2.2\n    Calls ``current_app.aborter`` if available instead of always\n    using Werkzeug's default ``abort``.",
        "output": "def abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_template_attribute",
        "input": "Loads a macro (or variable) a template exports.  This can be used to\ninvoke a macro from within Python code.  If you for example have a\ntemplate named :file:`_cider.html` with the following contents:\n\n.. sourcecode:: html+jinja\n\n   {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\nYou can access this from Python code like this::\n\n    hello = get_template_attribute('_cider.html', 'hello')\n    return hello('World')\n\n.. versionadded:: 0.2\n\n:param template_name: the name of the template\n:param attribute: the name of the variable of macro to access",
        "output": "def get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "flash",
        "input": "Flashes a message to the next request.  In order to remove the\nflashed message from the session and to display it to the user,\nthe template has to call :func:`get_flashed_messages`.\n\n.. versionchanged:: 0.3\n   `category` parameter added.\n\n:param message: the message to be flashed.\n:param category: the category for the message.  The following values\n                 are recommended: ``'message'`` for any kind of message,\n                 ``'error'`` for errors, ``'info'`` for information\n                 messages and ``'warning'`` for warnings.  However any\n                 kind of string can be used as category.",
        "output": "def flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_flashed_messages",
        "input": "Pulls all flashed messages from the session and returns them.\nFurther calls in the same request to the function will return\nthe same messages.  By default just the messages are returned,\nbut when `with_categories` is set to ``True``, the return value will\nbe a list of tuples in the form ``(category, message)`` instead.\n\nFilter the flashed messages to one or more categories by providing those\ncategories in `category_filter`.  This allows rendering categories in\nseparate html blocks.  The `with_categories` and `category_filter`\narguments are distinct:\n\n* `with_categories` controls whether categories are returned with message\n  text (``True`` gives a tuple, where ``False`` gives just the message text).\n* `category_filter` filters the messages down to only those matching the\n  provided categories.\n\nSee :doc:`/patterns/flashing` for examples.\n\n.. versionchanged:: 0.3\n   `with_categories` parameter added.\n\n.. versionchanged:: 0.9\n    `category_filter` parameter added.\n\n:param with_categories: set to ``True`` to also receive categories.\n:param category_filter: filter of categories to limit return values.  Only\n                        categories in the list will be returned.",
        "output": "def get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "send_file",
        "input": "Send the contents of a file to the client.\n\nThe first argument can be a file path or a file-like object. Paths\nare preferred in most cases because Werkzeug can manage the file and\nget extra information from the path. Passing a file-like object\nrequires that the file is opened in binary mode, and is mostly\nuseful when building a file in memory with :class:`io.BytesIO`.\n\nNever pass file paths provided by a user. The path is assumed to be\ntrusted, so a user could craft a path to access a file you didn't\nintend. Use :func:`send_from_directory` to safely serve\nuser-requested paths from within a directory.\n\nIf the WSGI server sets a ``file_wrapper`` in ``environ``, it is\nused, otherwise Werkzeug's built-in wrapper is used. Alternatively,\nif the HTTP server supports ``X-Sendfile``, configuring Flask with\n``USE_X_SENDFILE = True`` will tell the server to send the given\npath, which is much more efficient than reading it in Python.\n\n:param path_or_file: The path to the file to send, relative to the\n    current working directory if a relative path is given.\n    Alternatively, a file-like object opened in binary mode. Make\n    sure the file pointer is seeked to the start of the data.\n:param mimetype: The MIME type to send for the file. If not\n    provided, it will try to detect it from the file name.\n:param as_attachment: Indicate to a browser that it should offer to\n    save the file instead of displaying it.\n:param download_name: The default name browsers will use when saving\n    the file. Defaults to the passed file name.\n:param conditional: Enable conditional and range responses based on\n    request headers. Requires passing a file path and ``environ``.\n:param etag: Calculate an ETag for the file, which requires passing\n    a file path. Can also be a string to use instead.\n:param last_modified: The last modified time to send for the file,\n    in seconds. If not provided, it will try to detect it from the\n    file path.\n:param max_age: How long the client should cache the file, in\n    seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n    it will be ``no-cache`` to prefer conditional caching.\n\n.. versionchanged:: 2.0\n    ``download_name`` replaces the ``attachment_filename``\n    parameter. If ``as_attachment=False``, it is passed with\n    ``Content-Disposition: inline`` instead.\n\n.. versionchanged:: 2.0\n    ``max_age`` replaces the ``cache_timeout`` parameter.\n    ``conditional`` is enabled and ``max_age`` is not set by\n    default.\n\n.. versionchanged:: 2.0\n    ``etag`` replaces the ``add_etags`` parameter. It can be a\n    string to use instead of generating one.\n\n.. versionchanged:: 2.0\n    Passing a file-like object that inherits from\n    :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n    than sending an empty file.\n\n.. versionadded:: 2.0\n    Moved the implementation to Werkzeug. This is now a wrapper to\n    pass some Flask-specific arguments.\n\n.. versionchanged:: 1.1\n    ``filename`` may be a :class:`~os.PathLike` object.\n\n.. versionchanged:: 1.1\n    Passing a :class:`~io.BytesIO` object supports range requests.\n\n.. versionchanged:: 1.0.3\n    Filenames are encoded with ASCII instead of Latin-1 for broader\n    compatibility with WSGI servers.\n\n.. versionchanged:: 1.0\n    UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n.. versionchanged:: 0.12\n    The filename is no longer automatically inferred from file\n    objects. If you want to use automatic MIME and etag support,\n    pass a filename via ``filename_or_fp`` or\n    ``attachment_filename``.\n\n.. versionchanged:: 0.12\n    ``attachment_filename`` is preferred over ``filename`` for MIME\n    detection.\n\n.. versionchanged:: 0.9\n    ``cache_timeout`` defaults to\n    :meth:`Flask.get_send_file_max_age`.\n\n.. versionchanged:: 0.7\n    MIME guessing and etag support for file-like objects was\n    removed because it was unreliable. Pass a filename if you are\n    able to, otherwise attach an etag yourself.\n\n.. versionchanged:: 0.5\n    The ``add_etags``, ``cache_timeout`` and ``conditional``\n    parameters were added. The default behavior is to add etags.\n\n.. versionadded:: 0.2",
        "output": "def send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "send_from_directory",
        "input": "Send a file from within a directory using :func:`send_file`.\n\n.. code-block:: python\n\n    @app.route(\"/uploads/<path:name>\")\n    def download_file(name):\n        return send_from_directory(\n            app.config['UPLOAD_FOLDER'], name, as_attachment=True\n        )\n\nThis is a secure way to serve files from a folder, such as static\nfiles or uploads. Uses :func:`~werkzeug.security.safe_join` to\nensure the path coming from the client is not maliciously crafted to\npoint outside the specified directory.\n\nIf the final path does not point to an existing regular file,\nraises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n:param directory: The directory that ``path`` must be located under,\n    relative to the current application's root path. This *must not*\n    be a value provided by the client, otherwise it becomes insecure.\n:param path: The path to the file to send, relative to\n    ``directory``.\n:param kwargs: Arguments to pass to :func:`send_file`.\n\n.. versionchanged:: 2.0\n    ``path`` replaces the ``filename`` parameter.\n\n.. versionadded:: 2.0\n    Moved the implementation to Werkzeug. This is now a wrapper to\n    pass some Flask-specific arguments.\n\n.. versionadded:: 0.5",
        "output": "def send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path. This *must not*\n        be a value provided by the client, otherwise it becomes insecure.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_root_path",
        "input": "Find the root path of a package, or the path that contains a\nmodule. If it cannot be found, returns the current working\ndirectory.\n\nNot to be confused with the value returned by :func:`find_package`.\n\n:meta private:",
        "output": "def get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)  # pyright: ignore\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dumps",
        "input": "Serialize data as JSON.\n\n:param obj: The data to serialize.\n:param kwargs: May be passed to the underlying JSON library.",
        "output": "def dumps(self, obj: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"Serialize data as JSON.\n\n        :param obj: The data to serialize.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        raise NotImplementedError"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dump",
        "input": "Serialize data as JSON and write to a file.\n\n:param obj: The data to serialize.\n:param fp: A file opened for writing text. Should use the UTF-8\n    encoding to be valid JSON.\n:param kwargs: May be passed to the underlying JSON library.",
        "output": "def dump(self, obj: t.Any, fp: t.IO[str], **kwargs: t.Any) -> None:\n        \"\"\"Serialize data as JSON and write to a file.\n\n        :param obj: The data to serialize.\n        :param fp: A file opened for writing text. Should use the UTF-8\n            encoding to be valid JSON.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        fp.write(self.dumps(obj, **kwargs))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "loads",
        "input": "Deserialize data as JSON.\n\n:param s: Text or UTF-8 bytes.\n:param kwargs: May be passed to the underlying JSON library.",
        "output": "def loads(self, s: str | bytes, **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON.\n\n        :param s: Text or UTF-8 bytes.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        raise NotImplementedError"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "load",
        "input": "Deserialize data as JSON read from a file.\n\n:param fp: A file opened for reading text or UTF-8 bytes.\n:param kwargs: May be passed to the underlying JSON library.",
        "output": "def load(self, fp: t.IO[t.AnyStr], **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON read from a file.\n\n        :param fp: A file opened for reading text or UTF-8 bytes.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        return self.loads(fp.read(), **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "response",
        "input": "Serialize the given arguments as JSON, and return a\n:class:`~flask.Response` object with the ``application/json``\nmimetype.\n\nThe :func:`~flask.json.jsonify` function calls this method for\nthe current application.\n\nEither positional or keyword arguments can be given, not both.\nIf no arguments are given, ``None`` is serialized.\n\n:param args: A single value to serialize, or multiple values to\n    treat as a list to serialize.\n:param kwargs: Treat as a dict to serialize.",
        "output": "def response(self, *args: t.Any, **kwargs: t.Any) -> Response:\n        \"\"\"Serialize the given arguments as JSON, and return a\n        :class:`~flask.Response` object with the ``application/json``\n        mimetype.\n\n        The :func:`~flask.json.jsonify` function calls this method for\n        the current application.\n\n        Either positional or keyword arguments can be given, not both.\n        If no arguments are given, ``None`` is serialized.\n\n        :param args: A single value to serialize, or multiple values to\n            treat as a list to serialize.\n        :param kwargs: Treat as a dict to serialize.\n        \"\"\"\n        obj = self._prepare_response_obj(args, kwargs)\n        return self._app.response_class(self.dumps(obj), mimetype=\"application/json\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dumps",
        "input": "Serialize data as JSON to a string.\n\nKeyword arguments are passed to :func:`json.dumps`. Sets some\nparameter defaults from the :attr:`default`,\n:attr:`ensure_ascii`, and :attr:`sort_keys` attributes.\n\n:param obj: The data to serialize.\n:param kwargs: Passed to :func:`json.dumps`.",
        "output": "def dumps(self, obj: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"Serialize data as JSON to a string.\n\n        Keyword arguments are passed to :func:`json.dumps`. Sets some\n        parameter defaults from the :attr:`default`,\n        :attr:`ensure_ascii`, and :attr:`sort_keys` attributes.\n\n        :param obj: The data to serialize.\n        :param kwargs: Passed to :func:`json.dumps`.\n        \"\"\"\n        kwargs.setdefault(\"default\", self.default)\n        kwargs.setdefault(\"ensure_ascii\", self.ensure_ascii)\n        kwargs.setdefault(\"sort_keys\", self.sort_keys)\n        return json.dumps(obj, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "loads",
        "input": "Deserialize data as JSON from a string or bytes.\n\n:param s: Text or UTF-8 bytes.\n:param kwargs: Passed to :func:`json.loads`.",
        "output": "def loads(self, s: str | bytes, **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON from a string or bytes.\n\n        :param s: Text or UTF-8 bytes.\n        :param kwargs: Passed to :func:`json.loads`.\n        \"\"\"\n        return json.loads(s, **kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "response",
        "input": "Serialize the given arguments as JSON, and return a\n:class:`~flask.Response` object with it. The response mimetype\nwill be \"application/json\" and can be changed with\n:attr:`mimetype`.\n\nIf :attr:`compact` is ``False`` or debug mode is enabled, the\noutput will be formatted to be easier to read.\n\nEither positional or keyword arguments can be given, not both.\nIf no arguments are given, ``None`` is serialized.\n\n:param args: A single value to serialize, or multiple values to\n    treat as a list to serialize.\n:param kwargs: Treat as a dict to serialize.",
        "output": "def response(self, *args: t.Any, **kwargs: t.Any) -> Response:\n        \"\"\"Serialize the given arguments as JSON, and return a\n        :class:`~flask.Response` object with it. The response mimetype\n        will be \"application/json\" and can be changed with\n        :attr:`mimetype`.\n\n        If :attr:`compact` is ``False`` or debug mode is enabled, the\n        output will be formatted to be easier to read.\n\n        Either positional or keyword arguments can be given, not both.\n        If no arguments are given, ``None`` is serialized.\n\n        :param args: A single value to serialize, or multiple values to\n            treat as a list to serialize.\n        :param kwargs: Treat as a dict to serialize.\n        \"\"\"\n        obj = self._prepare_response_obj(args, kwargs)\n        dump_args: dict[str, t.Any] = {}\n\n        if (self.compact is None and self._app.debug) or self.compact is False:\n            dump_args.setdefault(\"indent\", 2)\n        else:\n            dump_args.setdefault(\"separators\", (\",\", \":\"))\n\n        return self._app.response_class(\n            f\"{self.dumps(obj, **dump_args)}\\n\", mimetype=self.mimetype\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__init__",
        "input": "Create a tagger for the given serializer.",
        "output": "def __init__(self, serializer: TaggedJSONSerializer) -> None:\n        \"\"\"Create a tagger for the given serializer.\"\"\"\n        self.serializer = serializer"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "check",
        "input": "Check if the given value should be tagged by this tag.",
        "output": "def check(self, value: t.Any) -> bool:\n        \"\"\"Check if the given value should be tagged by this tag.\"\"\"\n        raise NotImplementedError"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "to_json",
        "input": "Convert the Python object to an object that is a valid JSON type.\nThe tag will be added later.",
        "output": "def to_json(self, value: t.Any) -> t.Any:\n        \"\"\"Convert the Python object to an object that is a valid JSON type.\n        The tag will be added later.\"\"\"\n        raise NotImplementedError"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "to_python",
        "input": "Convert the JSON representation back to the correct type. The tag\nwill already be removed.",
        "output": "def to_python(self, value: t.Any) -> t.Any:\n        \"\"\"Convert the JSON representation back to the correct type. The tag\n        will already be removed.\"\"\"\n        raise NotImplementedError"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "tag",
        "input": "Convert the value to a valid JSON type and add the tag structure\naround it.",
        "output": "def tag(self, value: t.Any) -> dict[str, t.Any]:\n        \"\"\"Convert the value to a valid JSON type and add the tag structure\n        around it.\"\"\"\n        return {self.key: self.to_json(value)}"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "register",
        "input": "Register a new tag with this serializer.\n\n:param tag_class: tag class to register. Will be instantiated with this\n    serializer instance.\n:param force: overwrite an existing tag. If false (default), a\n    :exc:`KeyError` is raised.\n:param index: index to insert the new tag in the tag order. Useful when\n    the new tag is a special case of an existing tag. If ``None``\n    (default), the tag is appended to the end of the order.\n\n:raise KeyError: if the tag key is already registered and ``force`` is\n    not true.",
        "output": "def register(\n        self,\n        tag_class: type[JSONTag],\n        force: bool = False,\n        index: int | None = None,\n    ) -> None:\n        \"\"\"Register a new tag with this serializer.\n\n        :param tag_class: tag class to register. Will be instantiated with this\n            serializer instance.\n        :param force: overwrite an existing tag. If false (default), a\n            :exc:`KeyError` is raised.\n        :param index: index to insert the new tag in the tag order. Useful when\n            the new tag is a special case of an existing tag. If ``None``\n            (default), the tag is appended to the end of the order.\n\n        :raise KeyError: if the tag key is already registered and ``force`` is\n            not true.\n        \"\"\"\n        tag = tag_class(self)\n        key = tag.key\n\n        if key:\n            if not force and key in self.tags:\n                raise KeyError(f\"Tag '{key}' is already registered.\")\n\n            self.tags[key] = tag\n\n        if index is None:\n            self.order.append(tag)\n        else:\n            self.order.insert(index, tag)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "tag",
        "input": "Convert a value to a tagged representation if necessary.",
        "output": "def tag(self, value: t.Any) -> t.Any:\n        \"\"\"Convert a value to a tagged representation if necessary.\"\"\"\n        for tag in self.order:\n            if tag.check(value):\n                return tag.tag(value)\n\n        return value"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "untag",
        "input": "Convert a tagged representation back to the original type.",
        "output": "def untag(self, value: dict[str, t.Any]) -> t.Any:\n        \"\"\"Convert a tagged representation back to the original type.\"\"\"\n        if len(value) != 1:\n            return value\n\n        key = next(iter(value))\n\n        if key not in self.tags:\n            return value\n\n        return self.tags[key].to_python(value[key])"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "dumps",
        "input": "Tag the value and dump it to a compact JSON string.",
        "output": "def dumps(self, value: t.Any) -> str:\n        \"\"\"Tag the value and dump it to a compact JSON string.\"\"\"\n        return dumps(self.tag(value), separators=(\",\", \":\"))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "loads",
        "input": "Load data from a JSON string and deserialized any tagged objects.",
        "output": "def loads(self, value: str) -> t.Any:\n        \"\"\"Load data from a JSON string and deserialized any tagged objects.\"\"\"\n        return self._untag_scan(loads(value))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "changelog",
        "input": " Get change log for provided revision range\n\n\b\nExample:\n\n\b\n$ spin authors -t $GH_TOKEN --revision-range v1.25.0..v1.26.0",
        "output": "def changelog(token, revision_range):\n    \"\"\" Get change log for provided revision range\n\n    \\b\n    Example:\n\n    \\b\n    $ spin authors -t $GH_TOKEN --revision-range v1.25.0..v1.26.0\n    \"\"\"\n    try:\n        from github.GithubException import GithubException\n        from git.exc import GitError\n        changelog = _get_numpy_tools(pathlib.Path('changelog.py'))\n    except ModuleNotFoundError as e:\n        raise click.ClickException(\n            f\"{e.msg}. Install the missing packages to use this command.\"\n        )\n    click.secho(\n        f\"Generating change log for range {revision_range}\",\n        bold=True, fg=\"bright_green\",\n    )\n    try:\n        changelog.main(token, revision_range)\n    except GithubException as e:\n        raise click.ClickException(\n            f\"GithubException raised with status: {e.status} \"\n            f\"and message: {e.data['message']}\"\n        )\n    except GitError as e:\n        raise click.ClickException(\n            f\"Git error in command `{' '.join(e.command)}` \"\n            f\"with error message: {e.stderr}\"\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "docs",
        "input": " Build Sphinx documentation\n\nBy default, SPHINXOPTS=\"-W\", raising errors on warnings.\nTo build without raising on warnings:\n\n  SPHINXOPTS=\"\" spin docs\n\nTo list all Sphinx targets:\n\n  spin docs targets\n\nTo build another Sphinx target:\n\n  spin docs TARGET\n\nE.g., to build a zipfile of the html docs for distribution:\n\n  spin docs dist",
        "output": "def docs(*, parent_callback, **kwargs):\n    \"\"\" Build Sphinx documentation\n\n    By default, SPHINXOPTS=\"-W\", raising errors on warnings.\n    To build without raising on warnings:\n\n      SPHINXOPTS=\"\" spin docs\n\n    To list all Sphinx targets:\n\n      spin docs targets\n\n    To build another Sphinx target:\n\n      spin docs TARGET\n\n    E.g., to build a zipfile of the html docs for distribution:\n\n      spin docs dist\n\n    \"\"\"\n    kwargs['clean_dirs'] = [\n        './doc/build/',\n        './doc/source/reference/generated',\n        './doc/source/reference/random/bit_generators/generated',\n        './doc/source/reference/random/generated',\n    ]\n\n    # Run towncrier without staging anything for commit. This is the way to get\n    # release notes snippets included in a local doc build.\n    cmd = ['towncrier', 'build', '--version', '2.x.y', '--keep', '--draft']\n    p = subprocess.run(cmd, check=True, capture_output=True, text=True)\n    outfile = curdir.parent / 'doc' / 'source' / 'release' / 'notes-towncrier.rst'\n    with open(outfile, 'w') as f:\n        f.write(p.stdout)\n\n    parent_callback(**kwargs)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "test",
        "input": "By default, spin will run `-m 'not slow'`. To run the full test suite, use\n`spin test -m full`",
        "output": "def test(*, parent_callback, pytest_args, tests, markexpr, **kwargs):\n    \"\"\"\n    By default, spin will run `-m 'not slow'`. To run the full test suite, use\n    `spin test -m full`\n    \"\"\"  # noqa: E501\n    if (not pytest_args) and (not tests):\n        pytest_args = ('--pyargs', 'numpy')\n\n    if '-m' not in pytest_args:\n        if markexpr != \"full\":\n            pytest_args = ('-m', markexpr) + pytest_args\n\n    kwargs['pytest_args'] = pytest_args\n    parent_callback(**{'pytest_args': pytest_args, 'tests': tests, **kwargs})"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "check_docs",
        "input": " Run doctests of objects in the public API.\n\nPYTEST_ARGS are passed through directly to pytest, e.g.:\n\n  spin check-docs -- --pdb\n\nTo run tests on a directory:\n\n \b\n spin check-docs numpy/linalg\n\nTo report the durations of the N slowest doctests:\n\n  spin check-docs -- --durations=N\n\nTo run doctests that match a given pattern:\n\n \b\n spin check-docs -- -k \"slogdet\"\n spin check-docs numpy/linalg -- -k \"det and not slogdet\"\n\n\b\nNote:\n-----\n\n\b\n - This command only runs doctests and skips everything under tests/\n - This command only doctests public objects: those which are accessible\n   from the top-level `__init__.py` file.",
        "output": "def check_docs(*, parent_callback, pytest_args, **kwargs):\n    \"\"\" Run doctests of objects in the public API.\n\n    PYTEST_ARGS are passed through directly to pytest, e.g.:\n\n      spin check-docs -- --pdb\n\n    To run tests on a directory:\n\n     \\b\n     spin check-docs numpy/linalg\n\n    To report the durations of the N slowest doctests:\n\n      spin check-docs -- --durations=N\n\n    To run doctests that match a given pattern:\n\n     \\b\n     spin check-docs -- -k \"slogdet\"\n     spin check-docs numpy/linalg -- -k \"det and not slogdet\"\n\n    \\b\n    Note:\n    -----\n\n    \\b\n     - This command only runs doctests and skips everything under tests/\n     - This command only doctests public objects: those which are accessible\n       from the top-level `__init__.py` file.\n\n    \"\"\"  # noqa: E501\n    try:\n        # prevent obscure error later\n        import scipy_doctest\n    except ModuleNotFoundError as e:\n        raise ModuleNotFoundError(\"scipy-doctest not installed\") from e\n\n    if (not pytest_args):\n        pytest_args = ('--pyargs', 'numpy')\n\n    # turn doctesting on:\n    doctest_args = (\n        '--doctest-modules',\n        '--doctest-collect=api'\n    )\n\n    pytest_args = pytest_args + doctest_args\n\n    parent_callback(**{'pytest_args': pytest_args, **kwargs})"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "check_tutorials",
        "input": " Run doctests of user-facing rst tutorials.\n\nTo test all tutorials in the numpy doc/source/user/ directory, use\n\n  spin check-tutorials\n\nTo run tests on a specific RST file:\n\n \b\n spin check-tutorials doc/source/user/absolute-beginners.rst\n\n\b\nNote:\n-----\n\n\b\n - This command only runs doctests and skips everything under tests/\n - This command only doctests public objects: those which are accessible\n   from the top-level `__init__.py` file.",
        "output": "def check_tutorials(*, parent_callback, pytest_args, **kwargs):\n    \"\"\" Run doctests of user-facing rst tutorials.\n\n    To test all tutorials in the numpy doc/source/user/ directory, use\n\n      spin check-tutorials\n\n    To run tests on a specific RST file:\n\n     \\b\n     spin check-tutorials doc/source/user/absolute-beginners.rst\n\n    \\b\n    Note:\n    -----\n\n    \\b\n     - This command only runs doctests and skips everything under tests/\n     - This command only doctests public objects: those which are accessible\n       from the top-level `__init__.py` file.\n\n    \"\"\"  # noqa: E501\n    # handle all of\n    #   - `spin check-tutorials` (pytest_args == ())\n    #   - `spin check-tutorials path/to/rst`, and\n    #   - `spin check-tutorials path/to/rst -- --durations=3`\n    if (not pytest_args) or all(arg.startswith('-') for arg in pytest_args):\n        pytest_args = ('doc/source/user',) + pytest_args\n\n    # make all paths relative to the numpy source folder\n    pytest_args = tuple(\n        str(curdir / '..' / arg) if not arg.startswith('-') else arg\n        for arg in pytest_args\n   )\n\n    # turn doctesting on:\n    doctest_args = (\n        '--doctest-glob=*rst',\n    )\n\n    pytest_args = pytest_args + doctest_args\n\n    parent_callback(**{'pytest_args': pytest_args, **kwargs})"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_set_mem_rlimit",
        "input": "Set address space rlimit",
        "output": "def _set_mem_rlimit(max_mem=None):\n    \"\"\"\n    Set address space rlimit\n    \"\"\"\n    import resource\n    import psutil\n\n    mem = psutil.virtual_memory()\n\n    if max_mem is None:\n        max_mem = int(mem.total * 0.7)\n    cur_limit = resource.getrlimit(resource.RLIMIT_AS)\n    if cur_limit[0] > 0:\n        max_mem = min(max_mem, cur_limit[0])\n\n    try:\n        resource.setrlimit(resource.RLIMIT_AS, (max_mem, cur_limit[1]))\n    except ValueError:\n        # on macOS may raise: current limit exceeds maximum limit\n        pass"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "lint",
        "input": " Run lint checks with Ruff\n\n\b\nTo run automatic fixes use:\n\n\b\n$ spin lint --fix",
        "output": "def lint(ctx, fix):\n    \"\"\" Run lint checks with Ruff\n\n    \\b\n    To run automatic fixes use:\n\n    \\b\n    $ spin lint --fix\n    \"\"\"\n    try:\n        linter = _get_numpy_tools(pathlib.Path('linter.py'))\n    except ModuleNotFoundError as e:\n        raise click.ClickException(\n            f\"{e.msg}. Install using requirements/linter_requirements.txt\"\n        )\n\n    linter.DiffLinter().run_lint(fix)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "bench",
        "input": " Run benchmarks.\n\n\b\nExamples:\n\n\b\n$ spin bench -t bench_lib\n$ spin bench -t bench_random.Random\n$ spin bench -t Random -t Shuffle\n\nTwo benchmark runs can be compared.\nBy default, `HEAD` is compared to `main`.\nYou can also specify the branches/commits to compare:\n\n\b\n$ spin bench --compare\n$ spin bench --compare main\n$ spin bench --compare main HEAD\n\nYou can also choose which benchmarks to run in comparison mode:\n\n$ spin bench -t Random --compare",
        "output": "def bench(ctx, tests, compare, verbose, quick, commits, build_dir):\n    \"\"\" Run benchmarks.\n\n    \\b\n    Examples:\n\n    \\b\n    $ spin bench -t bench_lib\n    $ spin bench -t bench_random.Random\n    $ spin bench -t Random -t Shuffle\n\n    Two benchmark runs can be compared.\n    By default, `HEAD` is compared to `main`.\n    You can also specify the branches/commits to compare:\n\n    \\b\n    $ spin bench --compare\n    $ spin bench --compare main\n    $ spin bench --compare main HEAD\n\n    You can also choose which benchmarks to run in comparison mode:\n\n    $ spin bench -t Random --compare\n    \"\"\"\n    if not commits:\n        commits = ('main', 'HEAD')\n    elif len(commits) == 1:\n        commits = commits + ('HEAD',)\n    elif len(commits) > 2:\n        raise click.ClickException(\n            'Need a maximum of two revisions to compare'\n        )\n\n    bench_args = []\n    for t in tests:\n        bench_args += ['--bench', t]\n\n    if verbose:\n        bench_args = ['-v'] + bench_args\n\n    if quick:\n        bench_args = ['--quick'] + bench_args\n\n    if not compare:\n        # No comparison requested; we build and benchmark the current version\n\n        click.secho(\n            \"Invoking `build` prior to running benchmarks:\",\n            bold=True, fg=\"bright_green\"\n        )\n        ctx.invoke(build)\n\n        meson._set_pythonpath(build_dir)\n\n        p = spin.util.run(\n            ['python', '-c', 'import numpy as np; print(np.__version__)'],\n            cwd='benchmarks',\n            echo=False,\n            output=False\n        )\n        os.chdir('..')\n\n        np_ver = p.stdout.strip().decode('ascii')\n        click.secho(\n            f'Running benchmarks on NumPy {np_ver}',\n            bold=True, fg=\"bright_green\"\n        )\n        cmd = [\n            'asv', 'run', '--dry-run', '--show-stderr', '--python=same'\n        ] + bench_args\n        _run_asv(cmd)\n    else:\n        # Ensure that we don't have uncommited changes\n        commit_a, commit_b = [_commit_to_sha(c) for c in commits]\n\n        if commit_b == 'HEAD' and _dirty_git_working_dir():\n            click.secho(\n                \"WARNING: you have uncommitted changes --- \"\n                \"these will NOT be benchmarked!\",\n                fg=\"red\"\n            )\n\n        cmd_compare = [\n            'asv', 'continuous', '--factor', '1.05',\n        ] + bench_args + [commit_a, commit_b]\n        _run_asv(cmd_compare)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "ipython",
        "input": " Launch IPython shell with PYTHONPATH set\n\nOPTIONS are passed through directly to IPython, e.g.:\n\nspin ipython -i myscript.py",
        "output": "def ipython(*, ipython_args, build_dir):\n    \"\"\" Launch IPython shell with PYTHONPATH set\n\n    OPTIONS are passed through directly to IPython, e.g.:\n\n    spin ipython -i myscript.py\n    \"\"\"\n    env = os.environ\n    env['PYTHONWARNINGS'] = env.get('PYTHONWARNINGS', 'all')\n\n    ctx = click.get_current_context()\n    ctx.invoke(build)\n\n    ppath = meson._set_pythonpath(build_dir)\n\n    print(f' Launching IPython with PYTHONPATH=\"{ppath}\"')\n\n    # In spin >= 0.13.1, can replace with extended command, setting `pre_import`\n    preimport = (r\"import numpy as np; \"\n                 r\"print(f'\\nPreimported NumPy {np.__version__} as np')\")\n    spin.util.run([\"ipython\", \"--ignore-cwd\",\n                   f\"--TerminalIPythonApp.exec_lines={preimport}\"] +\n                  list(ipython_args))"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "mypy",
        "input": " Run Mypy tests for NumPy",
        "output": "def mypy(ctx):\n    \"\"\" Run Mypy tests for NumPy\n    \"\"\"\n    env = os.environ\n    env['NPY_RUN_MYPY_IN_TESTSUITE'] = '1'\n    ctx.params['pytest_args'] = [os.path.join('numpy', 'typing')]\n    ctx.params['markexpr'] = 'full'\n    ctx.forward(test)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "config_openblas",
        "input": " Create .openblas/scipy-openblas.pc file\n\nAlso create _distributor_init_local.py\n\nRequires a pre-installed scipy-openblas64 or scipy-openblas32",
        "output": "def config_openblas(with_scipy_openblas):\n    \"\"\" Create .openblas/scipy-openblas.pc file\n\n    Also create _distributor_init_local.py\n\n    Requires a pre-installed scipy-openblas64 or scipy-openblas32\n    \"\"\"\n    _config_openblas(with_scipy_openblas)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "notes",
        "input": " Generate release notes and validate\n\n\b\nExample:\n\n\b\n$ spin notes --version-override 2.0\n\n\b\nTo automatically pick the version\n\n\b\n$ spin notes",
        "output": "def notes(version_override):\n    \"\"\" Generate release notes and validate\n\n    \\b\n    Example:\n\n    \\b\n    $ spin notes --version-override 2.0\n\n    \\b\n    To automatically pick the version\n\n    \\b\n    $ spin notes\n    \"\"\"\n    project_config = spin.util.get_config()\n    version = version_override or project_config['project.version']\n\n    click.secho(\n        f\"Generating release notes for NumPy {version}\",\n        bold=True, fg=\"bright_green\",\n    )\n\n    # Check if `towncrier` is installed\n    if not shutil.which(\"towncrier\"):\n        raise click.ClickException(\n            \"please install `towncrier` to use this command\"\n        )\n\n    click.secho(\n        f\"Reading upcoming changes from {project_config['tool.towncrier.directory']}\",\n        bold=True, fg=\"bright_yellow\"\n    )\n    # towncrier build --version 2.1 --yes\n    cmd = [\"towncrier\", \"build\", \"--version\", version, \"--yes\"]\n    p = spin.util.run(cmd=cmd, sys_exit=False, output=True, encoding=\"utf-8\")\n    if p.returncode != 0:\n        raise click.ClickException(\n            f\"`towncrier` failed returned {p.returncode} with error `{p.stderr}`\"\n        )\n\n    output_path = project_config['tool.towncrier.filename'].format(version=version)\n    click.secho(\n        f\"Release notes successfully written to {output_path}\",\n        bold=True, fg=\"bright_yellow\"\n    )\n\n    click.secho(\n        \"Verifying consumption of all news fragments\",\n        bold=True, fg=\"bright_green\",\n    )\n\n    try:\n        test_notes = _get_numpy_tools(pathlib.Path('ci', 'test_all_newsfragments_used.py'))\n    except ModuleNotFoundError as e:\n        raise click.ClickException(\n            f\"{e.msg}. Install the missing packages to use this command.\"\n        )\n\n    test_notes.main()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "maxes_of_dots",
        "input": "A magical feature score for each feature in each dataset\n:ref:`Haxby et al., Neuron (2011) <HGC+11>`.\nIf arrays are column-wise zscore-d before computation it\nresults in characterizing each column in each array with\nsum of maximal correlations of that column with columns\nin other arrays.\n\nArrays must agree only on the first dimension.\n\nNumpy uses this as a simultaneous benchmark of 1) dot products\nand 2) max(<array>, axis=<int>).",
        "output": "def maxes_of_dots(self, arrays):\n        \"\"\"\n        A magical feature score for each feature in each dataset\n        :ref:`Haxby et al., Neuron (2011) <HGC+11>`.\n        If arrays are column-wise zscore-d before computation it\n        results in characterizing each column in each array with\n        sum of maximal correlations of that column with columns\n        in other arrays.\n\n        Arrays must agree only on the first dimension.\n\n        Numpy uses this as a simultaneous benchmark of 1) dot products\n        and 2) max(<array>, axis=<int>).\n        \"\"\"\n        feature_scores = ([0] * len(arrays))\n        for (i, sd) in enumerate(arrays):\n            for (j, sd2) in enumerate(arrays[(i + 1):]):\n                corr_temp = np.dot(sd.T, sd2)\n                feature_scores[i] += np.max(corr_temp, axis=1)\n                feature_scores[((j + i) + 1)] += np.max(corr_temp, axis=0)\n        return feature_scores"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "random",
        "input": "Returns a randomly-shuffled array.",
        "output": "def random(size, dtype, rnd):\n        \"\"\"\n        Returns a randomly-shuffled array.\n        \"\"\"\n        arr = np.arange(size, dtype=dtype)\n        rnd = np.random.RandomState(1792364059)\n        np.random.shuffle(arr)\n        rnd.shuffle(arr)\n        return arr"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "ordered",
        "input": "Returns an ordered array.",
        "output": "def ordered(size, dtype, rnd):\n        \"\"\"\n        Returns an ordered array.\n        \"\"\"\n        return np.arange(size, dtype=dtype)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "reversed",
        "input": "Returns an array that's in descending order.",
        "output": "def reversed(size, dtype, rnd):\n        \"\"\"\n        Returns an array that's in descending order.\n        \"\"\"\n        dtype = np.dtype(dtype)\n        try:\n            with np.errstate(over=\"raise\"):\n                res = dtype.type(size - 1)\n        except (OverflowError, FloatingPointError):\n            raise SkipNotImplemented(\"Cannot construct arange for this size.\")\n\n        return np.arange(size - 1, -1, -1, dtype=dtype)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "uniform",
        "input": "Returns an array that has the same value everywhere.",
        "output": "def uniform(size, dtype, rnd):\n        \"\"\"\n        Returns an array that has the same value everywhere.\n        \"\"\"\n        return np.ones(size, dtype=dtype)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "sorted_block",
        "input": "Returns an array with blocks that are all sorted.",
        "output": "def sorted_block(size, dtype, block_size, rnd):\n        \"\"\"\n        Returns an array with blocks that are all sorted.\n        \"\"\"\n        a = np.arange(size, dtype=dtype)\n        b = []\n        if size < block_size:\n            return a\n        block_num = size // block_size\n        for i in range(block_num):\n            b.extend(a[i::block_num])\n        return np.array(b)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "time_randint_fast",
        "input": "Compare to uint32 below",
        "output": "def time_randint_fast(self):\n        \"\"\"Compare to uint32 below\"\"\"\n        np.random.randint(0, 2**30, size=10**5)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "time_randint_slow",
        "input": "Compare to uint32 below",
        "output": "def time_randint_slow(self):\n        \"\"\"Compare to uint32 below\"\"\"\n        np.random.randint(0, 2**30 + 1, size=10**5)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "time_bounded",
        "input": "Timer for 8-bit bounded values.\n\nParameters (packed as args)\n----------\ndt : {uint8, uint16, uint32, unit64}\n      output dtype\nmax : int\n      Upper bound for range. Lower is always 0.  Must be <= 2**bits.",
        "output": "def time_bounded(self, bitgen, args):\n        \"\"\"\n        Timer for 8-bit bounded values.\n\n        Parameters (packed as args)\n        ----------\n        dt : {uint8, uint16, uint32, unit64}\n              output dtype\n        max : int\n              Upper bound for range. Lower is always 0.  Must be <= 2**bits.\n        \"\"\"\n        dt, max = args\n        if bitgen == 'numpy':\n            self.rg.randint(0, max + 1, nom_size, dtype=dt)\n        else:\n            self.rg.integers(0, max + 1, nom_size, dtype=dt)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "test_parallel",
        "input": "Decorator to run the same function multiple times in parallel.\n\nParameters\n----------\nnum_threads : int, optional\n    The number of times the function is run in parallel.\nkwargs_list : list of dicts, optional\n    The list of kwargs to update original\n    function kwargs on different threads.\n\nNotes\n-----\nThis decorator does not pass the return value of the decorated function.\n\nOriginal from scikit-image:\n\nhttps://github.com/scikit-image/scikit-image/pull/1519",
        "output": "def test_parallel(num_threads=2, kwargs_list=None):\n    \"\"\"\n    Decorator to run the same function multiple times in parallel.\n\n    Parameters\n    ----------\n    num_threads : int, optional\n        The number of times the function is run in parallel.\n    kwargs_list : list of dicts, optional\n        The list of kwargs to update original\n        function kwargs on different threads.\n\n    Notes\n    -----\n    This decorator does not pass the return value of the decorated function.\n\n    Original from scikit-image:\n\n    https://github.com/scikit-image/scikit-image/pull/1519\n\n    \"\"\"\n    assert num_threads > 0\n    has_kwargs_list = kwargs_list is not None\n    if has_kwargs_list:\n        assert len(kwargs_list) == num_threads\n\n    def wrapper(func):\n        @wraps(func)\n        def inner(*args, **kwargs):\n            if has_kwargs_list:\n                update_kwargs = lambda i: dict(kwargs, **kwargs_list[i])\n            else:\n                update_kwargs = lambda i: kwargs\n            threads = []\n            for i in range(num_threads):\n                updated_kwargs = update_kwargs(i)\n                thread = threading.Thread(target=func, args=args, kwargs=updated_kwargs)\n                threads.append(thread)\n            for thread in threads:\n                thread.start()\n            for thread in threads:\n                thread.join()\n\n        return inner\n\n    return wrapper"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "clean",
        "input": " Clean build folder.\n\nVery rarely needed since meson-python recompiles as needed when sklearn is\nimported.\n\nOne known use case where \"spin clean\" is useful: avoid compilation errors\nwhen switching from numpy<2 to numpy>=2 in the same conda environment or\nvirtualenv.",
        "output": "def clean():\n    \"\"\" Clean build folder.\n\n    Very rarely needed since meson-python recompiles as needed when sklearn is\n    imported.\n\n    One known use case where \"spin clean\" is useful: avoid compilation errors\n    when switching from numpy<2 to numpy>=2 in the same conda environment or\n    virtualenv.\n    \"\"\"\n    util.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"scikit-learn\", \"-y\"])\n    default_meson_build_dir = (\n        f\"build/cp{sys.version_info.major}{sys.version_info.minor}\"\n    )\n    click.secho(\n        f\"removing default Meson build dir: {default_meson_build_dir}\",\n        bold=True,\n        fg=\"bright_blue\",\n    )\n\n    shutil.rmtree(default_meson_build_dir, ignore_errors=True)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_from_config",
        "input": "Get benchmarks configuration from the config.json file",
        "output": "def get_from_config():\n    \"\"\"Get benchmarks configuration from the config.json file\"\"\"\n    current_path = Path(__file__).resolve().parent\n\n    config_path = current_path / \"config.json\"\n    with open(config_path, \"r\") as config_file:\n        config_file = \"\".join(line for line in config_file if line and \"//\" not in line)\n        config = json.loads(config_file)\n\n    profile = os.getenv(\"SKLBENCH_PROFILE\", config[\"profile\"])\n\n    n_jobs_vals_env = os.getenv(\"SKLBENCH_NJOBS\")\n    if n_jobs_vals_env:\n        n_jobs_vals = json.loads(n_jobs_vals_env)\n    else:\n        n_jobs_vals = config[\"n_jobs_vals\"]\n    if not n_jobs_vals:\n        n_jobs_vals = list(range(1, 1 + cpu_count()))\n\n    cache_path = current_path / \"cache\"\n    cache_path.mkdir(exist_ok=True)\n    (cache_path / \"estimators\").mkdir(exist_ok=True)\n    (cache_path / \"tmp\").mkdir(exist_ok=True)\n\n    save_estimators = os.getenv(\"SKLBENCH_SAVE_ESTIMATORS\", config[\"save_estimators\"])\n    save_dir = os.getenv(\"ASV_COMMIT\", \"new\")[:8]\n\n    if save_estimators:\n        (cache_path / \"estimators\" / save_dir).mkdir(exist_ok=True)\n\n    base_commit = os.getenv(\"SKLBENCH_BASE_COMMIT\", config[\"base_commit\"])\n\n    bench_predict = os.getenv(\"SKLBENCH_PREDICT\", config[\"bench_predict\"])\n    bench_transform = os.getenv(\"SKLBENCH_TRANSFORM\", config[\"bench_transform\"])\n\n    return (\n        profile,\n        n_jobs_vals,\n        save_estimators,\n        save_dir,\n        base_commit,\n        bench_predict,\n        bench_transform,\n    )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_estimator_path",
        "input": "Get path of pickled fitted estimator",
        "output": "def get_estimator_path(benchmark, directory, params, save=False):\n    \"\"\"Get path of pickled fitted estimator\"\"\"\n    path = Path(__file__).resolve().parent / \"cache\"\n    path = (path / \"estimators\" / directory) if save else (path / \"tmp\")\n\n    filename = (\n        benchmark.__class__.__name__\n        + \"_estimator_\"\n        + \"_\".join(list(map(str, params)))\n        + \".pkl\"\n    )\n\n    return path / filename"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "clear_tmp",
        "input": "Clean the tmp directory",
        "output": "def clear_tmp():\n    \"\"\"Clean the tmp directory\"\"\"\n    path = Path(__file__).resolve().parent / \"cache\" / \"tmp\"\n    for child in path.iterdir():\n        child.unlink()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "make_data",
        "input": "Return the dataset for a combination of parameters",
        "output": "def make_data(self, params):\n        \"\"\"Return the dataset for a combination of parameters\"\"\"\n        # The datasets are cached using joblib.Memory so it's fast and can be\n        # called for each repeat\n        pass"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "make_estimator",
        "input": "Return an instance of the estimator for a combination of parameters",
        "output": "def make_estimator(self, params):\n        \"\"\"Return an instance of the estimator for a combination of parameters\"\"\"\n        pass"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "skip",
        "input": "Return True if the benchmark should be skipped for these params",
        "output": "def skip(self, params):\n        \"\"\"Return True if the benchmark should be skipped for these params\"\"\"\n        return False"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "setup_cache",
        "input": "Pickle a fitted estimator for all combinations of parameters",
        "output": "def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n\n        clear_tmp()\n\n        param_grid = list(itertools.product(*self.params))\n\n        for params in param_grid:\n            if self.skip(params):\n                continue\n\n            estimator = self.make_estimator(params)\n            X, _, y, _ = self.make_data(params)\n\n            estimator.fit(X, y)\n\n            est_path = get_estimator_path(\n                self, Benchmark.save_dir, params, Benchmark.save_estimators\n            )\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "setup",
        "input": "Generate dataset and load the fitted estimator",
        "output": "def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n\n        if self.skip(params):\n            raise NotImplementedError\n\n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n\n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\n        self.make_scorers()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "load_data",
        "input": "Load the data, then cache and memmap the train/test split",
        "output": "def load_data(dtype=np.float32, order=\"C\", random_state=13):\n    \"\"\"Load the data, then cache and memmap the train/test split\"\"\"\n    ######################################################################\n    # Load dataset\n    print(\"Loading dataset...\")\n    data = fetch_covtype(\n        download_if_missing=True, shuffle=True, random_state=random_state\n    )\n    X = check_array(data[\"data\"], dtype=dtype, order=order)\n    y = (data[\"target\"] != 1).astype(int)\n\n    # Create train-test split (as [Joachims, 2006])\n    print(\"Creating train-test split...\")\n    n_train = 522911\n    X_train = X[:n_train]\n    y_train = y[:n_train]\n    X_test = X[n_train:]\n    y_test = y[n_train:]\n\n    # Standardize first 10 features (the numerical ones)\n    mean = X_train.mean(axis=0)\n    std = X_train.std(axis=0)\n    mean[10:] = 0.0\n    std[10:] = 1.0\n    X_train = (X_train - mean) / std\n    X_test = (X_test - mean) / std\n    return X_train, X_test, y_train, y_test"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_parse_skip_subdirs_file",
        "input": "Read .mpl_skip_subdirs.yaml for subdirectories to not\nbuild if we do `make html-skip-subdirs`.  Subdirectories\nare relative to the toplevel directory.  Note that you\ncannot skip 'users' as it contains the table of contents,\nbut you can skip subdirectories of 'users'.  Doing this\ncan make partial builds very fast.",
        "output": "def _parse_skip_subdirs_file():\n    \"\"\"\n    Read .mpl_skip_subdirs.yaml for subdirectories to not\n    build if we do `make html-skip-subdirs`.  Subdirectories\n    are relative to the toplevel directory.  Note that you\n    cannot skip 'users' as it contains the table of contents,\n    but you can skip subdirectories of 'users'.  Doing this\n    can make partial builds very fast.\n    \"\"\"\n    default_skip_subdirs = [\n        'users/prev_whats_new/*', 'users/explain/*', 'api/*', 'gallery/*',\n        'tutorials/*', 'plot_types/*', 'devel/*']\n    try:\n        with open(\".mpl_skip_subdirs.yaml\", 'r') as fin:\n            print('Reading subdirectories to skip from',\n                  '.mpl_skip_subdirs.yaml')\n            out = yaml.full_load(fin)\n        return out['skip_subdirs']\n    except FileNotFoundError:\n        # make a default:\n        with open(\".mpl_skip_subdirs.yaml\", 'w') as fout:\n            yamldict = {'skip_subdirs': default_skip_subdirs,\n                        'comment': 'For use with make html-skip-subdirs'}\n            yaml.dump(yamldict, fout)\n        print('Skipping subdirectories, but .mpl_skip_subdirs.yaml',\n              'not found so creating a default one. Edit this file',\n              'to customize which directories are included in build.')\n\n        return default_skip_subdirs"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "autodoc_process_bases",
        "input": "Hide pybind11 base object from inheritance tree.\n\nNote, *bases* must be modified in place.",
        "output": "def autodoc_process_bases(app, name, obj, options, bases):\n    \"\"\"\n    Hide pybind11 base object from inheritance tree.\n\n    Note, *bases* must be modified in place.\n    \"\"\"\n    for cls in bases[:]:\n        if not isinstance(cls, type):\n            continue\n        if cls.__module__ == 'pybind11_builtins' and cls.__name__ == 'pybind11_object':\n            bases.remove(cls)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "add_html_cache_busting",
        "input": "Add cache busting query on CSS and JavaScript assets.\n\nThis adds the Matplotlib version as a query to the link reference in the\nHTML, if the path is not absolute (i.e., it comes from the `_static`\ndirectory) and doesn't already have a query.\n\n.. note:: Sphinx 7.1 provides asset checksums; so this hook only runs on\n          Sphinx 7.0 and earlier.",
        "output": "def add_html_cache_busting(app, pagename, templatename, context, doctree):\n    \"\"\"\n    Add cache busting query on CSS and JavaScript assets.\n\n    This adds the Matplotlib version as a query to the link reference in the\n    HTML, if the path is not absolute (i.e., it comes from the `_static`\n    directory) and doesn't already have a query.\n\n    .. note:: Sphinx 7.1 provides asset checksums; so this hook only runs on\n              Sphinx 7.0 and earlier.\n    \"\"\"\n    from sphinx.builders.html import Stylesheet, JavaScript\n\n    css_tag = context['css_tag']\n    js_tag = context['js_tag']\n\n    def css_tag_with_cache_busting(css):\n        if isinstance(css, Stylesheet) and css.filename is not None:\n            url = urlsplit(css.filename)\n            if not url.netloc and not url.query:\n                url = url._replace(query=SHA)\n                css = Stylesheet(urlunsplit(url), priority=css.priority,\n                                 **css.attributes)\n        return css_tag(css)\n\n    def js_tag_with_cache_busting(js):\n        if isinstance(js, JavaScript) and js.filename is not None:\n            url = urlsplit(js.filename)\n            if not url.netloc and not url.query:\n                url = url._replace(query=SHA)\n                js = JavaScript(urlunsplit(url), priority=js.priority,\n                                **js.attributes)\n        return js_tag(js)\n\n    context['css_tag'] = css_tag_with_cache_busting\n    context['js_tag'] = js_tag_with_cache_busting"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "linkcode_resolve",
        "input": "Determine the URL corresponding to Python object",
        "output": "def linkcode_resolve(domain, info):\n        \"\"\"\n        Determine the URL corresponding to Python object\n        \"\"\"\n        if domain != 'py':\n            return None\n\n        modname = info['module']\n        fullname = info['fullname']\n\n        submod = sys.modules.get(modname)\n        if submod is None:\n            return None\n\n        obj = submod\n        for part in fullname.split('.'):\n            try:\n                obj = getattr(obj, part)\n            except AttributeError:\n                return None\n\n        if inspect.isfunction(obj):\n            obj = inspect.unwrap(obj)\n        try:\n            fn = inspect.getsourcefile(obj)\n        except TypeError:\n            fn = None\n        if not fn or fn.endswith('__init__.py'):\n            try:\n                fn = inspect.getsourcefile(sys.modules[obj.__module__])\n            except (TypeError, AttributeError, KeyError):\n                fn = None\n        if not fn:\n            return None\n\n        try:\n            source, lineno = inspect.getsourcelines(obj)\n        except (OSError, TypeError):\n            lineno = None\n\n        linespec = (f\"#L{lineno:d}-L{lineno + len(source) - 1:d}\"\n                    if lineno else \"\")\n\n        startdir = Path(matplotlib.__file__).parent.parent\n        try:\n            fn = os.path.relpath(fn, start=startdir).replace(os.path.sep, '/')\n        except ValueError:\n            return None\n\n        if not fn.startswith(('matplotlib/', 'mpl_toolkits/')):\n            return None\n\n        version = parse_version(matplotlib.__version__)\n        tag = 'main' if version.is_devrelease else f'v{version.public}'\n        return (\"https://github.com/matplotlib/matplotlib/blob\"\n                f\"/{tag}/lib/{fn}{linespec}\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__call__",
        "input": "Return a string determining the sort order.",
        "output": "def __call__(self, item):\n        \"\"\"Return a string determining the sort order.\"\"\"\n        if item in self.ordered_list:\n            return f\"{self.ordered_list.index(item):04d}\"\n        else:\n            return f\"{self.ordered_list.index(UNSORTED):04d}{item}\""
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__call__",
        "input": "Return a string determining the sort order.",
        "output": "def __call__(self, item):\n        \"\"\"Return a string determining the sort order.\"\"\"\n        if item in self.ordered_list:\n            return f\"{self.ordered_list.index(item):04d}\"\n        else:\n            # ensure not explicitly listed items come last.\n            return \"zzz\" + item"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "make_link_node",
        "input": "Create a link to a github resource.\n\n:param rawtext: Text being replaced with link node.\n:param app: Sphinx application context\n:param type: Link type (issues, changeset, etc.)\n:param slug: ID of the thing to link to\n:param options: Options dictionary passed to role func.",
        "output": "def make_link_node(rawtext, app, type, slug, options):\n    \"\"\"\n    Create a link to a github resource.\n\n    :param rawtext: Text being replaced with link node.\n    :param app: Sphinx application context\n    :param type: Link type (issues, changeset, etc.)\n    :param slug: ID of the thing to link to\n    :param options: Options dictionary passed to role func.\n    \"\"\"\n\n    try:\n        base = app.config.github_project_url\n        if not base:\n            raise AttributeError\n        if not base.endswith('/'):\n            base += '/'\n    except AttributeError as err:\n        raise ValueError(\n            f'github_project_url configuration value is not set '\n            f'({err})') from err\n\n    ref = base + type + '/' + slug + '/'\n    set_classes(options)\n    prefix = \"#\"\n    if type == 'pull':\n        prefix = \"PR \" + prefix\n    node = nodes.reference(rawtext, prefix + utils.unescape(slug), refuri=ref,\n                           **options)\n    return node"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "ghissue_role",
        "input": "Link to a GitHub issue.\n\nReturns 2 part tuple containing list of nodes to insert into the\ndocument and a list of system messages.  Both are allowed to be\nempty.\n\n:param name: The role name used in the document.\n:param rawtext: The entire markup snippet, with role.\n:param text: The text marked with the role.\n:param lineno: The line number where rawtext appears in the input.\n:param inliner: The inliner instance that called us.\n:param options: Directive options for customization.\n:param content: The directive content for customization.",
        "output": "def ghissue_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n    \"\"\"\n    Link to a GitHub issue.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    :param name: The role name used in the document.\n    :param rawtext: The entire markup snippet, with role.\n    :param text: The text marked with the role.\n    :param lineno: The line number where rawtext appears in the input.\n    :param inliner: The inliner instance that called us.\n    :param options: Directive options for customization.\n    :param content: The directive content for customization.\n    \"\"\"\n\n    try:\n        issue_num = int(text)\n        if issue_num <= 0:\n            raise ValueError\n    except ValueError:\n        msg = inliner.reporter.error(\n            'GitHub issue number must be a number greater than or equal to 1; '\n            '\"%s\" is invalid.' % text, line=lineno)\n        prb = inliner.problematic(rawtext, rawtext, msg)\n        return [prb], [msg]\n    app = inliner.document.settings.env.app\n    if 'pull' in name.lower():\n        category = 'pull'\n    elif 'issue' in name.lower():\n        category = 'issues'\n    else:\n        msg = inliner.reporter.error(\n            'GitHub roles include \"ghpull\" and \"ghissue\", '\n            '\"%s\" is invalid.' % name, line=lineno)\n        prb = inliner.problematic(rawtext, rawtext, msg)\n        return [prb], [msg]\n    node = make_link_node(rawtext, app, category, str(issue_num), options)\n    return [node], []"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "ghuser_role",
        "input": "Link to a GitHub user.\n\nReturns 2 part tuple containing list of nodes to insert into the\ndocument and a list of system messages.  Both are allowed to be\nempty.\n\n:param name: The role name used in the document.\n:param rawtext: The entire markup snippet, with role.\n:param text: The text marked with the role.\n:param lineno: The line number where rawtext appears in the input.\n:param inliner: The inliner instance that called us.\n:param options: Directive options for customization.\n:param content: The directive content for customization.",
        "output": "def ghuser_role(name, rawtext, text, lineno, inliner, options={}, content=[]):\n    \"\"\"\n    Link to a GitHub user.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    :param name: The role name used in the document.\n    :param rawtext: The entire markup snippet, with role.\n    :param text: The text marked with the role.\n    :param lineno: The line number where rawtext appears in the input.\n    :param inliner: The inliner instance that called us.\n    :param options: Directive options for customization.\n    :param content: The directive content for customization.\n    \"\"\"\n    ref = 'https://www.github.com/' + text\n    node = nodes.reference(rawtext, text, refuri=ref, **options)\n    return [node], []"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "ghcommit_role",
        "input": "Link to a GitHub commit.\n\nReturns 2 part tuple containing list of nodes to insert into the\ndocument and a list of system messages.  Both are allowed to be\nempty.\n\n:param name: The role name used in the document.\n:param rawtext: The entire markup snippet, with role.\n:param text: The text marked with the role.\n:param lineno: The line number where rawtext appears in the input.\n:param inliner: The inliner instance that called us.\n:param options: Directive options for customization.\n:param content: The directive content for customization.",
        "output": "def ghcommit_role(\n        name, rawtext, text, lineno, inliner, options={}, content=[]):\n    \"\"\"\n    Link to a GitHub commit.\n\n    Returns 2 part tuple containing list of nodes to insert into the\n    document and a list of system messages.  Both are allowed to be\n    empty.\n\n    :param name: The role name used in the document.\n    :param rawtext: The entire markup snippet, with role.\n    :param text: The text marked with the role.\n    :param lineno: The line number where rawtext appears in the input.\n    :param inliner: The inliner instance that called us.\n    :param options: Directive options for customization.\n    :param content: The directive content for customization.\n    \"\"\"\n    app = inliner.document.settings.env.app\n    try:\n        base = app.config.github_project_url\n        if not base:\n            raise AttributeError\n        if not base.endswith('/'):\n            base += '/'\n    except AttributeError as err:\n        raise ValueError(\n            f'github_project_url configuration value is not set '\n            f'({err})') from err\n\n    ref = base + text\n    node = nodes.reference(rawtext, text[:6], refuri=ref, **options)\n    return [node], []"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "setup",
        "input": "Install the plugin.\n\n:param app: Sphinx application context.",
        "output": "def setup(app):\n    \"\"\"\n    Install the plugin.\n\n    :param app: Sphinx application context.\n    \"\"\"\n    app.add_role('ghissue', ghissue_role)\n    app.add_role('ghpull', ghissue_role)\n    app.add_role('ghuser', ghuser_role)\n    app.add_role('ghcommit', ghcommit_role)\n    app.add_config_value('github_project_url', None, 'env')\n\n    metadata = {'parallel_read_safe': True, 'parallel_write_safe': True}\n    return metadata"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "get_location",
        "input": "Given a docutils node and a sphinx application, return a string\nrepresentation of the source location of this node.\n\nUsually, this will be of the form \"path/to/file:linenumber\". Two\nspecial values can be emitted, \"<external>\" for paths which are\nnot contained in this source tree (e.g. docstrings included from\nother modules) or \"<unknown>\", indicating that the sphinx application\ncannot locate the original source file (usually because an extension\nhas injected text into the sphinx parsing engine).",
        "output": "def get_location(node, app):\n    \"\"\"\n    Given a docutils node and a sphinx application, return a string\n    representation of the source location of this node.\n\n    Usually, this will be of the form \"path/to/file:linenumber\". Two\n    special values can be emitted, \"<external>\" for paths which are\n    not contained in this source tree (e.g. docstrings included from\n    other modules) or \"<unknown>\", indicating that the sphinx application\n    cannot locate the original source file (usually because an extension\n    has injected text into the sphinx parsing engine).\n    \"\"\"\n    source, line = get_source_line(node)\n\n    if source:\n        # 'source' can have the form '/some/path:docstring of some.api' but the\n        # colons are forbidden on windows, but on posix just passes through.\n        if ':docstring of' in source:\n            path, *post = source.rpartition(':docstring of')\n            post = ''.join(post)\n        else:\n            path = source\n            post = ''\n        # We locate references relative to the parent of the doc\n        # directory, which for matplotlib, will be the root of the\n        # matplotlib repo. When matplotlib is not an editable install\n        # weird things will happen, but we can't totally recover from\n        # that.\n        basepath = Path(app.srcdir).parent.resolve()\n\n        fullpath = Path(path).resolve()\n\n        try:\n            path = fullpath.relative_to(basepath)\n        except ValueError:\n            # Sometimes docs directly contain e.g. docstrings\n            # from installed modules, and we record those as\n            # <external> so as to be independent of where the\n            # module was installed\n            path = Path(\"<external>\") / fullpath.name\n\n        # Ensure that all reported paths are POSIX so that docs\n        # on windows result in the same warnings in the JSON file.\n        path = path.as_posix()\n\n    else:\n        path = \"<unknown>\"\n        post = ''\n    if not line:\n        line = \"\"\n\n    return f\"{path}{post}:{line}\""
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_truncate_location",
        "input": "Cuts off anything after the first colon in location strings.\n\nThis allows for easy comparison even when line numbers change\n(as they do regularly).",
        "output": "def _truncate_location(location):\n    \"\"\"\n    Cuts off anything after the first colon in location strings.\n\n    This allows for easy comparison even when line numbers change\n    (as they do regularly).\n    \"\"\"\n    return location.split(\":\", 1)[0]"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "handle_missing_reference",
        "input": "Handle the warn-missing-reference Sphinx event.\n\nThis function will:\n\n#. record missing references for saving/comparing with ignored list.\n#. prevent Sphinx from raising a warning on ignored references.",
        "output": "def handle_missing_reference(app, domain, node):\n    \"\"\"\n    Handle the warn-missing-reference Sphinx event.\n\n    This function will:\n\n    #. record missing references for saving/comparing with ignored list.\n    #. prevent Sphinx from raising a warning on ignored references.\n    \"\"\"\n    refdomain = node[\"refdomain\"]\n    reftype = node[\"reftype\"]\n    target = node[\"reftarget\"]\n    location = get_location(node, app)\n    domain_type = f\"{refdomain}:{reftype}\"\n\n    app.env.missing_references_events[(domain_type, target)].add(location)\n\n    # If we're ignoring this event, return True so that Sphinx thinks we handled it,\n    # even though we didn't print or warn. If we aren't ignoring it, Sphinx will print a\n    # warning about the missing reference.\n    if location in app.env.missing_references_ignored_references.get(\n            (domain_type, target), []):\n        return True"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "warn_unused_missing_references",
        "input": "Check that all lines of the existing JSON file are still necessary.",
        "output": "def warn_unused_missing_references(app, exc):\n    \"\"\"\n    Check that all lines of the existing JSON file are still necessary.\n    \"\"\"\n    # We can only warn if we are building from a source install\n    # otherwise, we just have to skip this step.\n    basepath = Path(matplotlib.__file__).parent.parent.parent.resolve()\n    srcpath = Path(app.srcdir).parent.resolve()\n\n    if basepath != srcpath:\n        return\n\n    # This is a dictionary of {(domain_type, target): locations}\n    references_ignored = app.env.missing_references_ignored_references\n    references_events = app.env.missing_references_events\n\n    # Warn about any reference which is no longer missing.\n    for (domain_type, target), locations in references_ignored.items():\n        missing_reference_locations = [\n            _truncate_location(location)\n            for location in references_events.get((domain_type, target), [])]\n\n        # For each ignored reference location, ensure a missing reference\n        # was observed. If it wasn't observed, issue a warning.\n        for ignored_reference_location in locations:\n            short_location = _truncate_location(ignored_reference_location)\n            if short_location not in missing_reference_locations:\n                msg = (f\"Reference {domain_type} {target} for \"\n                       f\"{ignored_reference_location} can be removed\"\n                       f\" from {app.config.missing_references_filename}.\"\n                        \" It is no longer a missing reference in the docs.\")\n                logger.warning(msg,\n                               location=ignored_reference_location,\n                               type='ref',\n                               subtype=domain_type)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "save_missing_references",
        "input": "Write a new JSON file containing missing references.",
        "output": "def save_missing_references(app, exc):\n    \"\"\"\n    Write a new JSON file containing missing references.\n    \"\"\"\n    json_path = Path(app.confdir) / app.config.missing_references_filename\n    references_warnings = app.env.missing_references_events\n    _write_missing_references_json(references_warnings, json_path)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_write_missing_references_json",
        "input": "Convert ignored references to a format which we can write as JSON\n\nConvert from ``{(domain_type, target): locations}`` to\n``{domain_type: {target: locations}}`` since JSON can't serialize tuples.",
        "output": "def _write_missing_references_json(records, json_path):\n    \"\"\"\n    Convert ignored references to a format which we can write as JSON\n\n    Convert from ``{(domain_type, target): locations}`` to\n    ``{domain_type: {target: locations}}`` since JSON can't serialize tuples.\n    \"\"\"\n    # Sorting records and keys avoids needlessly big diffs when\n    # missing_references.json is regenerated.\n    transformed_records = defaultdict(dict)\n    for (domain_type, target), paths in records.items():\n        transformed_records[domain_type][target] = sorted(paths)\n    with json_path.open(\"w\") as stream:\n        json.dump(transformed_records, stream, sort_keys=True, indent=2)\n        stream.write(\"\\n\")  # Silence pre-commit no-newline-at-end-of-file warning."
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_read_missing_references_json",
        "input": "Convert from the JSON file to the form used internally by this\nextension.\n\nThe JSON file is stored as ``{domain_type: {target: [locations,]}}``\nsince JSON can't store dictionary keys which are tuples. We convert\nthis back to ``{(domain_type, target):[locations]}`` for internal use.",
        "output": "def _read_missing_references_json(json_path):\n    \"\"\"\n    Convert from the JSON file to the form used internally by this\n    extension.\n\n    The JSON file is stored as ``{domain_type: {target: [locations,]}}``\n    since JSON can't store dictionary keys which are tuples. We convert\n    this back to ``{(domain_type, target):[locations]}`` for internal use.\n\n    \"\"\"\n    with json_path.open(\"r\") as stream:\n        data = json.load(stream)\n\n    ignored_references = {}\n    for domain_type, targets in data.items():\n        for target, locations in targets.items():\n            ignored_references[(domain_type, target)] = locations\n    return ignored_references"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "prepare_missing_references_setup",
        "input": "Initialize this extension once the configuration is ready.",
        "output": "def prepare_missing_references_setup(app):\n    \"\"\"\n    Initialize this extension once the configuration is ready.\n    \"\"\"\n    if not app.config.missing_references_enabled:\n        # no-op when we are disabled.\n        return\n\n    app.connect(\"warn-missing-reference\", handle_missing_reference)\n    if app.config.missing_references_warn_unused_ignores:\n        app.connect(\"build-finished\", warn_unused_missing_references)\n    if app.config.missing_references_write_json:\n        app.connect(\"build-finished\", save_missing_references)\n\n    json_path = Path(app.confdir) / app.config.missing_references_filename\n    app.env.missing_references_ignored_references = (\n        _read_missing_references_json(json_path) if json_path.exists() else {}\n    )\n    app.env.missing_references_events = defaultdict(set)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "redirects",
        "input": "The mapping of the redirects.",
        "output": "def redirects(self):\n        \"\"\"The mapping of the redirects.\"\"\"\n        return self.data.setdefault('redirects', {})"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "matplotlib_reduced_latex_scraper",
        "input": "Reduce srcset when creating a PDF.\n\nBecause sphinx-gallery runs *very* early, we cannot modify this even in the\nearliest builder-inited signal. Thus we do it at scraping time.",
        "output": "def matplotlib_reduced_latex_scraper(block, block_vars, gallery_conf,\n                                     **kwargs):\n    \"\"\"\n    Reduce srcset when creating a PDF.\n\n    Because sphinx-gallery runs *very* early, we cannot modify this even in the\n    earliest builder-inited signal. Thus we do it at scraping time.\n    \"\"\"\n    from sphinx_gallery.scrapers import matplotlib_scraper\n\n    if gallery_conf['builder_name'] == 'latex':\n        gallery_conf['image_srcset'] = []\n    return matplotlib_scraper(block, block_vars, gallery_conf, **kwargs)"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "generate a text file with random data for testing file uploads",
        "output": "wanted_size=$((1024*2048*512))\nfile_size=$(( ((wanted_size/12)+1)*12 ))\nread_size=$((file_size*3/4))\n\necho \"wanted=$wanted_size file=$file_size read=$read_size\"\n\ndd if=/dev/urandom bs=$read_size count=1 | base64 > /tmp/small_test_file.txt\n\ntruncate -s \"$wanted_size\" /tmp/big_test_file.txt"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "compose",
        "input": "Create child widgets for the app.",
        "output": "def compose(self) -> ComposeResult:\n        \"\"\"Create child widgets for the app.\"\"\"\n        with Container():\n            yield SessionDisplay(id=\"session-display\")\n            yield AudioStatusIndicator(id=\"status-indicator\")\n            yield RichLog(id=\"bottom-pane\", wrap=True, highlight=True, markup=True)"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        git clone --depth=1 https://github.com/awslabs/aws-encryption-sdk-python\n        cd aws-encryption-sdk-python\n        git rev-parse HEAD\n        pip install -e .\n        pip install -r test/upstream-requirements-py311.txt\n        ;;\n    run)\n        cd aws-encryption-sdk-python\n        pytest -m local test/ --ignore test/mpl/\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        git clone --depth=1 https://github.com/certbot/josepy\n        cd josepy\n        git rev-parse HEAD\n        curl -sSL https://install.python-poetry.org | python3 -\n        \"${HOME}/.local/bin/poetry\" self add poetry-plugin-export\n        \"${HOME}/.local/bin/poetry\" export -f constraints.txt --dev --without-hashes -o constraints.txt\n        pip install -e . pytest -c constraints.txt\n        ;;\n    run)\n        cd josepy\n        pytest tests\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        git clone --depth=1 https://github.com/certbot/certbot\n        cd certbot\n        git rev-parse HEAD\n        tools/pip_install.py -e ./acme[test]\n        tools/pip_install.py -e ./certbot[test]\n        pip install -U pyopenssl\n        ;;\n    run)\n        cd certbot\n        # Ignore some warnings for now since they're now automatically promoted\n        # to errors. We can probably remove this when acme gets split into\n        # its own repo\n        pytest -Wignore certbot\n        pytest acme\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        git clone --depth=1 https://github.com/awslabs/aws-dynamodb-encryption-python\n        cd aws-dynamodb-encryption-python\n        git rev-parse HEAD\n        pip install -e .\n        pip install -r test/upstream-requirements-py311.txt\n        ;;\n    run)\n        cd aws-dynamodb-encryption-python\n        pytest -n auto test/ -m \"local and not slow and not veryslow and not nope\"\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        pip install uv\n        git clone --depth=1 https://github.com/mitmproxy/mitmproxy\n        cd mitmproxy\n        git rev-parse HEAD\n        uv pip install --system --group dev -e .\n        ;;\n    run)\n        cd mitmproxy\n        pytest test\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        git clone --depth=1 https://github.com/paramiko/paramiko\n        cd paramiko\n        git rev-parse HEAD\n        pip install -e .\n        pip install -r dev-requirements.txt\n        ;;\n    run)\n        cd paramiko\n        # https://github.com/paramiko/paramiko/issues/1927\n        inv test || inv test\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        VERSION=$(curl https://pypi.org/pypi/pyOpenSSL/json | jq -r .info.version)\n        git clone https://github.com/pyca/pyopenssl\n        cd pyopenssl\n        git checkout \"$VERSION\"\n        pip install -e \".[test]\"\n        ;;\n    run)\n        cd pyopenssl\n        pytest tests\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        git clone --depth=1 https://github.com/pyca/pyopenssl\n        cd pyopenssl\n        git rev-parse HEAD\n        pip install -e \".[test]\"\n        ;;\n    run)\n        cd pyopenssl\n        pytest tests\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        git clone --depth=1 https://github.com/secdev/scapy\n        cd scapy\n        git rev-parse HEAD\n        pip install tox\n        ;;\n    run)\n        cd scapy\n        # this tox case uses sitepackages=true to use local cryptography\n        tox -qe cryptography\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        # NOTE: placed in /tmp to avoid inscrutable pytest failures\n        # with 'unrecognized arguments: --benchmark-disable'\n        git clone --depth=1 https://github.com/sigstore/sigstore-python /tmp/sigstore-python\n        cd /tmp/sigstore-python\n        git rev-parse HEAD\n        pip install -e \".[test]\"\n        ;;\n    run)\n        cd /tmp/sigstore-python\n        # Run only the unit tests, and skip any that require network access.\n        pytest test/unit --skip-online\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "!/bin/bash -ex",
        "output": "case \"${1}\" in\n    install)\n        git clone --depth=1 https://github.com/twisted/twisted\n        cd twisted\n        git rev-parse HEAD\n        pip install \".[all_non_platform]\"\n        ;;\n    run)\n        cd twisted\n        python -m twisted.trial -j4 src/twisted\n        ;;\n    *)\n        exit 1\n        ;;\nesac"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "linkcode_resolve",
        "input": "Determine the url corresponding to Python object",
        "output": "def linkcode_resolve(domain, info):\n    \"\"\"\n    Determine the url corresponding to Python object\n    \"\"\"\n    if domain != \"py\":\n        return None\n\n    modname = info[\"module\"]\n    fullname = info[\"fullname\"]\n\n    try:\n        importlib.import_module(modname)\n    except Exception:\n        return None\n    submod = sys.modules.get(modname)\n    if submod is None:\n        return None\n\n    obj = submod\n    for part in fullname.split(\".\"):\n        try:\n            obj = getattr(obj, part)\n        except Exception:\n            return None\n\n    # strip decorators, which would resolve to the source of the decorator\n    # possibly an upstream bug in getsourcefile, bpo-1764286\n    try:\n        unwrap = inspect.unwrap\n    except AttributeError:\n        pass\n    else:\n        obj = unwrap(obj)\n\n    fn = None\n    lineno = None\n\n    try:\n        fn = inspect.getsourcefile(obj)\n    except Exception:\n        fn = None\n    if not fn:\n        return None\n\n    try:\n        source, lineno = inspect.getsourcelines(obj)\n    except Exception:\n        lineno = None\n\n    fn = os.path.relpath(fn, start=os.path.dirname(cryptography.__file__))\n\n    if lineno:\n        linespec = f\"#L{lineno}-L{lineno + len(source) - 1}\"\n    else:\n        linespec = \"\"\n\n    url = \"https://github.com/pyca/cryptography/blob/%s/src/cryptography/%s%s\"\n    if \"dev\" in cryptography.__version__:\n        return url % (\"main\", fn, linespec)\n    else:\n        version = \".\".join(cryptography.__version__.split(\".\")[:2] + [\"x\"])\n        return url % (version, fn, linespec)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "convert_key_to_192_bits",
        "input": "This takes existing 128 and 256-bit keys from test vectors from OpenSSL\nand makes them 192-bit by either appending 0 or truncating the key.",
        "output": "def convert_key_to_192_bits(key: str) -> str:\n    \"\"\"\n    This takes existing 128 and 256-bit keys from test vectors from OpenSSL\n    and makes them 192-bit by either appending 0 or truncating the key.\n    \"\"\"\n    new_key = binascii.unhexlify(key)\n    if len(new_key) == 16:\n        new_key += b\"\\x00\" * 8\n    elif len(new_key) == 32:\n        new_key = new_key[0:24]\n    else:\n        raise RuntimeError(\n            \"Unexpected key length. OpenSSL AES-GCM-SIV test vectors only \"\n            \"contain 128-bit and 256-bit keys\"\n        )\n\n    return binascii.hexlify(new_key).decode(\"ascii\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "run_queries",
        "input": "A function written in \"synchronous\" style that will be invoked\nwithin the asyncio event loop.\n\nThe session object passed is a traditional orm.Session object with\nsynchronous interface.",
        "output": "def run_queries(session):\n    \"\"\"A function written in \"synchronous\" style that will be invoked\n    within the asyncio event loop.\n\n    The session object passed is a traditional orm.Session object with\n    synchronous interface.\n\n    \"\"\"\n\n    stmt = select(A)\n\n    result = session.execute(stmt)\n\n    for a1 in result.scalars():\n        print(a1)\n        # lazy loads\n        for b1 in a1.bs:\n            print(b1)\n\n    result = session.execute(select(A).order_by(A.id))\n\n    a1 = result.scalars().first()\n\n    a1.data = \"new data\""
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "configure_listener",
        "input": "Establish attribute setters for every default-holding column on the\ngiven mapper.",
        "output": "def configure_listener(mapper, class_):\n    \"\"\"Establish attribute setters for every default-holding column on the\n    given mapper.\"\"\"\n\n    # iterate through ColumnProperty objects\n    for col_attr in mapper.column_attrs:\n        # look at the Column mapped by the ColumnProperty\n        # (we look at the first column in the less common case\n        # of a property mapped to multiple columns at once)\n        column = col_attr.columns[0]\n\n        # if the Column has a \"default\", set up a listener\n        if column.default is not None:\n            default_listener(col_attr, column.default)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "default_listener",
        "input": "Establish a default-setting listener.\n\nGiven a class attribute and a :class:`.DefaultGenerator` instance.\nThe default generator should be a :class:`.ColumnDefault` object with a\nplain Python value or callable default; otherwise, the appropriate behavior\nfor SQL functions and defaults should be determined here by the\nuser integrating this feature.",
        "output": "def default_listener(col_attr, default):\n    \"\"\"Establish a default-setting listener.\n\n    Given a class attribute and a :class:`.DefaultGenerator` instance.\n    The default generator should be a :class:`.ColumnDefault` object with a\n    plain Python value or callable default; otherwise, the appropriate behavior\n    for SQL functions and defaults should be determined here by the\n    user integrating this feature.\n\n    \"\"\"\n\n    @event.listens_for(col_attr, \"init_scalar\", retval=True, propagate=True)\n    def init_scalar(target, value, dict_):\n        if default.is_callable:\n            # the callable of ColumnDefault always accepts a context\n            # argument; we can pass it as None here.\n            value = default.arg(None)\n        elif default.is_scalar:\n            value = default.arg\n        else:\n            # default is a Sequence, a SQL expression, server\n            # side default generator, or other non-Python-evaluable\n            # object.  The feature here can't easily support this.   This\n            # can be made to return None, rather than raising,\n            # or can procure a connection from an Engine\n            # or Session and actually run the SQL, if desired.\n            raise NotImplementedError(\n                \"Can't invoke pre-default for a SQL-level column default\"\n            )\n\n        # set the value in the given dict_; this won't emit any further\n        # attribute set events or create attribute \"history\", but the value\n        # will be used in the INSERT statement\n        dict_[col_attr.key] = value\n\n        # return the value as well\n        return value"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "load_name_range",
        "input": "Load Person objects on a range of names.\n\nstart/end are integers, range is then\n\"person <start>\" - \"person <end>\".\n\nThe cache option we set up is called \"name_range\", indicating\na range of names for the Person class.\n\nThe `Person.addresses` collections are also cached.  Its basically\nanother level of tuning here, as that particular cache option\ncan be transparently replaced with joinedload(Person.addresses).\nThe effect is that each Person and their Address collection\nis cached either together or separately, affecting the kind of\nSQL that emits for unloaded Person objects as well as the distribution\nof data within the cache.",
        "output": "def load_name_range(start, end, invalidate=False):\n    \"\"\"Load Person objects on a range of names.\n\n    start/end are integers, range is then\n    \"person <start>\" - \"person <end>\".\n\n    The cache option we set up is called \"name_range\", indicating\n    a range of names for the Person class.\n\n    The `Person.addresses` collections are also cached.  Its basically\n    another level of tuning here, as that particular cache option\n    can be transparently replaced with joinedload(Person.addresses).\n    The effect is that each Person and their Address collection\n    is cached either together or separately, affecting the kind of\n    SQL that emits for unloaded Person objects as well as the distribution\n    of data within the cache.\n    \"\"\"\n    q = (\n        select(Person)\n        .filter(\n            Person.name.between(\"person %.2d\" % start, \"person %.2d\" % end)\n        )\n        .options(cache_address_bits)\n        .options(FromCache(\"default\", \"name_range\"))\n    )\n\n    # have the \"addresses\" collection cached separately\n    # each lazyload of Person.addresses loads from cache.\n    q = q.options(RelationshipCache(Person.addresses, \"default\"))\n\n    # alternatively, eagerly load the \"addresses\" collection, so that they'd\n    # be cached together.   This issues a bigger SQL statement and caches\n    # a single, larger value in the cache per person rather than two\n    # separate ones.\n    # q = q.options(joinedload(Person.addresses))\n\n    # if requested, invalidate the cache on current criterion.\n    if invalidate:\n        cache.invalidate(q, {}, FromCache(\"default\", \"name_range\"))\n        cache.invalidate(q, {}, RelationshipCache(Person.addresses, \"default\"))\n\n    return Session.scalars(q).all()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "invalidate",
        "input": "Invalidate the cache value represented by a statement.",
        "output": "def invalidate(self, statement, parameters, opt):\n        \"\"\"Invalidate the cache value represented by a statement.\"\"\"\n\n        if isinstance(statement, Query):\n            statement = statement.__clause_element__()\n\n        dogpile_region = self.cache_regions[opt.region]\n\n        cache_key = opt._generate_cache_key(statement, parameters, self)\n\n        dogpile_region.delete(cache_key)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__init__",
        "input": "Construct a new FromCache.\n\n:param region: the cache region.  Should be a\n region configured in the dictionary of dogpile\n regions.\n\n:param cache_key: optional.  A string cache key\n that will serve as the key to the query.   Use this\n if your query has a huge amount of parameters (such\n as when using in_()) which correspond more simply to\n some other identifier.",
        "output": "def __init__(\n        self,\n        region=\"default\",\n        cache_key=None,\n        expiration_time=None,\n        ignore_expiration=False,\n    ):\n        \"\"\"Construct a new FromCache.\n\n        :param region: the cache region.  Should be a\n         region configured in the dictionary of dogpile\n         regions.\n\n        :param cache_key: optional.  A string cache key\n         that will serve as the key to the query.   Use this\n         if your query has a huge amount of parameters (such\n         as when using in_()) which correspond more simply to\n         some other identifier.\n\n        \"\"\"\n        self.region = region\n        self.cache_key = cache_key\n        self.expiration_time = expiration_time\n        self.ignore_expiration = ignore_expiration"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_generate_cache_key",
        "input": "generate a cache key with which to key the results of a statement.\n\nThis leverages the use of the SQL compilation cache key which is\nrepurposed as a SQL results key.",
        "output": "def _generate_cache_key(self, statement, parameters, orm_cache):\n        \"\"\"generate a cache key with which to key the results of a statement.\n\n        This leverages the use of the SQL compilation cache key which is\n        repurposed as a SQL results key.\n\n        \"\"\"\n        statement_cache_key = statement._generate_cache_key()\n\n        key = statement_cache_key.to_offline_string(\n            orm_cache._statement_cache, statement, parameters\n        ) + repr(self.cache_key)\n        # print(\"here's our key...%s\" % key)\n        return key"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "__init__",
        "input": "Construct a new RelationshipCache.\n\n:param attribute: A Class.attribute which\n indicates a particular class relationship() whose\n lazy loader should be pulled from the cache.\n\n:param region: name of the cache region.\n\n:param cache_key: optional.  A string cache key\n that will serve as the key to the query, bypassing\n the usual means of forming a key from the Query itself.",
        "output": "def __init__(\n        self,\n        attribute,\n        region=\"default\",\n        cache_key=None,\n        expiration_time=None,\n        ignore_expiration=False,\n    ):\n        \"\"\"Construct a new RelationshipCache.\n\n        :param attribute: A Class.attribute which\n         indicates a particular class relationship() whose\n         lazy loader should be pulled from the cache.\n\n        :param region: name of the cache region.\n\n        :param cache_key: optional.  A string cache key\n         that will serve as the key to the query, bypassing\n         the usual means of forming a key from the Query itself.\n\n        \"\"\"\n        self.region = region\n        self.cache_key = cache_key\n        self.expiration_time = expiration_time\n        self.ignore_expiration = ignore_expiration\n        self._relationship_options = {\n            (attribute.property.parent.class_, attribute.property.key): self\n        }"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "and_",
        "input": "Chain another RelationshipCache option to this one.\n\nWhile many RelationshipCache objects can be specified on a single\nQuery separately, chaining them together allows for a more efficient\nlookup during load.",
        "output": "def and_(self, option):\n        \"\"\"Chain another RelationshipCache option to this one.\n\n        While many RelationshipCache objects can be specified on a single\n        Query separately, chaining them together allows for a more efficient\n        lookup during load.\n\n        \"\"\"\n        self._relationship_options.update(option._relationship_options)\n        return self"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "md5_key_mangler",
        "input": "Receive cache keys as long concatenated strings;\ndistill them into an md5 hash.",
        "output": "def md5_key_mangler(key):\n    \"\"\"Receive cache keys as long concatenated strings;\n    distill them into an md5 hash.\n\n    \"\"\"\n    return md5(key.encode(\"ascii\")).hexdigest()"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "_cache_dictionary",
        "input": "Return the cache dictionary linked to the current Session.",
        "output": "def _cache_dictionary(self):\n        \"\"\"Return the cache dictionary linked to the current Session.\"\"\"\n\n        sess = self.scoped_session()\n        try:\n            cache_dict = sess._cache_dictionary\n        except AttributeError:\n            sess._cache_dictionary = cache_dict = {}\n        return cache_dict"
    },
    {
        "task_type": "security_classification",
        "language": "shell",
        "input": "This script must be sourced with the following variables already set:",
        "output": ": \"${ANDROID_HOME:?}\"  # Path to Android SDK\n: \"${HOST:?}\"  # GNU target triplet\n\n# You may also override the following:\n: \"${api_level:=24}\"  # Minimum Android API level the build will run on\n: \"${PREFIX:-}\"  # Path in which to find required libraries\n\n\n# Print all messages on stderr so they're visible when running within build-wheel.\nlog() {\n    echo \"$1\" >&2\n}\n\nfail() {\n    log \"$1\"\n    exit 1\n}\n\n# When moving to a new version of the NDK, carefully review the following:\n#\n# * https://developer.android.com/ndk/downloads/revision_history\n#\n# * https://android.googlesource.com/platform/ndk/+/ndk-rXX-release/docs/BuildSystemMaintainers.md\n#   where XX is the NDK version. Do a diff against the version you're upgrading from, e.g.:\n#   https://android.googlesource.com/platform/ndk/+/ndk-r25-release..ndk-r26-release/docs/BuildSystemMaintainers.md\nndk_version=27.1.12297006\n\nndk=$ANDROID_HOME/ndk/$ndk_version\nif ! [ -e \"$ndk\" ]; then\n    log \"Installing NDK - this may take several minutes\"\n    yes | \"$ANDROID_HOME/cmdline-tools/latest/bin/sdkmanager\" \"ndk;$ndk_version\"\nfi\n\nif [ \"$HOST\" = \"arm-linux-androideabi\" ]; then\n    clang_triplet=armv7a-linux-androideabi\nelse\n    clang_triplet=\"$HOST\"\nfi\n\n# These variables are based on BuildSystemMaintainers.md above, and\n# $ndk/build/cmake/android.toolchain.cmake.\ntoolchain=$(echo \"$ndk\"/toolchains/llvm/prebuilt/*)\nexport AR=\"$toolchain/bin/llvm-ar\"\nexport AS=\"$toolchain/bin/llvm-as\"\nexport CC=\"$toolchain/bin/${clang_triplet}${api_level}-clang\"\nexport CXX=\"${CC}++\"\nexport LD=\"$toolchain/bin/ld\"\nexport NM=\"$toolchain/bin/llvm-nm\"\nexport RANLIB=\"$toolchain/bin/llvm-ranlib\"\nexport READELF=\"$toolchain/bin/llvm-readelf\"\nexport STRIP=\"$toolchain/bin/llvm-strip\"\n\n# The quotes make sure the wildcard in the `toolchain` assignment has been expanded.\nfor path in \"$AR\" \"$AS\" \"$CC\" \"$CXX\" \"$LD\" \"$NM\" \"$RANLIB\" \"$READELF\" \"$STRIP\"; do\n    if ! [ -e \"$path\" ]; then\n        fail \"$path does not exist\"\n    fi\ndone\n\nexport CFLAGS=\"-D__BIONIC_NO_PAGE_SIZE_MACRO\"\nexport LDFLAGS=\"-Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,-z,max-page-size=16384\"\n\n# Unlike Linux, Android does not implicitly use a dlopened library to resolve\n# relocations in subsequently-loaded libraries, even if RTLD_GLOBAL is used\n# (https://github.com/android/ndk/issues/1244). So any library that fails to\n# build with this flag, would also fail to load at runtime.\nLDFLAGS=\"$LDFLAGS -Wl,--no-undefined\"\n\n# Many packages get away with omitting -lm on Linux, but Android is stricter.\nLDFLAGS=\"$LDFLAGS -lm\"\n\n# -mstackrealign is included where necessary in the clang launcher scripts which are\n# pointed to by $CC, so we don't need to include it here.\nif [ \"$HOST\" = \"arm-linux-androideabi\" ]; then\n    CFLAGS=\"$CFLAGS -march=armv7-a -mthumb\"\nfi\n\nif [ -n \"${PREFIX:-}\" ]; then\n    abs_prefix=\"$(realpath \"$PREFIX\")\"\n    CFLAGS=\"$CFLAGS -I$abs_prefix/include\"\n    LDFLAGS=\"$LDFLAGS -L$abs_prefix/lib\"\n\n    export PKG_CONFIG=\"pkg-config --define-prefix\"\n    export PKG_CONFIG_LIBDIR=\"$abs_prefix/lib/pkgconfig\"\nfi\n\n# When compiling C++, some build systems will combine CFLAGS and CXXFLAGS, and some will\n# use CXXFLAGS alone.\nexport CXXFLAGS=\"$CFLAGS\"\n\n# Use the same variable name as conda-build\nif [ \"$(uname)\" = \"Darwin\" ]; then\n    CPU_COUNT=\"$(sysctl -n hw.ncpu)\"\n    export CPU_COUNT\nelse\n    CPU_COUNT=\"$(nproc)\"\n    export CPU_COUNT\nfi"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "build_python_path",
        "input": "The path to the build Python binary.",
        "output": "def build_python_path():\n    \"\"\"The path to the build Python binary.\"\"\"\n    build_dir = subdir(\"build\")\n    binary = build_dir / \"python\"\n    if not binary.is_file():\n        binary = binary.with_suffix(\".exe\")\n        if not binary.is_file():\n            raise FileNotFoundError(\"Unable to find `python(.exe)` in \"\n                                    f\"{build_dir}\")\n\n    return binary"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "magic_html_parser",
        "input": "Return safety-sanitized html linked to partfiles.\n\nRewrite the href=\"cid:....\" attributes to point to the filenames in partfiles.\nThough not trivial, this should be possible using html.parser.",
        "output": "def magic_html_parser(html_text, partfiles):\n    \"\"\"Return safety-sanitized html linked to partfiles.\n\n    Rewrite the href=\"cid:....\" attributes to point to the filenames in partfiles.\n    Though not trivial, this should be possible using html.parser.\n    \"\"\"\n    raise NotImplementedError(\"Add the magic needed\")"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "checkout_commit",
        "input": "Context manager that checks out a given commit when entered, but gets back to the reference it was at on exit.\nArgs:\n    repo (`git.Repo`): A git repository (for instance the Transformers repo).\n    commit_id (`str`): The commit reference to checkout inside the context manager.",
        "output": "def checkout_commit(repo: Repo, commit_id: str):\n    \"\"\"\n    Context manager that checks out a given commit when entered, but gets back to the reference it was at on exit.\n    Args:\n        repo (`git.Repo`): A git repository (for instance the Transformers repo).\n        commit_id (`str`): The commit reference to checkout inside the context manager.\n    \"\"\"\n    current_head = repo.head.commit if repo.head.is_detached else repo.head.ref\n\n    try:\n        repo.git.checkout(commit_id)\n        yield\n\n    finally:\n        repo.git.checkout(current_head)"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "summarize",
        "input": "Produce a summary for each optimum-benchmark launched job's output directory found in `run_dir`.\n\nEach summary's format is as follows (for `expand_metrics=False`):\n```\n{\n    \"model\": \"google/gemma-2b\",\n    \"commit\": \"3cd6ed22e4d49219f300f5055e71e3929aba20d7\",\n    \"config\": \"benchmark.input_shapes.batch_size=1,benchmark.input_shapes.sequence_length=5\",\n    \"metrics\": {\n        \"decode.latency.mean\": 1.624666809082031,\n        \"per_token.latency.mean\": 0.012843788806628804,\n        \"per_token.throughput.value\": 77.85864553330948\n    }\n}\n```",
        "output": "def summarize(run_dir, metrics, expand_metrics=False):\n    \"\"\"Produce a summary for each optimum-benchmark launched job's output directory found in `run_dir`.\n\n    Each summary's format is as follows (for `expand_metrics=False`):\n    ```\n    {\n        \"model\": \"google/gemma-2b\",\n        \"commit\": \"3cd6ed22e4d49219f300f5055e71e3929aba20d7\",\n        \"config\": \"benchmark.input_shapes.batch_size=1,benchmark.input_shapes.sequence_length=5\",\n        \"metrics\": {\n            \"decode.latency.mean\": 1.624666809082031,\n            \"per_token.latency.mean\": 0.012843788806628804,\n            \"per_token.throughput.value\": 77.85864553330948\n        }\n    }\n    ```\n    \"\"\"\n    reports = glob.glob(os.path.join(run_dir, \"**/benchmark_report.json\"), recursive=True)\n    report_dirs = [str(Path(report).parent) for report in reports]\n\n    summaries = []\n    for report_dir in report_dirs:\n        commit = re.search(r\"/commit=([^/]+)\", report_dir).groups()[0]\n\n        if not os.path.isfile(os.path.join(report_dir, \"benchmark.json\")):\n            continue\n        benchmark = Benchmark.from_json(os.path.join(report_dir, \"benchmark.json\"))\n        report = benchmark.report\n\n        model = benchmark.config.backend[\"model\"]\n\n        # Ths looks like `benchmark.input_shapes.batch_size=1,benchmark.input_shapes.sequence_length=5`.\n        # (we rely on the usage of hydra's `${hydra.job.override_dirname}`.)\n        benchmark_name = re.sub(f\"backend.model={model},*\", \"\", report_dir)\n        benchmark_name = str(Path(benchmark_name).parts[-1])\n        if benchmark_name.startswith(\"commit=\"):\n            benchmark_name = benchmark.config.name\n\n        metrics_values = {}\n        # post-processing of report: show a few selected/important metric\n        for metric in metrics:\n            keys = metric.split(\".\")\n            value = report.to_dict()\n            current = metrics_values\n            for key in keys:\n                # Avoid KeyError when a user's specified metric has typo.\n                # TODO: Give warnings.\n                if key not in value:\n                    continue\n                value = value[key]\n\n                if expand_metrics:\n                    if isinstance(value, dict):\n                        if key not in current:\n                            current[key] = {}\n                            current = current[key]\n                    else:\n                        current[key] = value\n\n            if not expand_metrics:\n                metrics_values[metric] = value\n\n        # show some config information\n        print(f\"model: {model}\")\n        print(f\"commit: {commit}\")\n        print(f\"config: {benchmark_name}\")\n        if len(metrics_values) > 0:\n            print(\"metrics:\")\n            if expand_metrics:\n                print(metrics_values)\n            else:\n                for metric, value in metrics_values.items():\n                    print(f\"  - {metric}: {value}\")\n        print(\"-\" * 80)\n\n        summary = {\n            \"model\": model,\n            \"commit\": commit,\n            \"config\": benchmark_name,\n            \"metrics\": metrics_values,\n        }\n        summaries.append(summary)\n\n        with open(os.path.join(report_dir, \"summary.json\"), \"w\") as fp:\n            json.dump(summary, fp, indent=4)\n\n    return summaries"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "combine_summaries",
        "input": "Combine a list of summary obtained from the function `summarize`.\n\nThe combined summary's format is as follows:\n```\n\"google/gemma-2b\": {\n    \"benchmark.input_shapes.batch_size=1,benchmark.input_shapes.sequence_length=5\": {\n        \"3cd6ed22e4d49219f300f5055e71e3929aba20d7\": {\n            \"metrics\": {\"decode.latency.mean\": 1.624666809082031}\n        },\n        \"c97ee28b117c0abe8e08891f402065e4df6d72aa\": {\n            \"metrics\": {\"decode.latency.mean\": 1.6278163452148438}\n        }\n    },\n    \"benchmark.input_shapes.batch_size=2,benchmark.input_shapes.sequence_length=5\": {\n        \"3cd6ed22e4d49219f300f5055e71e3929aba20d7\": {\n            \"metrics\": {\"decode.latency.mean\": 1.6947791748046876}\n        },\n        \"c97ee28b117c0abe8e08891f402065e4df6d72aa\": {\n            \"metrics\": {\n                \"decode.latency.mean\": 1.6980519409179688}\n        }\n    }\n}\n```",
        "output": "def combine_summaries(summaries):\n    \"\"\"Combine a list of summary obtained from the function `summarize`.\n\n    The combined summary's format is as follows:\n    ```\n    \"google/gemma-2b\": {\n        \"benchmark.input_shapes.batch_size=1,benchmark.input_shapes.sequence_length=5\": {\n            \"3cd6ed22e4d49219f300f5055e71e3929aba20d7\": {\n                \"metrics\": {\"decode.latency.mean\": 1.624666809082031}\n            },\n            \"c97ee28b117c0abe8e08891f402065e4df6d72aa\": {\n                \"metrics\": {\"decode.latency.mean\": 1.6278163452148438}\n            }\n        },\n        \"benchmark.input_shapes.batch_size=2,benchmark.input_shapes.sequence_length=5\": {\n            \"3cd6ed22e4d49219f300f5055e71e3929aba20d7\": {\n                \"metrics\": {\"decode.latency.mean\": 1.6947791748046876}\n            },\n            \"c97ee28b117c0abe8e08891f402065e4df6d72aa\": {\n                \"metrics\": {\n                    \"decode.latency.mean\": 1.6980519409179688}\n            }\n        }\n    }\n    ```\n    \"\"\"\n    combined = {}\n    for summary in summaries:\n        model = summary[\"model\"]\n        config = summary[\"config\"]\n        commit = summary[\"commit\"]\n\n        if model not in combined:\n            combined[model] = {}\n\n        if config not in combined[model]:\n            combined[model][config] = {}\n\n        if commit not in combined[model][config]:\n            combined[model][config][commit] = {\"metrics\": summary[\"metrics\"]}\n\n    with open(os.path.join(exp_run_dir, \"summary.json\"), \"w\") as fp:\n        json.dump(combined, fp, indent=4)\n\n    print(json.dumps(combined, indent=4))\n\n    return combined"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "parse_arguments",
        "input": "Parse command line arguments for the benchmarking CLI.",
        "output": "def parse_arguments():\n    \"\"\"\n    Parse command line arguments for the benchmarking CLI.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=\"CLI for benchmarking the huggingface/transformers.\")\n\n    parser.add_argument(\n        \"branch\",\n        type=str,\n        help=\"The branch name on which the benchmarking is performed.\",\n    )\n\n    parser.add_argument(\n        \"commit_id\",\n        type=str,\n        help=\"The commit hash on which the benchmarking is performed.\",\n    )\n\n    parser.add_argument(\n        \"commit_msg\",\n        type=str,\n        help=\"The commit message associated with the commit, truncated to 70 characters.\",\n    )\n\n    args = parser.parse_args()\n\n    return args.branch, args.commit_id, args.commit_msg"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "initialise_benchmark",
        "input": "Creates a new benchmark, returns the benchmark id",
        "output": "def initialise_benchmark(self, metadata: Dict[str, str]) -> int:\n        \"\"\"\n        Creates a new benchmark, returns the benchmark id\n        \"\"\"\n        # gpu_name: str, model_id: str\n        with self.conn.cursor() as cur:\n            cur.execute(\n                \"INSERT INTO benchmarks (branch, commit_id, commit_message, metadata) VALUES (%s, %s, %s, %s) RETURNING benchmark_id\",\n                (self.branch, self.commit_id, self.commit_msg, metadata),\n            )\n            benchmark_id = cur.fetchone()[0]\n            logger.debug(f\"initialised benchmark #{benchmark_id}\")\n            return benchmark_id"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "collect_device_measurements",
        "input": "Collect device metrics, such as CPU & GPU usage. These are \"static\", as in you cannot pass arbitrary arguments to the function.",
        "output": "def collect_device_measurements(self, benchmark_id: int, cpu_util, mem_megabytes, gpu_util, gpu_mem_megabytes):\n        \"\"\"\n        Collect device metrics, such as CPU & GPU usage. These are \"static\", as in you cannot pass arbitrary arguments to the function.\n        \"\"\"\n        with self.conn.cursor() as cur:\n            cur.execute(\n                \"INSERT INTO device_measurements (benchmark_id, cpu_util, mem_megabytes, gpu_util, gpu_mem_megabytes) VALUES (%s, %s, %s, %s, %s)\",\n                (benchmark_id, cpu_util, mem_megabytes, gpu_util, gpu_mem_megabytes),\n            )\n        self.logger.debug(\n            f\"inserted device measurements for benchmark #{benchmark_id} [CPU util: {cpu_util}, mem MBs: {mem_megabytes}, GPU util: {gpu_util}, GPU mem MBs: {gpu_mem_megabytes}]\"\n        )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "shift_tokens_right",
        "input": "Shift input ids one token to the right.",
        "output": "def shift_tokens_right(input_ids: np.ndarray, pad_token_id: int, decoder_start_token_id: int) -> np.ndarray:\n    \"\"\"\n    Shift input ids one token to the right.\n    \"\"\"\n    shifted_input_ids = np.zeros_like(input_ids)\n    shifted_input_ids[:, 1:] = input_ids[:, :-1]\n    shifted_input_ids[:, 0] = decoder_start_token_id\n\n    shifted_input_ids = np.where(shifted_input_ids == -100, pad_token_id, shifted_input_ids)\n    return shifted_input_ids"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "data_loader",
        "input": "Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\nShuffle batches if `shuffle` is `True`.",
        "output": "def data_loader(rng: jax.random.PRNGKey, dataset: Dataset, batch_size: int, shuffle: bool = False):\n    \"\"\"\n    Returns batches of size `batch_size` from truncated `dataset`, sharded over all local devices.\n    Shuffle batches if `shuffle` is `True`.\n    \"\"\"\n    steps = len(dataset) // batch_size  # Skip incomplete batch.\n\n    # We use `numpy.ndarray` to interact with `datasets.Dataset`, since using `jax.numpy.array` to index into a\n    # dataset is significantly slow. Using JAX array at the 1st place is only to keep JAX's PRNGs generation\n    # mechanism, which works differently from NumPy/SciPy.\n    if shuffle:\n        batch_idx = jax.random.permutation(rng, len(dataset))\n        batch_idx = np.asarray(batch_idx)\n    else:\n        batch_idx = np.arange(len(dataset))\n\n    for idx in range(steps):\n        start_idx = batch_size * idx\n        end_idx = batch_size * (idx + 1)\n\n        selected_indices = batch_idx[start_idx:end_idx]\n        batch = dataset[selected_indices]\n        batch = shard(batch)\n\n        yield batch"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "create_learning_rate_fn",
        "input": "Returns a linear warmup, linear_decay learning rate function.",
        "output": "def create_learning_rate_fn(\n    train_ds_size: int, train_batch_size: int, num_train_epochs: int, num_warmup_steps: int, learning_rate: float\n) -> Callable[[int], jnp.ndarray]:\n    \"\"\"Returns a linear warmup, linear_decay learning rate function.\"\"\"\n    steps_per_epoch = train_ds_size // train_batch_size\n    num_train_steps = steps_per_epoch * num_train_epochs\n    warmup_fn = optax.linear_schedule(init_value=0.0, end_value=learning_rate, transition_steps=num_warmup_steps)\n    decay_fn = optax.linear_schedule(\n        init_value=learning_rate, end_value=0, transition_steps=num_train_steps - num_warmup_steps\n    )\n    schedule_fn = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[num_warmup_steps])\n    return schedule_fn"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "to_dict",
        "input": "Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\nthe token values by removing their value.",
        "output": "def to_dict(self):\n        \"\"\"\n        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\n        the token values by removing their value.\n        \"\"\"\n        d = asdict(self)\n        for k, v in d.items():\n            if isinstance(v, Enum):\n                d[k] = v.value\n            if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):\n                d[k] = [x.value for x in v]\n            if k.endswith(\"_token\"):\n                d[k] = f\"<{k.upper()}>\"\n        return d"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "filter_fn",
        "input": "remove problematic images",
        "output": "def filter_fn(examples):\n        \"\"\"remove problematic images\"\"\"\n\n        bools = []\n        for image_file in examples[image_column]:\n            try:\n                image = Image.open(image_file)\n                image_processor(images=image, return_tensors=\"np\")\n                bools.append(True)\n            except Exception:\n                bools.append(False)\n\n        return bools"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "tokenization_fn",
        "input": "Run tokenization on captions.",
        "output": "def tokenization_fn(examples, max_target_length):\n        \"\"\"Run tokenization on captions.\"\"\"\n\n        captions = []\n        for caption in examples[caption_column]:\n            captions.append(caption.lower() + \" \" + tokenizer.eos_token)\n        targets = captions\n\n        model_inputs = {}\n\n        labels = tokenizer(\n            text_target=targets,\n            max_length=max_target_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"np\",\n        )\n        model_inputs[\"labels\"] = labels[\"input_ids\"]\n        decoder_input_ids = shift_tokens_right_fn(\n            labels[\"input_ids\"], model.config.pad_token_id, model.config.decoder_start_token_id\n        )\n        model_inputs[\"decoder_input_ids\"] = np.asarray(decoder_input_ids)\n        # We need decoder_attention_mask so we can ignore pad tokens from loss\n        model_inputs[\"decoder_attention_mask\"] = labels[\"attention_mask\"]\n        model_inputs[image_column] = examples[image_column]\n\n        return model_inputs"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "image_processing_fn",
        "input": "Run preprocessing on images\n\nIf `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\nOtherwise, an exception will be thrown.",
        "output": "def image_processing_fn(examples, check_image=True):\n        \"\"\"\n        Run preprocessing on images\n\n        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n        Otherwise, an exception will be thrown.\n        \"\"\"\n\n        model_inputs = {}\n\n        if check_image:\n            images = []\n            to_keep = []\n            for image_file in examples[image_column]:\n                try:\n                    img = Image.open(image_file)\n                    images.append(img)\n                    to_keep.append(True)\n                except Exception:\n                    to_keep.append(False)\n\n            for k, v in examples.items():\n                if k != image_column:\n                    model_inputs[k] = v[to_keep]\n        else:\n            images = [Image.open(image_file) for image_file in examples[image_column]]\n\n        encoder_inputs = image_processor(images=images, return_tensors=\"np\")\n        model_inputs[\"pixel_values\"] = encoder_inputs.pixel_values\n\n        return model_inputs"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "preprocess_fn",
        "input": "Run tokenization + image processing",
        "output": "def preprocess_fn(examples, max_target_length, check_image=True):\n        \"\"\"Run tokenization + image processing\"\"\"\n\n        model_inputs = {}\n        # This contains image path column\n        model_inputs.update(tokenization_fn(examples, max_target_length))\n        model_inputs.update(image_processing_fn(model_inputs, check_image=check_image))\n        # Remove image path column\n        model_inputs.pop(image_column)\n\n        return model_inputs"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "blockwise_data_loader",
        "input": "Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\nIf `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\nprocessing (with the column name being specified by `image_column`). The tokenization should be done before\ntraining in this case.",
        "output": "def blockwise_data_loader(\n        rng: jax.random.PRNGKey,\n        ds: Dataset,\n        block_size: int,\n        batch_size: int,\n        shuffle: bool = False,\n        keep_in_memory: bool = False,\n        split: str = \"\",\n    ):\n        \"\"\"\n        Wrap the simple `data_loader` in a block-wise way if `block_size` > 0, else it's the same as `data_loader`.\n\n        If `block_size` > 0, it requires `ds` to have a column that gives image paths in order to perform image\n        processing (with the column name being specified by `image_column`). The tokenization should be done before\n        training in this case.\n        \"\"\"\n\n        # We use `numpy.ndarray` to interact with `datasets.Dataset`, since using `jax.numpy.array` to index into a\n        # dataset is significantly slow. Using JAX array at the 1st place is only to keep JAX's PRNGs generation\n        # mechanism, which works differently from NumPy/SciPy.\n        if shuffle:\n            indices = jax.random.permutation(rng, len(ds))\n            indices = np.asarray(indices)\n        else:\n            indices = np.arange(len(ds))\n\n        _block_size = len(ds) if not block_size else block_size\n\n        steps_per_block = _block_size // batch_size\n        num_examples = len(ds)\n        steps = num_examples // batch_size\n        num_splits = steps // steps_per_block + int(steps % steps_per_block > 0)\n\n        for idx in range(num_splits):\n            if not block_size:\n                _ds = ds\n            else:\n                start_idx = block_size * idx\n                end_idx = block_size * (idx + 1)\n\n                selected_indices = indices[start_idx:end_idx]\n\n                _ds = ds.select(selected_indices)\n\n                _ds = _ds.map(\n                    image_processing_fn,\n                    batched=True,\n                    num_proc=data_args.preprocessing_num_workers,\n                    remove_columns=[image_column],\n                    load_from_cache_file=not data_args.overwrite_cache,\n                    features=features,\n                    keep_in_memory=keep_in_memory,\n                    # The images are already checked either in `.filter()` or in `preprocess_fn()`\n                    fn_kwargs={\"check_image\": False},\n                    desc=f\"Running image processing on {split} dataset\".replace(\"  \", \" \"),\n                )\n                _ds = _ds.with_format(\"numpy\")\n\n            # No need to shuffle here\n            loader = data_loader(rng, _ds, batch_size=batch_size, shuffle=False)\n\n            yield from loader"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "loss_fn",
        "input": "The label smoothing implementation is adapted from Flax's official example:\nhttps://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104",
        "output": "def loss_fn(logits, labels, padding_mask, label_smoothing_factor=0.0):\n        \"\"\"\n        The label smoothing implementation is adapted from Flax's official example:\n        https://github.com/google/flax/blob/87a211135c6a377c8f29048a1cac3840e38b9da4/examples/wmt/train.py#L104\n        \"\"\"\n        vocab_size = logits.shape[-1]\n        confidence = 1.0 - label_smoothing_factor\n        low_confidence = (1.0 - confidence) / (vocab_size - 1)\n        normalizing_constant = -(\n            confidence * jnp.log(confidence) + (vocab_size - 1) * low_confidence * jnp.log(low_confidence + 1e-20)\n        )\n        soft_labels = onehot(labels, vocab_size, on_value=confidence, off_value=low_confidence)\n\n        loss = optax.softmax_cross_entropy(logits, soft_labels)\n        loss = loss - normalizing_constant\n\n        # ignore padded tokens from loss\n        loss = loss * padding_mask\n        loss = loss.sum()\n        num_labels = padding_mask.sum()\n        return loss, num_labels"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "save_ckpt",
        "input": "save checkpoints and push to Hugging Face Hub if specified",
        "output": "def save_ckpt(ckpt_dir: str, commit_msg: str = \"\"):\n        \"\"\"save checkpoints and push to Hugging Face Hub if specified\"\"\"\n\n        # save checkpoint after each epoch and push checkpoint to the hub\n        if jax.process_index() == 0:\n            params = jax.device_get(jax.tree_util.tree_map(lambda x: x[0], state.params))\n            model.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir), params=params)\n            tokenizer.save_pretrained(os.path.join(training_args.output_dir, ckpt_dir))\n            if training_args.push_to_hub:\n                api.upload_folder(\n                    commit_message=commit_msg,\n                    folder_path=training_args.output_dir,\n                    repo_id=repo_id,\n                    repo_type=\"model\",\n                    token=training_args.hub_token,\n                )"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "generate_batch_splits",
        "input": "Generate batches of data for a specified batch size from sample indices. If the dataset size is not divisible by\nthe batch size and `drop_last` is `True`, the last incomplete batch is dropped. Else, it is returned.",
        "output": "def generate_batch_splits(samples_idx: np.ndarray, batch_size: int, drop_last=True) -> np.ndarray:\n    \"\"\"Generate batches of data for a specified batch size from sample indices. If the dataset size is not divisible by\n    the batch size and `drop_last` is `True`, the last incomplete batch is dropped. Else, it is returned.\"\"\"\n    num_samples = len(samples_idx)\n    if drop_last:\n        samples_to_remove = num_samples % batch_size\n        if samples_to_remove != 0:\n            samples_idx = samples_idx[:-samples_to_remove]\n        sections_split = num_samples // batch_size\n        samples_idx = samples_idx.reshape((sections_split, batch_size))\n    else:\n        sections_split = math.ceil(num_samples / batch_size)\n        samples_idx = np.array_split(samples_idx, sections_split)\n    return samples_idx"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "to_dict",
        "input": "Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\nthe token values by removing their value.",
        "output": "def to_dict(self):\n        \"\"\"\n        Serializes this instance while replace `Enum` by their values (for JSON serialization support). It obfuscates\n        the token values by removing their value.\n        \"\"\"\n        d = asdict(self)\n        for k, v in d.items():\n            if isinstance(v, Enum):\n                d[k] = v.value\n            if isinstance(v, list) and len(v) > 0 and isinstance(v[0], Enum):\n                d[k] = [x.value for x in v]\n            if k.endswith(\"_token\"):\n                d[k] = f\"<{k.upper()}>\"\n        return d"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "permute_sentences",
        "input": "Shuffle sentences in each document.",
        "output": "def permute_sentences(self, input_ids):\n        \"\"\"\n        Shuffle sentences in each document.\n        \"\"\"\n        results = input_ids.copy()\n\n        # find end locations of sentences\n        end_sentence_mask = input_ids == self.tokenizer.pad_token_id\n        sentence_ends = np.argwhere(end_sentence_mask)\n        sentence_ends[:, 1] += 1\n        example_has_multiple_sentences, num_sentences = np.unique(sentence_ends[:, 0], return_counts=True)\n        num_sentences_map = dict(zip(example_has_multiple_sentences, num_sentences))\n\n        num_to_permute = np.ceil(num_sentences * self.permute_sentence_ratio).astype(int)\n        num_to_permute_map = dict(zip(example_has_multiple_sentences, num_to_permute))\n\n        sentence_ends = np.split(sentence_ends[:, 1], np.unique(sentence_ends[:, 0], return_index=True)[1][1:])\n        sentence_ends_map = dict(zip(example_has_multiple_sentences, sentence_ends))\n\n        for i in range(input_ids.shape[0]):\n            if i not in example_has_multiple_sentences:\n                continue\n            substitutions = np.random.permutation(num_sentences_map[i])[: num_to_permute_map[i]]\n            ordering = np.arange(0, num_sentences_map[i])\n            ordering[substitutions] = substitutions[np.random.permutation(num_to_permute_map[i])]\n\n            # write shuffled sentences into results\n            index = 0\n            for j in ordering:\n                sentence = input_ids[i, (sentence_ends_map[i][j - 1] if j > 0 else 0) : sentence_ends_map[i][j]]\n                results[i, index : index + sentence.shape[0]] = sentence\n                index += sentence.shape[0]\n        return results"
    },
    {
        "task_type": "code_generation",
        "language": "python",
        "func_name": "span_mask_tokens",
        "input": "Sampling text spans with span lengths drawn from a Poisson distribution and masking them.",
        "output": "def span_mask_tokens(self, input_ids, labels, do_permute):\n        \"\"\"\n        Sampling text spans with span lengths drawn from a Poisson distribution and masking them.\n        \"\"\"\n        special_tokens_mask_labels = [\n            self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n        ]\n        special_tokens_mask_inputs = [\n            self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in input_ids.tolist()\n        ]\n        special_tokens_mask_labels = np.array(special_tokens_mask_labels, dtype=bool)\n        special_tokens_mask_inputs = np.array(special_tokens_mask_inputs, dtype=bool)\n\n        # determine how many tokens we need to mask in total\n        is_token_mask = ~(input_ids == self.tokenizer.pad_token_id) & ~special_tokens_mask_inputs\n        num_tokens_to_mask = int(math.ceil(is_token_mask.astype(float).sum() * self.mask_ratio))\n        if num_tokens_to_mask == 0:\n            return input_ids, labels\n\n        # generate a sufficient number of span lengths\n        span_lengths = np.random.poisson(lam=self.poisson_lambda, size=(num_tokens_to_mask,))\n        while np.cumsum(span_lengths, 0)[-1] < num_tokens_to_mask:\n            span_lengths = np.concatenate(\n                [span_lengths, np.random.poisson(lam=self.poisson_lambda, size=(num_tokens_to_mask,))]\n            )\n\n        # remove all spans of length 0\n        # note that BART inserts additional mask tokens where length == 0,\n        # which we do not implement for now as it adds additional complexity\n        span_lengths = span_lengths[span_lengths > 0]\n\n        # trim to about num_tokens_to_mask tokens\n        cutoff_idx = np.argmin(np.abs(np.cumsum(span_lengths, 0) - num_tokens_to_mask)) + 1\n        span_lengths = span_lengths[:cutoff_idx]\n\n        # randomly choose starting positions for masking\n        token_indices = np.argwhere(is_token_mask == 1)\n        span_starts = np.random.permutation(token_indices.shape[0])[: span_lengths.shape[0]]\n        # prepare mask\n        masked_indices = np.array(token_indices[span_starts])\n        mask = np.full_like(input_ids, fill_value=False)\n\n        # mask starting positions\n        for mi in masked_indices:\n            mask[tuple(mi)] = True\n        span_lengths -= 1\n\n        # fill up spans\n        max_index = input_ids.shape[1] - 1\n        remaining = (span_lengths > 0) & (masked_indices[:, 1] < max_index)\n        while np.any(remaining):\n            masked_indices[remaining, 1] += 1\n            for mi in masked_indices:\n                mask[tuple(mi)] = True\n            span_lengths -= 1\n            remaining = (span_lengths > 0) & (masked_indices[:, 1] < max_index)\n\n        # place the mask tokens\n        mask[np.where(special_tokens_mask_inputs)] = False\n        input_ids[np.where(mask)] = self.tokenizer.mask_token_id\n        if not do_permute:\n            labels[np.where(mask == 0)] = -100\n        else:\n            labels[np.where(special_tokens_mask_labels)] = -100\n\n        # remove mask tokens that are not starts of spans\n        to_remove = (mask == 1) & np.roll((mask == 1), 1, 1)\n        new_input_ids = np.full_like(input_ids, fill_value=self.tokenizer.pad_token_id)\n        for i, example in enumerate(input_ids):\n            new_example = example[~to_remove[i]]\n            new_input_ids[i, : new_example.shape[0]] = new_example\n\n        return new_input_ids, labels"
    }
]